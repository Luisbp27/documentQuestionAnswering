{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Document(page_content='Grado en Ingenier ´ıa Inform ´atica\\nEvaluaci´ on y Comportamiento de los Sistemas Inform´ aticos\\nCuaderno de Pr´ acticas\\nLluis Barca Pons\\nlluis.barca1@estudiant.uib.es\\n6 de junio de 2022', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 0}), Document(page_content='Pr´ actica 1\\nPara la realizaci´ on de esta pr´ actica contaremos con los servidores A y B los cuales est´ an dedicados\\na tareas de c´ alculo cient´ ıfico. Es decir, las cargas que ejecutan son intensivas en CPU, y, por lo\\ntanto, este es su dispositivo m´ as demandado. A continuaci´ on, se detallan las caracter´ ısticas de\\ncada uno de los servidores.\\nServidor A\\nNombre del servidor: Dell Power Edge T430\\nN´ umero de CPUs: 16\\nTama˜ no de la memoria RAM: 7753Mib ( ≈8GB)\\nCoste: 1245 e\\nServidor B\\nNombre del servidor: Dell Power Edge T330\\nN´ umero de CPUs: 8\\nTama˜ no de la memoria RAM: 15258,8Mib ( ≈16GB)\\nCoste: 907 e\\nEl administrador de un centro de datos se enfrenta al reto de decidir qu´ e servidor es m´ as adecuado\\npara la ejecuci´ on de una carga intensiva de CPU, el servidor A o el servidor B. Actualmente, el\\ntiempo medio para ejecutar la carga en el servidor es de 31,01 segundos. Para realizar una justa\\ncomparaci´ on, se ha ejecutado la carga intensiva de CPU en los servidores A y B un total de 10\\nveces, obteniendo los resultados mostrados a continuaci´ on.\\nTiempo de ejecuci´ on (s)\\nServidor A Servidor B\\n24,15 27,01\\n23,18 26,18\\n25,01 26,56\\n23,34 28,02\\n22,65 26,78\\n24,54 27,43\\n23,46 27,34\\n22,38 26,04\\n23,54 27,19\\n23,59 27,43\\nTiempo medio: 23,584 26,998\\n1', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 1}), Document(page_content='1. ¿Qu´ e servidor resulta m´ as adecuado para el cambio solamente considerando el\\nrendimiento? ¿Por qu´ e? ¿En qu´ e m´ etrica o valor determina la decisi´ on?\\nPara decidir que servidor es el m´ as adecuado con respecto al actual, tenemos que comprar la\\naceleraci´ on de los respectivos servidores.\\nA:TO\\nTA=31,01\\n23,584= 1,3149\\nB:TO\\nTB=31,01\\n26,998= 1,1490\\nFinalmente, podemos concluir que, considerando ´ unicamente el rendimiento, el servidor A ofrecer´ ıa\\nuna mayor mejora. Concretamente, el servidor A es aproximadamente 1,3149 veces m´ as r´ apido, o\\nun 31,49 % mejor, respecto al servidor original.\\n2. ¿Y si adem´ as tenemos en cuenta el coste del servidor? ¿Cu´ al ser´ ıa m´ as adecuado?\\n¿Por qu´ e? ¿En qu´ e m´ etrica o valor te basas?\\nSi ahora tenemos en cuenta el coste de dichos servidores, deberemos analizarlo con otro ´ ındice. En\\neste caso, si le damos m´ as importancia al coste del servidor, obtendremos los siguientes ´ ındices de\\ncada uno de ellos. En primer lugar, el ´ ındice del servidor A:\\nRatio−Rendimiento/Coste A=1\\nCoste A∗TA=1\\n1245e∗23,584s= 0,000034058 = 3 ,4058∗10−5\\nY, por otro lado, el ´ ındice del servidor B:\\nRatio−Rendimiento/Coste B=1\\nCoste B∗TB=1\\n907e∗26,998s= 0,000040838 = 4 ,0838∗10−5\\nAhora, si dividimos los ´ ındices\\nIndice B\\nIndice A=4,0838∗10−5\\n3,4058∗10−5= 1,2\\nPodemos observar que el servidor A es un 20 % m´ as rentable que el servidor B.\\n3. ¿C´ omo crees que afectan los recursos hardware de los servidores? ¿Tienen alg´ un\\ntipo de trascendencia en la decisi´ on?\\nEn efecto, los recursos hardware en los servidores son un factor importante a la hora de decidir si\\nun servidor es mejor o peor para el uso que le queramos dar\\nHabitualmente podemos pensar que la mejora de hardware en un servidor se manifestar´ a como\\nuna mejor lineal del rendimiento. Por ejemplo, si tenemos un servidor que ejecuta una carga en\\nun tiempo de ejecuci´ on tcon una mejora del hardware k, el tiempo de ejecuci´ on no ser´ at\\n2si la\\nmejora realizada es 2 k; esta mejora en funci´ on del tiempo no suele seguir una funci´ on lineal\\nEn conclusi´ on, la decisi´ on a tomar si tiene alg´ un tipo de transcendencia porque esta mejora de\\nrendimiento se tiene que ver compensada con el coste de dicha mejora.\\n2', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 2}), Document(page_content='Pr´ actica 2\\nPara la realizaci´ on de esta pr´ actica, el alumno ya contar´ a con el entorno Ubuntu (o el que ha-\\nya considerado) instalado, siendo totalmente funcional. Para asegurarnos de que el entorno est´ a\\ntotalmente listo, se deber´ a poder acceder al directorio /proc. Adem´ as, se contar´ a ya con una he-\\nrramienta para filtrar y limpiar los ficheros de datos como para realizar representaciones gr´ aficas.\\nEn esta pr´ actica no se tendr´ a en cuenta qu´ e tipo de actividad est´ a realizando el sistema mientras\\nse realiza la monitorizaci´ on del mismo. Antes de empezar a responder las diferentes partes, se\\nrecomienda probar los monitores, sus filtros, el volcado de ficheros y el tratamiento de los mismos.\\nMonitorizaci´ on de la CPU\\nEn esta primera parte, se pide monitorizar la CPU durante 1 hora haciendo uso del monitor TOP.\\nLos datos obtenidos ( ´UTILES) deber´ an ser guardados en un fichero de salida para posteriormente\\ntratarlos y responder a las siguientes preguntas:\\n1. ¿Cu´ antas CPUs tiene el sistema que se ha monitorizado? ¿De d´ onde se ha obtenido\\nesa informaci´ on?\\nEl sistema monitorizado tiene 8 CPUs dedicadas a soportar la carga del trabajo. Esta informaci´ on\\nse ha obtenido utilizando el comando que se muestra a continuaci´ on:\\nDonde claramente nos indica que el n´ umero de CPUs es 8.\\n2. ¿Cu´ al es la utilizaci´ on media de la CPU en modo usuario, sistema y en global?\\nPara obtener los datos que se nos pide, se ha monitorizado la CPU durante 1h con intervalos\\nde muestreo de 15 minutos. Se ha decidido tomar este intervalo para poder compararlo con los\\ndatos obtenidos de la monitorizaci´ on de la memoria principal. De esta forma mantendremos una\\nconsistencia en los datos presentados.\\nConcretamente, utilizaremos el monitor TOP para registrar los valores de la CPU del sistema, en\\nmodo usuario y la global. El comando concreto es el siguiente:\\n1 top -b -d 15 -n 242 | grep -i \"Cpu(s)\" > topCPU.txt\\n3', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 3}), Document(page_content=\"Podemos observar que en los par´ ametros le indicamos la frecuencia de muestreo en primer lugar y\\nel total de muestras a realizar, que equivalen a 1h. Observamos un aumento en dos unidades del\\ntotal de muestras a realizar; esto se debe a que la primera y la ´ ultima muestra las descartamos para\\nuna menor contaminaci´ on de los datos (esto se aplicara en todos los procesos de monitorizaci´ on\\nque se realicen). A continuaci´ on, con el comando grep indicamos los datos del comando TOP que\\nqueremos almacenar; en este caso los de la CPU. Todo ello transferido a un fichero de texto que\\npodremos consultar al final del proceso de monitorizaci´ on.\\nAhora necesitamos sacar la columna que nos interese en cada caso. Para ello utilizaremos el si-\\nguiente comando:\\n1 cat topCPU.txt | awk '{print $x}' > columnaX.txt\\nEl comando catnos permite coger el fichero deseado y meterlo en la terminal. A continuaci´ on con\\nel comando awkpodemos filtrar la columna que nos interese. En este caso, filtraremos por colum-\\nnas, donde xes el n´ umero de la columna que queramos almacenar. Concretamente nos interesan\\nlas columnas 2, 4 y 6, que son respectivamente la de usuario, de sistema y inactiva. Para obtener\\nla utilizaci´ on de CPU global se ha restado la inactiva a la total (en este caso 100 %). Finalmente\\nenviamos esta informaci´ on filtrada a un nuevo fichero para no sobreescribir el de origen.\\nCon todos estos datos a disposici´ on, podemos realizar las correspondientes medias utilizando una\\nhoja de Excel. Los resultados obtenidos son los siguientes:\\nMedias en %\\nCPU Global CPU Sistema CPU Usuario\\n0,17 0,02 0,12\\nCabe a˜ nadir que este proceso de filtrado por columna se llevara a cabo cuando sea necesario, sin\\nmencionarlo expl´ ıcitamente, en las pr´ oximas monitorizaciones.\\n3. ¿C´ omo se comportan las medidas anteriores a lo largo del tiempo de observaci´ on?\\nMuestra las tres m´ etricas de forma gr´ afica.\\nLas m´ etricas expuestas a continuaci´ on muestran un comportamiento similar entre ellas. Esto se\\ndebe a que en los primeros 15 minutos, se ha realizado alg´ un uso del sistema (aunque sea bajo)\\ny en el resto de tiempo este se encuentra pr´ acticamente inutilizado, ya que no realizaba ning´ un\\ntrabajo.\\nEs necesario comentar que los ejes Y de las gr´ aficas no tienen el mismo valor m´ aximo. Estos valores\\nson din´ amicos con el objetivo de poder observar con mayor detalle las gr´ aficas que tienen valores\\nm´ as peque˜ nos. En cambio, si se mantuviera un valor m´ aximo fijo e igual, alguna detalles de la\\ngr´ afica no podrian ser apreciados.\\n4\", metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 4}), Document(page_content='4. ¿Cu´ al es la sobrecarga provocada por el monitor TOP?\\nLa sobrecarga del monitor la obtendremos registrando la informaci´ on que nos devuelve el monitor\\nTIME cuando ejecutamos el monitor TOP para una ´ unica muestra.\\n1 time top -b -d 1 -n 1 | grep -i \"Cpu(s)\" > sobrecargaTOP.txt\\nPor tanto, obtendremos la sobrecarga dividiendo el tiempo real que tarda el monitor en realizar\\nuna muestra (obtenido con el monitor TIME), entre el tiempo de muestreo; como se muestra en\\nla siguiente f´ ormula:\\nSobrecarga =0,182s\\n15s∗100 = 1 ,21 %\\n5', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 5}), Document(page_content='Monitorizaci´ on de la memoria principal\\nEn esta segunda parte, se pide monitorizar la memoria principal del sistema durante 1 hora hacien-\\ndo uso del monitor VMSTAT con un intervalo de muestreo de 15 segundos. Los datos obtenidos\\n(´UTILES) deber´ an ser guardados en un fichero de salida para posteriormente tratarlos y responder\\na las siguientes preguntas:\\n1. ¿Qu´ e capacidad total tiene la memoria principal del sistema? ¿De d´ onde se ha\\nobtenido ese dato?\\nPara saber la capacidad total de memoria principal que tiene el sistema, utilizaremos monitor\\nTOP, que entre muchas cosas tambi´ en nos muestra la memoria total. Esto lo obtendremos con el\\nsiguiente comando:\\n1 top -b -d 1 -n 1 | grep -i \"KiB Mem\"\\nAl monitor TOP le asignamos unos par´ ametros, simplemente para que no este activo constante-\\nmente, y a continuaci´ on con el comando grep podemos extraer el valor de la memoria principal; el\\ncual nos dar´ a: 8074700 KiB .\\n2. ¿Cu´ al es la utilizaci´ on media de la memoria? ¿Y la capacidad media utilizada?\\nPara obtener los datos para realizar las respectivas medias, se ha monitorizado la memoria principal\\ndurante 1h en un intervalo de 15 segundos. Concretamente, utilizaremos el monitor VMSTAT para\\nregistrar los valores de la memoria libre. El comando concreto es el siguiente:\\n1 vmstat 15 242 -n > vmstatMEM.txt\\nUna vez recogidos todos los datos, podemos obtener la columna que nos informa del valor de la\\nmemoria libre del sistema realizando el siguiente comando, para efectuar el filtrado:\\n1 cat vmstatMEM.txt | awk \\'{print $4}\\' > MEMlibre.txt\\nFinalmente, en este ´ ultimo fichero tendremos todos los valores de memoria libre que ha registrado\\nel monitor. Para obtener la memoria utilizada, debemos restar al total de la memoria principal el\\nvalor de la memoria libre. Es con este valor con el que se ha calculado tanto la utilizaci´ on media\\ncomo la capacidad media utilizada de la memoria, utilizando una hoja de Excel. Los resultados\\nobtenidos son los siguientes:\\nUtilizaci´ on Media (KiB) Capacidad Media ( %)\\n3.806.916 47,15\\n6', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 6}), Document(page_content='3. ¿C´ omo se comporta la utilizaci´ on de la memoria y la capacidad utilizada? Repre-\\nsenta estas m´ etricas gr´ aficamente.\\nDurante el proceso de monitorizaci´ on, observamos dos picos en las gr´ aficas. Estos se deben a que\\nen los primeros minutos del proceso de monitorizaci´ on, estaban abiertas ciertas ventanas del gestor\\nde ficheros; adem´ as de realizarse algunos movimientos de ficheros entre directorios. El resto del\\ntiempo no se realiz´ o ning´ un trabajo concreto, por tanto, la carga de trabajo que vemos se deber´ a\\na los procesos internos del propio sistema operativo.\\n4. ¿Cu´ al es la sobrecarga provocada por el monitor VMSTAT?\\nPara obtener la sobrecarga del monitor, primero deberemos registrar el tiempo de ejecuci´ on del\\nmonitor VMSTAT; para luego dividirlo entre el tiempo de muestreo. Para lo comentado en primera\\ninstancia, utilizaremos el monitor TIME, el cual nos permitir´ a registrar el tiempo de ejecuci´ on del\\nmonitor TOP para una ´ unica muestra.\\n1 time vmstat 1 1 -n > sobrecarga_VMSTAT.txt\\nPor tanto, obtendremos la sobrecarga como se muestra en la siguiente f´ ormula:\\nSobrecarga =0,007s\\n15s∗100 = 0 ,05 %\\n7', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 7}), Document(page_content='Monitorizaci´ on de la CPU y de la memoria principal al mismo tiempo\\nSe desea monitorizar un sistema inform´ atico con el fin de conocer el comportamiento de la CPU\\ny la memoria principal. De la CPU se desea estudiar la utilizaci´ on en modo usuario, sistema y la\\nutilizaci´ on de forma global. Por otra parte, de la memoria principal se desea estudiar la capacidad\\ny la utilizaci´ on de la misma.\\n1. Determinar el monitor o monitores m´ as adecuados para obtener la informaci´ on\\nsolicitada.\\nLos monitores m´ as adecuados para obtener dicha informaci´ on son, por un lado, el TOP para\\nmonitorizar los valores de la CPU y el VMSTAT para la memoria principal.\\n2. Monitorizar el sistema durante 90 minutos, recogiendo la informaci´ on ´ util cada 30\\nsegundos. La informaci´ on ´ util deber´ a ser almacenada en un fichero de salida.\\nPara monitorizar el sistema se utilizar´ an los monitores comentados en el apartado anterior, ambos\\nejecutados a la vez, en terminales diferentes. Por un lado, el monitor TOP:\\n1 top -b -d 30 -n 182 | grep -i \"Cpu(s)\" > topCPU.txt\\nSus par´ ametros nos indica que la frecuencia de muestreo ser´ a cada 30 segundos y en total se rea-\\nlizaran 182 muestras. Todo ello almacenado en un fichero de texto de salida, para su posterior\\nfiltrado y tratado de datos.\\nEsto equivale a los 90 minutos exigidos en el enunciado. Aunque como siempre, realizamos dos\\nmuestras extras para descartar los extremos, con la finalidad de tener unos datos menos contami-\\nnados.\\nY, por otro lado, el monitor VMSTAT:\\n1 vmstat 30 182 -n > vmstatMEM.txt\\nEl cual tambi´ en vemos una semejanza con el monitor VMSTAT en cuanto a los par´ ametros es-\\ntablecidos. Toda la informaci´ on recogida, al igual que con el otro monitor, se almacenara en un\\nfichero de texto de salida para su posterior filtrado y tratado.\\n8', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 8}), Document(page_content='3. Calcular la media para la utilizaci´ on de la CPU en modo usuario, sistema y la\\nutilizaci´ on global. Tambi´ en, calcular la media para la capacidad y la utilizaci´ on de la\\nmemoria principal.\\nEn este apartado, con todo el trabajo realizado en los apartados anteriores, solo tendremos que\\nintroducir los datos en un Excel para calcular las medias. Los resultados son los que se muestran\\na continuaci´ on:\\nMedias\\nCPU Memoria Principal\\nGlobal Sistema Usuario Capacidad Utilizaci´ on\\n0,28 % 0,03 % 0,21 % 3.953.994 KiB 48,97 %\\n4. Graficar todos los resultados obtenidos durante los 90 minutos de monitorizaci´ on\\ndel sistema.\\nA continuaci´ on los datos graficados de la CPU:\\n9', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 9}), Document(page_content='Y aqu´ ı los datos de la memoria principal:\\n5. Calcular la sobrecarga que ejerce el monitor (o los monitores) sobre el sistema.\\nLa sobrecarga en este caso ser´ a la de los dos monitores a la vez. Esto es as´ ı porque tenemos dos\\nmonitores ejecut´ andose en paralelo, que consumir´ an recursos a la vez. Por tanto, la sobrecarga\\nfinal que ejercer´ an estos monitores sobre el sistema ser´ a la suma de ambos monitores.\\nVM TOP\\n0s 0,007s 0,182s 30s\\nCon esta imagen se intenta mostrar de forma gr´ afica el paralelismo de los monitores. Es por eso\\nque debemos realizar la suma de ambos, para obtener la sobrecarga total sobre el sistema.\\nPrimero calcularemos la sobrecarga que ejerce el monitor TOP:\\nSobrecarga =0,182s\\n30s∗100 = 0 ,6 %\\nY ahora la sobrecarga que ejerce el monitor VMSTAT:\\nSobrecarga =0,007s\\n30s∗100 = 0 ,02 %\\nFinalmente, nos queda esta sobrecarga:\\nSobrecarga =Sobrecarga TOP+Sobrecarga V MSTAT = 0,6 % + 0 ,02 % = 0 ,62 %\\n10', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 10}), Document(page_content='Pr´ actica 3\\nEn la pr´ actica 1 se presentaron los servidores A y B como alternativas al sistema actual. Adem´ as,\\nse afirm´ o que los dos servidores ejecutaban cargas de CPU, concretamente, el servidor A ejecuta la\\ncarga Sysbench CPU y el servidor B la carga Stress-ng. A continuaci´ on, se muestran los tiempos\\nde ejecuci´ on de cada servidor para determinadas configuraciones de carga y % de uso de la CPU:\\nTiempos de ejecuci´ on (s)\\nServidor A Servidor B\\nConfiguraci´ onCarga = 250000\\n% CPU = 50Carga = 300000\\n% CPU = 100\\nEjecuci´ on 1 24,15 27,01\\nEjecuci´ on 2 23,18 26,18\\nEjecuci´ on 3 25,01 26,56\\nEjecuci´ on 4 23,34 28,02\\nEjecuci´ on 5 22,65 26,78\\nEjecuci´ on 6 24,54 27,43\\nEjecuci´ on 7 23,46 27,34\\nEjecuci´ on 8 22,38 26,04\\nEjecuci´ on 9 23,54 27,19\\nEjecuci´ on 10 23,59 27,43\\nTiempo medio 23,584 26,998\\n11', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 11}), Document(page_content='Evaluaci´ on del sistema actual\\nPara la evaluaci´ on del sistema actual, se utilizar´ a la carga Sysbench CPU con un porcentaje de\\nuso de la CPU del 50 %, la cual se ejecutar´ a en el sistema actual y se har´ an uso de las t´ ecnicas\\nde monitorizaci´ on ya aprendidas en la pr´ actica anterior. De este modo, se pide responder a las\\nsiguientes preguntas.\\n1. Explica con detalle c´ omo es el dise˜ no y la implementaci´ on del experimento para\\nevaluar el sistema actual. Se deben justificar las decisiones tomadas, desde el n´ umero\\nde muestras que se van a tomar hasta qu´ e monitores se van a lazar y por qu´ e.\\nPara llevar a cabo el dise˜ no y la implementaci´ on de este experimento, se seguir´ a el siguiente\\ndiagrama que representa una metodolog´ ıa para el estudio del rendimiento de sistemas.\\n12', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 12}), Document(page_content='En primer lugar, el sistema que vamos a evaluar tiene las siguientes propiedades; todas ellas\\nobtenidas a trav´ es del comando lscpu u obtenidas de pr´ acticas anteriores:\\nPropiedas Sistema Actual\\nArquitectura 64 bits\\nCapacidad de memoria 8074700 KiB\\nProcesador Intel Core i5-8250U 1.6-3.4GHz\\nN´ umero de CPUs 8\\nA continuaci´ on definimos las cargas a ejecutar en el sistema actual. Estas ser´ an lanzadas con\\nel benchmark sysbench (centrado en la obtenci´ on de n´ umeros primos) y ser´ an de 25000, 50000,\\n100000, 150000 y 250000. Las cuatro primeras se ejecutar´ an porque b´ asicamente es lo que se nos\\npide en el enunciado y la ´ ultima ser´ a para, en los siguientes apartados, poder comparar el sistema\\nactual con uno de los propuestos; que se ha estresado con el mismo benchmark y con una carga de\\n250000. Tambi´ en se configurara el benchmark para que estrese el 50 % de la CPU, lo que quiere\\ndecir que estresara un total de 4 CPUs.\\nCon este conjunto de cargas podremos observar si al aumentar el n´ umero de n´ umeros primos a\\nbuscar, el tiempo de respuesta del sistema aumenta de forma lineal o no. Dependiendo de dichos\\nresultados, podremos afirmar que no hay la misma cantidad de n´ umeros primos entre los distintos\\nrangos, a pesar de ser una carga el doble que la otra.\\nPara realizar el experimento, se utilizar´ a el sysbench (como se ha comentado anteriormente) para\\nestresar la CPU y los monitores que recoger´ an las muestras necesarias son el top, para la CPU y\\nvmstat para la memoria. Para calcular la frecuencia de muestreo de los monitores, se ha ejecutado\\nunsysbench para cada carga mencionada anteriormente, para as´ ı obtener el tiempo que tarda\\ncada una. A continuaci´ on esta carga se ejecuta 5 veces para posteriormente hacer una media del\\ntiempo de respuesta resultante. Esto se realiza de esta forma para garantizar, estad´ ısticamente,\\nque esos tiempos de respuesta son realmente los que tardan cada carga (aunque para un estudio\\nreal se deber´ ıan hacer 10 o m´ as ejecuciones). Se ha decidido la frecuencia de muestreo en funci´ on\\ndel tiempo de respuesta m´ as bajo; en este caso el de la primera carga. A continuaci´ on los diferentes\\ntiempos de respuesta:\\nCarga Tiempo de respuesta (s) Ejecuciones Total (s)\\n25000 8 + 2 5 50\\n50000 20 + 2 5 110\\n100000 55 + 2 5 285\\n150000 100 + 2 5 510\\n250000 202 + 2 5 1020\\nSuma total: 1975\\nPodemos observar un tiempo a˜ nadido en cada carga de 2 segundos. Este es porque realizamos una\\nmonitorizaci´ on (tanto de la CPU como de la memoria) y en el script de monitorizaci´ on tenemos un\\nsleep de 2 segundos cada vez que acaba una ejecuci´ on de cualquier carga. Con esto conseguimos\\n13', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 13}), Document(page_content='saber cuando inicia y finaliza una ejecuci´ on de una carga por los picos que se producen en las\\ngr´ aficas. Por tanto, para saber cuantas veces deber´ an registrar los monitores el total de muestras,\\nse calcula dividiendo el tiempo total de respuesta entre la frecuencia de muestreo.\\nMuestras =1975\\n2= 988\\nDe todas formas, para realizar la monitorizaci´ on real, se han cogido algunas muestras extras por si\\nun caso alg´ un monitor tuviera alg´ un tipo de problema o para corregir el redondeo de los tiempos\\nde respuesta de cada carga obtenidos anteriormente. Una vez obtenidos todos estos par´ ametros,\\npodremos ejecutar los respectivos scripts que nos realizaran el trabajo de forma secuencial y au-\\ntom´ atica.\\nCabe mencionar que las condiciones del sistema actual han intentado ser las m´ as ´ optimas posibles.\\nSe ha mantenido el sistema con un 100 % de carga, enchufado a la corriente el´ ectrica y a tempera-\\ntura ambiente, durante todo el transcurso del experimento. Adem´ as, no se ha utilizado el sistema\\npara realizar ninguna otra tarea que no fuese ejecutar el respectivo benchmark o los monitores.\\n´Unicamente pod´ ıa haber procesos propios del sistema operativo de autogesti´ on en los cuales el\\nusuario no tiene acceso. Todo ello con el objetivo de conseguir unas muestras fiables y aptas para\\npoder comparar posteriormente con otros sistemas de la forma m´ as igualada posible.\\n2. ¿C´ omo se comporta el sistema actual si variamos la carga var´ ıa en 25000, 50000,\\n100000 y 150000 n´ umeros primos? ¿C´ omo es el comportamiento del tiempo de respues-\\nta y la productividad? Indica el valor para cada una de las ejecuciones del experimento\\ny la media entre todos ellas.\\nSi variamos la carga entre los valores expuestos, el sistema se va a comportar de la misma forma,\\ncomo vemos en las gr´ aficas generales a continuaci´ on:\\nEn la primera observamos la utilizaci´ on de CPU que se mantiene al 50 %, como era de esperar.\\nAl lanzar un benchmark que estresa este componente al 50 %, lo esperado es que durante todas\\nlas cargas el tanto por ciento de CPU sea ese. Cabe mencionar que se nos pide observar como\\n14', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 14}), Document(page_content='se comporta el sistema en cada carga, pero en las gr´ aficas se muestra el conjunto de ellas. El\\nobjetivo es poder visualizar con mayor perspectiva y no mostrar tantas representaciones gr´ aficas\\nque podr´ ıan dificultar el entendimiento de los datos recogidos. Por tanto, con esta representaci´ on\\npodemos apreciar las diferentes ejecuciones y/o cargas y sus respectivos valles.\\nPor otro lado, por lo que hace a la memoria, tambi´ en se ha representado con una perspectiva global\\nde todas las cargas. Apreciamos que dicha memoria se mantiene pr´ acticamente igual durante el\\ntranscurso del experimento. De hecho, era lo esperado, ya que las cargas inyectadas (b´ usquedas\\nde n´ umeros primos) no intervienen en dicha memoria y, por tanto, su uso solo se debe a lo que el\\npropio sistema necesita para estar funcionando.\\nA continuaci´ on los valores obtenidos de cada carga tanto de los tiempos de respuesta como de la\\nproductividad:\\nCarga Tiempo de respuesta (s) Productividad (W/T)\\n25000 8 3333\\n50000 20 2500\\n100000 55 1818\\n150000 100 1500\\n250000 202 1238\\nMedias 77 1822\\nSeguidamente los gr´ aficos respectivos:\\nEl tiempo de respuesta, como podemos observar en los valores obtenidos, tiende subir de forma\\nbastante pronunciada. Por otro lado, la productividad tiende a bajar a medida que la carga au-\\nmenta. Esto nos indica que a un mayor n´ umero de cargas, el sistema tiende a tardar m´ as y a ser\\nmenos productivo; pero no sigue una tendencia lineal. Esto se debe realmente a que cada vez nos\\nencontramos con un menor n´ umero de n´ umeros primos. Adem´ as de que al no tener ”memoria”, ca-\\nda vez que aumentamos la carga, el sistema debe recorrer los n´ umeros primos que ya ha recorrido.\\n15', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 15}), Document(page_content='3. ¿Cu´ al es el porcentaje de CPU y de memoria del sistema para cada una de las\\ncargas ejecutadas? ¿Por qu´ e se produce ese comportamiento? Mu´ estralo gr´ aficamente\\na lo largo del tiempo de ejecuci´ on de la carga.\\nA continuaci´ on las respectivas gr´ aficas de la utilizaci´ on de CPU de cada carga:\\n16', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 16}), Document(page_content='Seguidamente, las gr´ aficas de la capacidad de memoria utilizada:\\nComo observamos, tanto en la CPU como en la memoria, los valores se mantienen igual. Esto,\\ncomo se ha comentado durante el experimento, es lo esperado; ya que el sysbench estresa el 50 %\\nde la CPU y la memoria no se utiliza para realizar la b´ usqueda de n´ umeros primos.\\n17', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 17}), Document(page_content='Comparaci´ on del sistema actual con el servidor A y B\\nPara la comparaci´ on del sistema actual con los servidores A y B se har´ an uso de los datos propor-\\ncionados anteriormente en la tabla. Se deber´ a aplicar la t´ ecnica de benchmarking para realizar la\\ncomparaci´ on teniendo en cuenta la carga que ejecuta cada uno de los servidores, as´ ı como su nivel\\nde uso de los recursos de CPU. Adem´ as, se deber´ an contestar las siguientes cuestiones.\\n1. Explica detalladamente c´ omo se va a realizar el proceso de benchmarking. Se de-\\nber´ an justificar todas las decisiones que se han tomado al respecto.\\nPara llevar a cabo el dise˜ no y la implementaci´ on de este experimento, se seguir´ a el diagrama\\nexpuesto en el apartado anterior.\\nEl sistema actual tiene las propiedades representadas en la tabla del apartado anterior y la carga\\nejecutada con el benchmark stress ser´ a de 300000. Esta carga se ejecutar´ a 5 veces para garantizar\\nque los datos obtenidos son lo m´ as realista posibles. Para ello, se utilizar´ an los scripts mencionados\\nal principio del experimento y que se podr´ an encontrar al final de esta documentaci´ on. En este\\ncaso, el benchmark stress ser´ a configurado para estresar el 100 % de las CPUs, que corresponde a\\nun total de 8.\\nPor lo que hace a los monitores, se utilizaran los mismos que en el apartado anterior, el toppara\\nmonitorizar el estado de la CPU y el vmstat para hacer lo respectivo con la memoria. Estos\\nmonitores tienen como par´ ametros la frecuencia de muestreo y el total de ejecuciones que deber´ ıa\\nhacer el monitor. Como la carga tarda aproximadamente 238s en ejecutarse por completo, ejecutar\\n5 veces dicha carga m´ as un sleep de 2s entre ejecuciones, nos deja un tiempo total de 1200s; lo\\ncual equivale a 600 muestras. De todas formas, como es habitual, recogeremos algunas muestras\\nm´ as con el monitor para corregir el redondeo de los tiempos de respuesta obtenidos.\\nPor lo que hace a las condiciones del sistema actual, se han buscado las condiciones ´ optimas para\\nrealizar el experimento con la mayor objetividad posible. Se ha mantenido el sistema a un 100 % de\\ncarga y conectado a la red el´ ectrica durante toda la prueba. Adem´ as, no se ha utilizado el sistema\\npara realizar ninguna otra tarea que no fuera ejecutar el benchmark y los monitores. ´Unicamente\\nse han podido ejecutar procesos propios del sistema operativo, necesarios para mantenerlo activo.\\n18', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 18}), Document(page_content='2. Considerando solamente el rendimiento de los servidores, ¿cambiar´ ıas el sistema\\nactual por el servidor A? ¿Y por el B? ¿Por qu´ e?\\nSi tenemos en cuenta ´ unicamente el rendimiento de ambos sistemas, entonces deberemos comparar\\nlas respectivas productividades:\\nXA=Trabajo\\nTiempo=250000 W\\n23,584s= 10600 W/s\\nXB=Trabajo\\nTiempo=300000 W\\n26,998s= 11112 W/s\\nXActual −Sysbench =Trabajo\\nTiempo=250000 W\\n202s= 1237 W/s\\nXActual −Stress =Trabajo\\nTiempo=300000 W\\n237,41s= 1263 W/s\\nObservamos claramente como ambos servidores son mejores que el sistema actual. Cabe recordar\\nque no ser´ ıa una comparaci´ on justa decir que el Servidor B tiene una mejor productividad que el\\nServidor A, ya que ambos han sido estresados con benchmarks distintos, totalmente diferentes.\\nSi ahora nos disponemos a hacer las respectivas aceleraciones:\\nAA−Actual =XA\\nXActual −Sysbench=10600\\n1237= 8,57\\nAB−Actual =XB\\nXActual −Stress=11112\\n1263= 8,8\\nEntonces podemos afirmar que ambos servidores son, aproximadamente, 8 veces mejor que el\\nsistema actual. Y, por tanto, realizar el cambio del sistema actual por ambos servidores ser´ ıa una\\ndecisi´ on acertada.\\n3. Si adem´ as consideramos el coste econ´ omico, ¿cambiar´ ıas el sistema actual por el\\nservidor A? ¿Y por el B? ¿Por qu´ e?\\nEn primer lugar, debemos calcular el rendimiento que hemos sacado sobre el dinero invertido en\\ncada sistema. Esto se calcular´ a dividiendo la productividad entre el coste de cada uno.\\nRendimiento −Coste A=XA\\nCoste A=10600\\n1245e= 8,51\\nRendimiento −Coste B=XB\\nCoste B=11112\\n907e= 12,25\\n19', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 19}), Document(page_content='Rendimiento −Coste Actual −Sysbench =XActual\\nCoste Actual=1237\\n700e= 1,77\\nRendimiento −Coste Actual −Stress =XAcual\\nCoste Actual=1263\\n700e= 1,8\\nAunque la forma habitual de calcular el rendimiento coste sea:\\nX=1\\nRendimiento ×Coste\\ncreo que calculando las productividades, el ´ ındice resultante es m´ as visual. De todas formas, ambos\\nc´ alculos son linealmente y dar´ ıan resultados proporcionales.\\nSi ahora nos disponemos a calcular las respectivas aceleraciones:\\nAA−Actual =Rendimiento −Coste A\\nRendimiento −Coste Actual −Sysbench=8,51\\n1,77= 4,8\\nAB−Actual =Rendimiento −Coste B\\nRendimiento −Coste Actual −Stress=12,25\\n1,8= 6,8\\nPor tanto, podemos observar que el servidor A es 4,8 y el servidor B 6,8 veces mejor en lo que se\\nrefiere al rendimiento sacado sobre la inversi´ on realizada, que el sistema actual. Por tanto, realizar\\nun cambio de cualquiera de los servidores por el sistema actual, ser´ ıa una decisi´ on totalmente\\nacertada.\\n4. ¿C´ omo influye la carga ejecutada en los servidores A y B en la decisi´ on de cambio?\\nEn primer lugar, hay que diferenciar entre los benmchmarks ejecutados en cada servidor. Por un\\nlado, el sysbench realiza una b´ usqueda de n´ umeros primos entre 0 y la carga inyectada (por ejemplo\\n25000). Y en este caso, al no haber una proporci´ on entre el n´ umero de n´ umeros primos que hay\\nentre dos valores, a mayor carga el tiempo de respuesta no aumenta linealmente. Por otro lado, el\\nstress realiza diferentes operaciones con enteros, n´ umeros en coma flotante, pruebas del registro 0\\ndel procesador, entre otras. La gran diferencia es que dichas operaciones si muestran una tendencia\\nlineal cuando la carga varia.\\nEn conclusi´ on, la carga ejecutada en los servidores si influye en la decisi´ on de cambio; todo depen-\\nder´ a del objetivo con el que queramos adquirir un sistema. Si comparamos, respectivamente, cada\\nservidor con el sistema actual, entonces podemos afirmar con total seguridad que los servidores\\nson mejores. Pero no podemos asegurar que el servidor B sea mejor o peor que el A realizando\\nb´ usquedas de n´ umeros primos, o viceversa con los diferentes tipos de operaciones.\\n20', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 20}), Document(page_content='Scripts\\nA continuaci´ on el script que ejecuta los distintos monitores:\\n1#!/bin/bash\\n2\\n3if [ -z \"$1\" ]; then # Check monitor\\n4 echo \"Define a valid moitor <top, vm>\"\\n5 exit 1\\n6else\\n7 case $1 in\\n8 help)\\n9 echo \"Usage: mon <top vm> <delay> <messures>\"\\n10 exit 1\\n11 ;;\\n12 top);;\\n13 vm) ;;\\n14 *)\\n15 echo \"Define a valid moitor <top, vm>\"\\n16 exit 1\\n17 ;;\\n18 esac\\n19fi\\n20\\n21if [ -z \"$2\" ]; then # Check delay\\n22 echo \"Define a delay\"\\n23 exit 1\\n24else\\n25\\n26 if [ \"$2\" -lt 1 ]; then # delay < 1\\n27 echo \"Define a valid range of delay. d > 1\"\\n28 exit 1\\n29 fi\\n30fi\\n31\\n32if [ -z \"$3\" ]; then # Check messures\\n33 echo \"Define the number of messures\"\\n34 exit 1\\n35else\\n36 if [ \"$3\" -lt 1 ]; then # messures < 1\\n37 echo \"Define a valid range of messures. n > 1\"\\n38 exit 1\\n39 fi\\n40fi\\n21', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 21}), Document(page_content='41\\n42# Correct syntax\\n43mkdir \"./monitor\" > /dev/null 2>&1\\n44echo \"=== Starting monitor ===\"\\n45\\n46printf \"Work in process... \"\\n47case $1 in\\n48 top)\\n49 top -b -d \"$2\" -n \"$3\" | grep \"%Cpu(s):\" > tempCPU\\n50\\n51 sed -i \\'s/ni,100.0/ni, 100.0/g\\' tempCPU # Add space to nice\\ntime. Avoid bug with awk ,→\\n52 awk \\'{print $2, $4, $8}\\' tempCPU > \"./monitor/TOP.txt\" # Data\\nfiltering ,→\\n53 rm tempCPU\\n54 ;;#break\\n55\\n56 vm)\\n57 vmstat \"$2\" \"$3\" -n >tempVM\\n58\\n59 sed -i \\'1,2d\\' tempVM # Remove first and second line (header)\\n60 awk \\'{print $4}\\' tempVM > \"./monitor/VM.txt\"\\n61 rm tempVM\\n62 ;;#break\\n63esac\\n64\\n65echo \"Done\"\\n22', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 22}), Document(page_content='A continuaci´ on el script que ejecuta los distintos benchmarks:\\n1#!/bin/bash\\n2\\n3case $1 in\\n4 help)\\n5 echo \"Usage: bench <sysbench stress> <number cpus> <number\\niterations>\" ,→\\n6 exit 1;\\n7 ;;\\n8 sysbench) ;;\\n9 stress) ;;\\n10 *)\\n11 echo \"Define a valid monitor <sysbench stress>\"\\n12 exit 1\\n13 ;;\\n14esac\\n15\\n16if [ -z \"$2\" ]\\n17then # Check number of cpus\\n18 echo \"Define the number of cpus\"\\n19 exit 1\\n20else\\n21 if [ \"$2\" -lt 1 ]\\n22 then # Number of cpus < 1\\n23 echo \"Define a valid number of cpus\"\\n24 exit 1\\n25 fi\\n26fi\\n27\\n28if [ -z \"$3\" ]\\n29then # Check number of iterations\\n30 echo \"Define the number of iterations\"\\n31 exit 1\\n32else\\n33 if [ \"$3\" -lt 1 ]\\n34 then # Number of iterations < 1\\n35 echo \"Define a valid number of iterations n > 1\"\\n36 exit 1\\n37 fi\\n38fi\\n39\\n40\\n41\\n23', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 23}), Document(page_content='42for i in 25000 50000 100000 150000 250000\\n43do\\n44 echo \"=== Start workload $i ===\"\\n45 j=1\\n46\\n47 while [ \"$j\" -le \"$3\" ]; do\\n48 echo \"$1 iteration $j...\"\\n49\\n50 case $1 in\\n51 sysbench)\\n52 sysbench --test=cpu --cpu-max-prime=\"$i\"\\n--num-threads=\"$2\" run ,→\\n53 ;;# Break\\n54\\n55 stress)\\n56 stress-ng --cpu=\"$2\" --cpu-ops=\"$i\"\\n57 ;;# Break\\n58 esac\\n59\\n60 echo \"Done\"\\n61 j=$((j + 1))\\n62\\n63 sleep 2\\n64 done\\n65 echo \"\"\\n66done\\n* Cabe remarcar que en caso de querer usar otras cargas, se deber´ an modificar desde el script.\\n24', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 24}), Document(page_content='Pr´ actica 4\\nBloque 1\\nSe pide responder las siguientes cuestiones:\\n1. ¿Cu´ al es la principal diferencia entre la evaluaci´ on de sistemas mediante la experi-\\nmentaci´ on real y el modelado?\\nLa principal diferencia es que con la primera estamos trabajando con un sistema real y con la\\nsegunda con uno “inventado”. En consecuencia, el sistema real no sigue ninguna funci´ on (ya que\\nel sistema puede experimentar diferentes actividades no esperadas) y el modelo si, es por eso que\\nnunca va a fallar (independientement del sistema real).\\n2. ¿Qu´ e relaci´ on hay entre ellas?\\nLa relaci´ on es que podemos trabajar sobre ambas para realizar los c´ alculos necesarios para la im-\\nplementaci´ on de un sistema cualquiera. Es decir, el modelo nos podria servir para inyectar posibles\\ncargas reales y poder evaluar como se comporta el sistema. Por otro lado, la experimentaci´ on real\\nayuda a mejorar el modelo que tenemos.\\n3. ¿C´ omo podr´ ıamos combinar ambas formas de evaluaci´ on? Explica detalladamente\\nc´ omo podr´ ıamos combinarlas con un ejemplo de la vida real.\\nAmbas formas deber´ ıan combinarse. B´ asicamente, porque el objetivo de los modelos es recrear\\nde manera ficticia la realidad; con el objetivo de estresar al sistema con ese modelo y observar si\\nsoportar´ ıa una situaci´ on real similar. Aunque debemos ser conscientes de que el modelo es algo\\ninventado y, por tanto, la realidad siempre puede sorprendernos. En consecuencia, tener un modelo\\nes necesario para predecir (en la medida de lo posible) lo que nuestro sistema deber´ a soportar.\\nPara entenderlo mejor, el ejemplo del servidor es muy claro. Tenemos un servidor que anualmente\\nrecibe una serie de peticiones (por ejemplo registros de matr´ ıculas de una universidad) que suelen\\nser similares, a˜ no tras a˜ no. Entonces, el administrador del sistema puede recrear un modelo con\\nlos datos obtenidos del mismo sistema (o datos externos, como por ejemplo el n´ umero de personas\\nque ha aprobado selectividad en la misma zona) y testear el servidor para ver si soportara la carga.\\nA partir de all´ ı ya seria decisi´ on del administrador si los resultados obtenidos son fiables o no para\\nafrontar el siguiente periodo de matr´ ıculas.\\n25', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 25}), Document(page_content='Bloque 2\\nConsideremos la carga Stress-ng ejecutada en la pr´ actica 3. En concreto, el que es ejecutado al\\n100 % de uso de la CPU. De la ejecuci´ on de esta carga se obtuvo un tiempo medio de respuesta.\\nAdem´ as, ahora se concreta que el tiempo medio de ejecuci´ on es de 1,23 segundos. Tambi´ en, la\\nCPU recibe una media de dos programas por segundo (del tipo Stress-ng).\\nSe pide calcular:\\n1. Utilizaci´ on media del procesador.\\nSi aplicamos la hip´ otesis de equilibrio de flujo, entonces podemos aplicar la Ley de la Utilizaci´ on.\\nEn este caso, al recibir la CPU 2 trabajos por segundo, nuestra λ= 2. Adem´ as, nuestro tiempo\\nmedio de ejecuci´ on es de 1,23s, como se indica en el enunciado. Por tanto, la utilizaci´ on se calcular´ ıa\\nde la siguiente forma:\\nU=X×S=λ×S= 2×1,23 = 2 ,46≃246 %\\nComo la utilizaci´ on es mayor al 100 % entonces podemos deducir que el sistema est´ a saturado y,\\npor tanto, es seguro que si no ha colapsado, colapsara en cualquier momento. Entonces, para que\\nel sistema tenga una utilizaci´ on del 100 %, necesitar´ ıamos reducir el tiempo de servicio a 0,5s o\\nbajar la productividad a 0,813 trabajos/s.\\n2. Tiempo medio de espera en la cola del procesador.\\nEl tiempo de espera, es aquel en el cual un trabajo se encuentra en la cola de trabajos para ser\\nservido. Este se puede calcular si restamos al tiempo total, el tiempo de ejecuci´ on. Por tanto, el\\nresultado se calcular´ ıa de la siguiente forma:\\nWi=Ri−Si= 26,998s−1,23s= 25,768s\\n3. N´ umero medio de programas en la cola de espera del procesador.\\nPara calcular el n´ umero medio de trabajo en la cola de espera, podemos aplicar la Ley de Little\\na la misma cola. La productividad del procesador es la misma que la de la cola y el tiempo de\\nrespuesta es el tiempo de espera en cola calculador en el apartado anterior. Por tanto, se calcula\\nde la siguiente forma:\\nN=X×R= 2trabajos/s ×25,768s= 51,536trabajos\\n26', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 26}), Document(page_content='Pr´ actica 5\\nBloque 1\\nEsta pr´ actica consiste en implementar y verificar el correcto funcionamiento del algoritmo del valor\\nmedio para resolver redes cerradas (MVA). El algoritmo se puede entrar en la p´ agina 136 del libro\\nde la asignatura. Tambi´ en, se pueden hacer uso de los ejercicios resueltos en el libro para comprobar\\nque el algoritmo funciona correctamente.\\nAdem´ as, se deber´ an mostrar gr´ aficamente el valor de las variables Ri, R, X, N iyUien funci´ on del\\nn´ umero de clientes que hay en el sistema. Se deber´ a entregar:\\n1. Implementaci´ on del algoritmo en el lenguaje que el alumno considere m´ as oportuno.\\nEl c´ odigo implementado se ha adjuntado al final de esta pr´ actica. Es un script en Python que\\ncalcula el algoritmo del valor medio para resolver redes cerradas y adem´ as, genera los gr´ aficos\\ncorrespondientes.\\n2. Un documento donde se reflejen tres ejemplos usados para verificar el buen funcio-\\nnamiento del algoritmo.\\nSe han realizado tres experimentos para verificar el buen funcionamiento del algoritmo. A conti-\\nnuaci´ on se muestran las condiciones y los resultados de los mismos.\\n27', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 27}), Document(page_content='Experimento 1\\nEn este experimento se han introducido un tiempo de reflexi´ on de 5 segundos y un total de 5\\ntrabajos. Adem´ as, las razones de visita y los tiempos de servicio de cada dispositivo son 15 y 0,03s\\npara el dispositivo 0 y 14 y 0,5s para el dispositivo 1, respectivamente.\\nTrabajos R (s) X (trabajos/s)\\n1 7.45 0.0803\\n2 11.402 0.1219\\n3 16.8098 0.1376\\n4 23.2072 0.1418\\n5 30.0414 0.1427\\nTrabajos Dispositivo Ri (s) Xi (trabajos/s) Ni (trabajos) Ui ( %)\\n0 0.03 1.2048 0.0361 0.036111 0.5 1.1245 0.5622 0.5622\\n0 0.0311 1.829 0.0569 0.054921 0.7811 1.7071 1.3335 0.8536\\n0 0.0317 2.0633 0.0654 0.061931 1.1667 1.9257 2.2468 0.9629\\n0 0.032 2.1271 0.068 0.063841 1.6234 1.9853 3.223 0.9927\\n0 0.032 2.1403 0.0686 0.064251 2.1115 1.9976 4.218 0.9988\\n28', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 28}), Document(page_content='Experimento 2\\nEn este experimento se han introducido un tiempo de reflexi´ on de 8 segundos y un total de 10\\ntrabajos. Adem´ as, las razones de visita y los tiempos de servicio de cada dispositivo son 8 y 0,03s\\npara el dispositivo 0 y 7 y 0,1s para el dispositivo 1, respectivamente.\\nTrabajos R (s) X (trabajos/s)\\n1 0.94 0.1119\\n2 1.0013 0.2222\\n3 1.0705 0.3307\\n4 1.1493 0.4372\\n5 1.2394 0.5412\\n6 1.343 0.6422\\n7 1.4626 0.7398\\n8 1.6013 0.8332\\n9 1.7628 0.9219\\n10 1.9511 1.0049\\nTrabajos Dispositivo Ri (s) Xi (trabajos/s) Ni (trabajos) Ui ( %)\\n0 0.03 0.8949 0.0268 0.026811 0.1 0.783 0.0783 0.0783\\n0 0.0308 1.7775 0.0548 0.053321 0.1078 1.5553 0.1677 0.1555\\n0 0.0316 2.6459 0.0837 0.079431 0.1168 2.3152 0.2703 0.2315\\n0 0.0325 3.4975 0.1137 0.104941 0.127 3.0603 0.3888 0.306\\n0 0.0334 4.3293 0.1446 0.129951 0.1389 3.7881 0.5261 0.3788\\n0 0.0343 5.1376 0.1764 0.154161 0.1526 4.4954 0.686 0.4495\\n0 0.0353 5.9181 0.2089 0.177571 0.1686 5.1783 0.8731 0.5178\\n0 0.0363 6.6658 0.2417 0.281 0.1873 5.8326 1.0925 0.5833\\n0 0.0373 7.375 0.2747 0.221291 0.2092 6.4531 1.3503 0.6453\\n0 0.0382 8.0393 0.3074 0.2412101 0.235 7.0344 1.6533 0.7034\\n29', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 29}), Document(page_content='Experimento 3\\nEn este experimento se han introducido un tiempo de reflexi´ on de 8 segundos y un total de 10\\ntrabajos. Adem´ as, las razones de visita y los tiempos de servicio de cada dispositivo son 8 y 0,03s\\npara el dispositivo 0, 7 y 0,1s para el dispositivo 1 y 16 y 0.15s para el dispositivo 2, respectivamente.\\nTrabajos R (s) X (trabajos/s)\\n1 3.34 0.0882\\n2 3.8962 0.1681\\n3 4.6107 0.2379\\n4 5.5256 0.2957\\n5 6.6816 0.3406\\n6 8.1065 0.3725\\n7 9.8026 0.3932\\n8 11.7407 0.4053\\n9 13.8674 0.4116\\n10 16.1217 0.4146\\nTrabajos Dispositivo Ri (s) Xi (trabajos/s) Ni (trabajos) Ui ( %)\\n0 0.03 0.7055 0.0212 0.0212\\n1 0.1 0.6173 0.0617 0.0617 1\\n2 0.15 1.4109 0.2116 0.2116\\n0 0.0306 1.345 0.0412 0.0403\\n1 0.1062 1.1768 0.1249 0.1177 2\\n2 0.1817 2.6899 0.4889 0.4035\\n0 0.0312 1.9031 0.0594 0.0571\\n1 0.1125 1.6653 0.1873 0.1665 3\\n2 0.2233 3.8063 0.8501 0.5709\\n0 0.0318 2.3659 0.0752 0.071\\n1 0.1187 2.0702 0.2458 0.207 4\\n2 0.2775 4.7318 1.3131 0.7098\\n0 0.0323 2.7245 0.0879 0.0817\\n1 0.1246 2.3839 0.297 0.2384 5\\n2 0.347 5.449 1.8906 0.8174\\n0 0.0326 2.9802 0.0973 0.0894\\n1 0.1297 2.6076 0.3382 0.2608 6\\n2 0.4336 5.9603 2.5844 0.894\\n0 0.0329 3.1456 0.1035 0.0944\\n1 0.1338 2.7524 0.3683 0.2752 7\\n2 0.5377 6.2912 3.3825 0.9437\\n30', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 30}), Document(page_content='0 0.0331 3.242 0.1073 0.0973\\n1 0.1368 2.8368 0.3882 0.2837 8\\n2 0.6574 6.4841 4.2625 0.9726\\n0 0.0332 3.2926 0.1094 0.0988\\n1 0.1388 2.881 0.3999 0.2881 9\\n2 0.7894 6.5851 5.1981 0.9878\\n0 0.0333 3.3165 0.1104 0.0995\\n1 0.14 2.902 0.4063 0.2902 10\\n2 0.9297 6.633 6.1669 0.995\\nN´ otese que en las tablas de los diferentes experimentos, el dispositivo 0, tiene como resultado\\nvalores bastante inferiores con respecto al dispositivo 0. Esto se debe a que el tiempo de servicio\\ndel primer dispositivo es mucho menor que del segundo, la cual cosa veremos reflejada en las\\ngr´ aficas a continuaci´ on.\\nCon todos estos experimentos, tendremos diferentes datos para poder observar el comportamiento\\ndel algoritmo. En el siguiente apartado se proceder´ a a graficar y analizarlos.\\n31', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 31}), Document(page_content='3. A˜ nadir a la documentaci´ on la representaci´ on gr´ afica de las variables calculadas y\\nuna discusi´ on sobre su comportamiento.\\nExperimento 1\\nEn primer lugar, podemos observar que el tiempo de respuesta muestra una tendencia lineal a\\nlargo plazo. Por tanto, podemos decir que a mayor n´ umero de trabajos, proporcionalmente el\\nsistema tendr´ a un tiempo de respuesta mayor. Por otro lado, la productividad tiene una tendencia\\nlogar´ ıtmica, la cual nos muestra a partir de cuantos trabajos el sistema queda estancado. Si nos\\nfijamos, a partir de 4 trabajos, el sistema ya se estanca en cuanto a productividad; pero realmente\\nsolo ha llegado a aproximadamente 0.14 trabajos/s. Eso nos indicia que alg´ un dispositivo hace de\\ncuello de botella.\\nEn este caso, como se ha comentado en el apartado anterior, observamos que los valores del\\ndispositivo 0 en algunas gr´ aficas, no se pueden apreciar del todo. De todos modos, es m´ as interesante\\ncomparar los distintos valores entre dispositivos, con el objetivo de visualizar cu´ al est´ a teniendo\\nm´ as o menos carga de trabajo. Es por eso que las tendencias del dispositivo 0 ser´ an similares\\na las del dispositivo 1. Adem´ as, los resultados que nos pueda ofrecer un sistema al monitorizar\\nlos dispositivos, ser´ a similar a como est´ an graficados ahora. Procedemos ahora si, a comentar su\\ncomportamiento.\\n32', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 32}), Document(page_content='En primer lugar, observamos que el tiempo de respuesta del dispositivo 1 es mucho mayor (debido\\na los valores del tiempo de servicio de ambos) y parece mostrar una tendencia lineal relativamente\\nsuave. Esto nos indica que de primeras, con un n´ umero de trabajos bajos, la productividad es alta,\\npero a la larga se acaba estancando (a partir de 3) y a cuantos m´ as trabajos, proporcionalmente\\ntardara m´ as tiempo. Estas suposiciones se afirman observando la gr´ afica de la productividad, que\\na partir de 3 trabajos, el sistema empieza a observar un cuello de botella. Comentar adem´ as, que\\nes curioso como el dispositivo 0 es m´ as productivo que el 1, la cual cosa a simple vista no nos\\nlo parece. En consecuencia, es muy seguro que en las siguientes graficamos veamos como en las\\nrespectivas utilizaciones de los dispositivos, el 1 es el que nos perjudica el rendimiento general del\\nsistema.\\nAqu´ ı podemos ver como el n´ umero de trabajos que se van acumulando en la estaci´ on de cada\\ndispositivo, aumenta linealmente. Esto se debe a que la llegada de trabajos tambi´ en es lineal.\\nPor otro lado, la utilizaci´ on de los dispositivos es distinta. El dispositivo 1 llega a su punto de\\nsaturaci´ on a partir del trabajo 4, es decir, a su m´ axima utilizaci´ on. En cambio, el dispositivo 0\\ntambi´ en se estanca entre el trabajo 3 y 4, pero no pasa de un 10 % de utilizaci´ on. Esto se debe a\\nque el dispositivo 1 tiene una mayor carga de trabajo y, por tanto, una mayor demanda de servicio;\\nes por eso que podr´ ıamos decir que se trata del cuello de botella dels sistema.\\n33', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 33}), Document(page_content='Experimento 2\\nEn este caso, el tiempo de respuesta del sistema tiene una tendencia exponencial. Esto significa\\nque a mayor n´ umero de trabajos, el tiempo de respuesta es cada vez mayor (por tanto, peor que\\nen el anterior experimento). Por otro lado, la productividad muestra una tendencia logar´ ıtmica,\\naunque no muy marcada. Podr´ ıamos deducir que a largo plazo se llegar´ ıa a estancar; pero con los\\ndatos recogidos no podemos deducir ese valor. En consecuencia, el sistema tiene a´ un tiene margen\\npara soportar una mayor carga.\\nEn este caso, los dispositivos se comportan muy diferente por lo que se refiere a su tiempo de\\nrespuesta. El dispositivo 0 tiene una tendencia lineal y, sin embargo, el dispositivo 1 la tiene\\nexponencial. Esto significa que el dispositivo 0, a un mayor n´ umero de trabajos, tiene un menor\\ntiempo de respuesta y en consecuencia es m´ as r´ apido. Esto se ve reflejado en la gr´ afica de las\\nproductividades. Claramente, el dispositivo 0 realiza m´ as trabajos por segundo que el dispositivo 1.\\nAmbas no muestran una tendencia clara, pero por lo que nos dice la experiencia, si la calcul´ aramos\\ncon un n´ umero mayor de trabajos, resultar´ ıa ser una tendencia logar´ ıtmica.\\n34', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 34}), Document(page_content='En este caso, nos encontramos que el dispositivo 1 tambi´ en muestra peores resultados en estas\\ngr´ aficas. Por un lado, la tendencia de trabajos que se van acumulando en la estaci´ on es exponencial,\\nfrente a la lineal del dispositivo 0. Por otro lado, las dos utilizaciones muestran la misma tendencia,\\npero la del dispositivo 1 aumenta mucho m´ as r´ apido en el eje de las ordenadas.\\nEntonces podemos concluir que en este experimento, ambos dispositivos tienen margen para recibir\\nm´ as carga de trabajo; ya que ninguno se encuentra saturado. Por consiguiente, el sistema tambien\\ntiene margen para recibir m´ as trabajo.\\n35', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 35}), Document(page_content='Experimento 3\\nEn este experimento, el tiempo de respuesta tambi´ en es exponencial, y todo lo que ello conlle-\\nva (comentado en el experimento anterior). Adem´ as, la productividad del sistema muestra una\\ntendencia logar´ ıtmica y a partir de los 10 trabajos aproximadamente, el sistema se estanca. Esto\\nquiere decir que algunos de los dispositivos es nuestro cuello de botella.\\nN´ otese que en estas gr´ aficas hemos realizado el experimento con tres dispositivos, a diferencia de\\nlos otros que eran con dos. En este caso, por lo que hace al tiempo de respuesta, el dispositivo 0 y\\n1 tienen una tendencia similar. Sin embargo, el dispositivo 2 muestra una tendencia exponencial,\\npor tanto, tiene un tiempo de respuesta mucho mayor que los otros. En consecuencia, con los\\nmismos trabajos, emplear´ a mucho m´ as tiempo que los otros dispositivos. Como siempre, esto se\\nve reflejado en la productividad del sistema. Sin embargo, por lo que hace a la productividad, el\\ndispositvo 2 muestra una diferencia notoria entre los otros dispostivos. Por mucho que el tiempo\\nde respuesta del dispositvo 2 sea mucho mayor, su productividad sigue siendo mucho mejor que la\\nde los otros dispositivos y esto se ver´ a reflejado en la producitividad del sistema.\\n36', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 36}), Document(page_content='El dispositivo 2 muestra un mayor numero de trabajos en la estaci´ on en funci´ on del tiempo, frente\\na los otros dispisitivos. Concretamente, tiene una tendencia que primeramente parece exponencial\\npero se consigue fijar como una tendencia lineal (a un numero mayor de trabajos). Por otro lado,\\nla utilizaci´ on sigue la misma tendencia logaritmica en en todos los dispositivos, pero claramente\\nla del dispositivo 2 llega practicmante al 100 % y por ende seria el cuello de botella del sistema.\\n37', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 37}), Document(page_content='Bloque 2 (Opcional)\\nDada la l´ ınea 11 del metro de Barcelona, la cual consta de 5 paradas, se pide modelar el sistema\\nde transporte haciendo uso de la teor´ ıa de colas y responder a las siguientes preguntas:\\nLa informaci´ on necesaria para responder a las preguntas es:\\nFrecuencia de llegada de pasajeros a cada estaci´ on: 20 pasajeros / minuto\\nFrecuencia de llegada del metro en cada estaci´ on: 1 metro / 3 minutos\\nTiempo medio del recorrido entre estaciones: 1 minuto\\nProbabilidad de un pasajero de bajarse: 40\\nTiempo medio de permanencia de un metro en la estaci´ on: 30 segundos\\nPara realizar esta parte de la pr´ actica, se ha llevado a cabo un modelo de una posible soluci´ on del\\nproblema propuesto. El modelo en cuesti´ on es el siguiente:\\nEn este modelo, modelamos dos colas de forma recursiva (para todas las estaciones del metro).\\nLa primera cola ser´ ıa una cola abierta, que representar´ ıa la llegada de personas a la estaci´ on de\\nmetro; y su servicio ser´ ıa entrar dentro del vag´ on del metro. Por otro lado, tenemos la cola que\\nmodela los trenes del metro, concretamente el trayecto que estos siguen. Como la red de metros es\\nuna red cerrada, la respectiva cola tambi´ en lo ser´ a y su servicio ser´ ıa el tiempo que tarda en hacer\\nun trayecto de una estaci´ on a otra.\\nPor tanto, con los datos que se no facilitan, podemos deducir las siguientes equivalencias:\\nFrecuencia de llegadas de pasajeros a cada estaci´ on = λPersonas\\nFrecuencia de llegada del metro en cada estaci´ on = λMetro\\nTiempo del recorrido entre estaciones = STrayecto\\nTiempo medio de permamencia de un metro en la estaci´ on = SMetro =WTrayecto\\n38', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 38}), Document(page_content='Ahora entonces, con el modelo hecho y teniendo claro que es cada cosa, podemos proceder a resolver\\nlas siguientes cuestiones.\\n1. ¿Cu´ anto tiempo tarda un metro en recorrer la l´ ınea?\\nSiguiendo el modelo anterior, el tiempo que tarda en recorrer el metro la l´ ınea ser´ ıa equivalente\\nal tiempo de respuesta de la cola cerrada que representa el trayecto. El tiempo de servicio nos lo\\ndan, es 1 minuto, y el tiempo de espera ser´ a el tiempo de servicio de la cola anterior, es decir, 30\\nsegundos. Por tanto, el tiempo de respuesta se puede resolver de la siguiente forma:\\nRTrayecto =SMetro +STrayecto =WTrayecto +STrayecto = 30s+ 1min = 1,5min\\n2. ¿Cu´ al es la probabilidad de llegar a la estaci´ on y encontrarse un metro? ¿Y qu´ e no\\nhaya?\\nEn este caso entendemos que la probabilidad de que un cliente encuentre un metro en la estaci´ on,\\nser´ ıa equivalente a cuando el metro est´ a siendo utilizado.\\nPMetro =UMetro =λMetro∗SMetro =1\\n180trabajos/s ∗30s=1\\n6= 0,1667\\nPor tanto, la probabilidad de llegar y encontrarse un metro es de un 16,67 %. En consecuencia, la\\nprobabilidad de no encontrarselo seria 1 −0,1667 = 0 ,8333, es decir, un 83,33 %.\\n3. ¿Cu´ al es la frecuencia de llegadas m´ axima que soporta el sistema?\\nLa frecuencia m´ axima que soportara el sistema ser´ a la frecuencia m´ axima que soporte la segunda\\ncola; ya que realmente el cuello de botella del sistema es el trayecto que realizan los metros. En\\neste caso, se rige por la siguiente f´ ormula:\\nλmax=1\\nDb\\nPero para caluclar la Dbnecesitamos saber las razones de visita del dispositivo. En este caso es\\n1, ya que las v´ ıas del tren solo pueden llevar un metro. Entonces, la ecuaci´ on se resolver´ a de la\\nsiguiente forma:\\nλmax=1\\nDb=1\\nV∗S=1\\n1∗30= 0,0333\\nPor tanto, la mayor frecuencia de metros/segundo que soportara el sistema ser´ a de 0,0333, es decir,\\naproximadamente 120 metros cada hora.\\n39', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 39}), Document(page_content='Scripts\\nA continuaci´ on el script implementado:\\n1import csv\\n2import matplotlib.pyplot as plt\\n3\\n4# Leemos el fichero con los datos\\n5with open(\"data.txt\", \"r\") as f:\\n6 csv_reader = list(csv.reader(f, delimiter=\" \"))\\n7\\n8# Eliminamos la cabecera de las columnas\\n9csv_reader.pop(0)\\n10\\n11# Declaramos la raz´ on de visita y el tiempo de servicio\\n12V = []\\n13S = []\\n14\\n15# Almacenamos los datos del fichero en los arrays correspondientes\\n16for i in range(len(csv_reader)):\\n17 V.append(float(csv_reader[i][0]))\\n18 S.append(float(csv_reader[i][1]))\\n19\\n20dispositivos = len(V)\\n21\\n22# Array bidimensional que contendra los resultados obtenidos\\n23resultados_sistema = []\\n24resultados_dispositivos = []\\n25\\n26# Almacenamos el input del usuario\\n27N = int(input(\"Introduce el n´ umero de trabajos: \"))\\n28Z = int(input(\"Introduce el tiempo de reflexi´ on: \"))\\n29\\n30\\n31def __main__():\\n32 \"\"\" Algoritmo para el an´ alisis del valor medio para redes de colas\\ncerradas\"\"\" ,→\\n33\\n34 # Para todos los trabajos\\n35 for n in range(1, N + 1):\\n36 print(f\"----- Job {n}-----\")\\n37\\n38\\n39\\n40', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 40}), Document(page_content='40 # Calculamos el tiempo de respuesta y la productividad del sistema\\n41 R = formatear(calcularR(n))\\n42 X = formatear(calcularX(n))\\n43\\n44 resultados_sistema.append([n, R, X])\\n45\\n46 # Para todos los dispositivos\\n47 for i in range(dispositivos):\\n48 Ri = formatear(calcularRi(n, i))\\n49 Xi = formatear(calcularXi(n, i))\\n50 Ni = formatear(calcularNi(n, i))\\n51 Ui = formatear(calcularUi(n, i))\\n52\\n53 resultados_dispositivos.append([i, Ri, Xi, Ni, Ui])\\n54\\n55 # Almacenamos los resultados del sistema en un fichero\\n56 with open(\"resultados_sistema.txt\", \"w\") as f:\\n57 write = csv.writer(f)\\n58 write.writerows(resultados_sistema)\\n59\\n60 # Almacenamos los resultados de los dispositivos en un fichero\\n61 with open(\"resultados_dispositivos.txt\", \"w\") as f:\\n62 write = csv.writer(f)\\n63 write.writerows(resultados_dispositivos)\\n64\\n65 # Almacenamos los valores del eje x para todas las graficas\\n66 j = 0\\n67 eje_x = [fila[j] for fila in resultados_sistema]\\n68\\n69 # Almacenamos las cabeceras de los valores del eje y\\n70 cabeceras = [\\n71 \"Tiempo de respuesta (s)\",\\n72 \"Productividad (trabajos/s)\"]\\n73\\n74 cabeceras_i = [\\n75 \"Tiempo de respuesta (s)\",\\n76 \"Productividad (trabajos/s)\",\\n77 \"Trabajos en la estaci´ on\",\\n78 \"Utilizaci´ on (%)\"]\\n79\\n80 # Graficamos los resultados del sistema\\n81 for i in range(len(cabeceras)):\\n82 plt.figure()\\n83\\n41', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 41}), Document(page_content='84 # Obtenemos los valores del eje y\\n85 eje_y = [fila[i + 1] for fila in resultados_sistema]\\n86\\n87 # Graficamos los resultados\\n88 plt.plot(eje_x, eje_y, marker = \\'o\\', markersize = 3)\\n89\\n90 # A~ nadimos las etiquetas\\n91 plt.xlabel(\"Trabajos\")\\n92 plt.ylabel(f\" {cabeceras[i] }\")\\n93 plt.title(f\" {cabeceras[i] }del sistema\")\\n94 plt.savefig(f\"grafica_sistema_ {i}.png\")\\n95\\n96 # Graficamos los resultados de los dispositivos\\n97 for i in range(len(cabeceras_i)):\\n98 plt.figure()\\n99\\n100 # Obtenemos los valores del eje y de cada dispositivo\\n101 for j in range(dispositivos):\\n102 eje_y = [fila[i + 1] for fila in resultados_dispositivos if fila[0]\\n== j] ,→\\n103\\n104 # Graficamos los resultados\\n105 plt.plot(eje_x, eje_y, label=f\"Dispositivo {j}\", marker = \\'o\\',\\nmarkersize = 3) ,→\\n106\\n107 # A~ nadimos las etiquetas\\n108 plt.xlabel(\"Trabajos\")\\n109 plt.ylabel(f\" {cabeceras_i[i] }\")\\n110 plt.title(f\" {cabeceras_i[i] }de los dispositivos\")\\n111 plt.legend(loc=\\'upper left\\')\\n112 plt.savefig(f\"grafica_ {i}.png\")\\n113\\n114# Funci´ on para formatear los resultados\\n115def formatear(x):\\n116 return float((\\' %.4f \\' % x).rstrip(\\'0\\').rstrip(\\'.\\'))\\n117\\n118# Funci´ on para calcular el tiempo de respuesta\\n119def calcularR(n):\\n120 return sum(V[i] * calcularRi(n, i) for i in range(dispositivos))\\n121\\n122# Funci´ on para calcular la productividad del sistema\\n123def calcularX(n):\\n124 return n / (Z + calcularR(n))\\n125\\n42', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 42}), Document(page_content=\"126# Funci´ on para calcular la productividad de un dispositivo\\n127def calcularXi(n, i):\\n128 return calcularX(n) * V[i]\\n129\\n130# Funci´ on para calcular el n´ umero de trabajos de un dispositivo\\n131def calcularNi(n, i):\\n132 return (calcularX(n) * V[i] * calcularRi(n, i) if n != 0 else 0)\\n133\\n134# Funci´ on para calcular el tiempo de respuesta de un dispositivo\\n135def calcularRi(n, i):\\n136 return (calcularNi(n - 1, i) + 1) * S[i]\\n137\\n138# Funci´ on para calcular la utilizaci´ on de un dispositivo\\n139def calcularUi(n, i):\\n140 return calcularX(n) * V[i] * S[i]\\n141\\n142\\n143if __name__ == '__main__':\\n144 __main__()\\n43\", metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 43}), Document(page_content='Pr´ actica 6\\nEl objetivo de esta pr´ actica es la comprensi´ on del concepto de caracterizaci´ on de la carga. Para\\nello, se har´ a uso de la herramienta Weka.\\nDe la monitorizaci´ on de un sistema de almacenamiento, se proporciona un fichero de datos llamado\\ndata.txt. En el fichero se almacenan tres columnas con la siguiente informaci´ on:\\nEl tama˜ no del fichero accedido (en MB). Los valores que correspondan con “-1” quieren decir\\nque el acceso al fichero ha fallado.\\nLa hora a la que se hizo el acceso. El valor 22 representan las 22h, el valor 01 representan\\nlas 1h (a.m.), etc.\\nEl ancho de banda consumido (en MS/s). Los valores de esta columna est´ an entre 453 y\\n1355, por lo tanto, los valores de esta columna deber´ an ser tratados. Es decir, el valor crudo\\nde “1258.84,”, corresponde con “1258,84”.\\nCon los datos proporcionados se pide caracterizar la carga haciendo uso del algoritmo de K-Means\\ny responder a las siguientes preguntas:\\nPara realizar el correcto filtrado de los datos del fichero, se ha realizado el script para que el\\nsoftware Weka pueda interpretar de forma correcta los datos; queda adjunto al final de la pr´ actica.\\n44', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 44}), Document(page_content='1. Aplicando el algoritmo con 100 iteraciones y agrupando los datos en 3 clases, ¿qu´ e\\nresultados se obtienen? Mu´ estralo gr´ aficamente.\\nEn primer lugar, se llev´ o a cabo la implementaci´ on de un script (opcional) que, teniendo como\\ninput los datos ofrecidos por el Weka, genera una gr´ afica en tres dimensiones (ya que dispon´ ıamos\\nde 3 variables) para obtener una correcta visualizaci´ on de las proyecciones de los datos.\\nEntonces, al visualizar esta gr´ afica, r´ apidamente nos damos cuenta de que la informaci´ on que\\nnos da es un tanto extra˜ na. Es posible esperar otro tipo de agrupamientos, pero analiz´ andolo\\ndetalladamente, nos percatamos de que esto se debe a que el eje del Time (h) no nos est´ a dando\\nninguna informaci´ on relevante. Al no tener datos de todo el d´ ıa, dicha variable no nos es del todo\\n´ util y, por tanto, se puede despreciar. Es por ello que ahora si podemos graficar los resultados\\nconforme a la gr´ afica siguiente; la cual representa, en dos dimensiones, el tama˜ no frente a la\\nvelocidad de transferencia.\\n45', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 45}), Document(page_content='Observamos ahora que el Weka nos agrupa los datos en tres grupos (como se le hab´ ıa pedido)\\nproporcionalmente iguales. Sin embargo, no tenemos una nube de puntos, la gr´ afica sigue un\\ncomportamiento conocido como o heavy-tailed distribution . Este comportamiento representa una\\ngran cantidad de valores pr´ oximos al punto cero de la gr´ afica y conforme avanza la gr´ afica se va\\nreduciendo de forma dr´ astica el n´ umero de valores. Esto nos puede hacer pensar que el sistema de\\nalmacenamiento mueve muchos m´ as ficheros de un tama˜ no peque˜ no que de tama˜ nos m´ as grandes.\\nEs obvio ya que los sistemas operativos suelen contener una multitud de ficheros de configuraci´ on\\no de registros, que suelen pesar bastante poco. Y claramente son ficheros que se van actualizando\\nconstantemente.\\n46', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 46}), Document(page_content='2. Con el mismo n´ umero de iteraciones y agrupando los datos en 5 clases, ¿qu´ e resul-\\ntados se obtienen? ¿C´ omo difieren de los anteriormente obtenidos?\\nAqu´ ı tambi´ en se realiz´ o la representaci´ on en tres dimensiones. Pero como se puede presuponer\\n(viendo los resultados anteriores) tampoco nos va a dar la informaci´ on de una forma ´ util para\\nanalizarla. Por tanto, tambi´ en se han realizado los mismos pasos que en el apartado anterior y se\\nha representado en dos dimensiones directamente.\\nVemos que sigue el mismo patr´ on que en apartado anterior. Es decir, observamos el mayor n´ umero\\nde transferencias de ficheros, son los que ocupan menos y a medida que el tama˜ no aumenta, se\\nrealizan menos transferencias. La ´ unica diferencia palpable es que el Weka ha realizado cinco\\ncl´ usteres en vez de tres.\\n3. ¿Hay alguna caracter´ ıstica especial en la carga proporcionada? Expl´ ıcala con detalle.\\nS´ ı, encontramos unas cuantas. En primer lugar, es un poco extra˜ no que el agrupamiento de los datos\\npor cl´ uster no sea una nube de puntos, como se hab´ ıa visto en las clases te´ oricas. De hecho, dicho\\nagrupamiento ha sido bastante igualado entre cl´ usteres. Esto nos indica que los datos introducidos\\nen el Weka tal vez no eran los correctos, para lo que finalmente quer´ ıamos observar y exige una\\ncomprensi´ on extra por parte del analista para darse cuenta de qu´ e est´ a pasando. En segundo lugar,\\nobservamos que los cl´ usteres se dividen en tres columnas (aunque podr´ ıan ser dos, dependiendo\\ndel zoom que hagamos o lo concretos que queramos ser), la cual cosa sorprende. Esto est´ a ligado\\ncon la tercera caracter´ ıstica especial, que es el porqu´ e se generan estas columnas en los gr´ aficos.\\nComo se ha comentado un poco anteriormente, parece ser que los datos siguen una distribuci´ on de\\ncola pesada (o heavy-tailed distribution ). Este tipo de distribuciones se caracteriza por concentrar\\nla mayor parte de los datos en los valores m´ as cercanos al cero y van disminuyendo a medida que\\naumenta el eje de las abscisas. A continuaci´ on un ejemplo de dicha distribuci´ on.\\n47', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 47}), Document(page_content='Heavy-Tailed Distribution\\nEn este ejemplo, la curva que representar´ ıa m´ as la tendencia que siguen nuestros datos ser´ ıa la\\nde color azul. Si nos imagin´ aramos que los ejes tuvieran los mismos nombres que en las gr´ aficas\\n(de dos dimensiones) anteriores, entonces ver´ ıamos claramente que se concentran la mayor´ ıa de\\nficheros al principio del gr´ afico.\\nFinalmente, comentar que para tener una mejor representaci´ on (y en consecuencia un mejor an´ ali-\\nsis) de los cl´ usteres, se deber´ ıa hacer un trabajo previo de agrupaci´ on cualitativa en funci´ on del\\ntama˜ no de los ficheros. Esto nos permitir´ ıa realizar un cl´ uster de cada agrupaci´ on de datos (en\\neste caso posiblemente serian 3) y seguramente el Weka nos mostrar´ ıa unos cl´ usteres mucho m´ as\\ninteresantes que los que nos ha mostrado hasta ahora.\\n48', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 48}), Document(page_content='Scripts\\nA continuaci´ on el script de filtrado de los datos que nos genera un archivo .arff de Weka:\\n1import argparse\\n2\\n3parser = argparse.ArgumentParser()\\n4parser.add_argument(\"-i\", \"--input\", help=\"Input file\",\\n5 default=\"data.in\", type=str)\\n6parser.add_argument(\\'-c\\', \"--csv\", help=\"csv format?\",\\n7 action=argparse.BooleanOptionalAction)\\n8args = parser.parse_args()\\n9\\n10def main():\\n11 with open(args.input) as file:\\n12 data = file.read().splitlines()\\n13\\n14 # Remove header\\n15 data.pop(0)\\n16 with open(f\"data. {\\'csv\\' if args.csv else \\'arff\\' }\", \"x\") as output:\\n17 if args.csv:\\n18 output.write(\"size,hour,MB/s\\\\n\")\\n19 else:\\n20 output.write(\"@relation data-server\\\\n\\\\n\")\\n21 output.write(\"@attribute SIZE numeric\\\\n\")\\n22 output.write(\"@attribute HOUR numeric\\\\n\")\\n23 output.write(\"@attribute MBS numeric \\\\n\")\\n24 output.write(\"\\\\n@data\\\\n\\\\n\")\\n25\\n26 for line in data:\\n27 line = line.split(\",\")\\n28\\n29 # Remove first -1\\n30 if line[0] == \"-1\":\\n31 continue\\n32\\n33 # Remove last part\\n34 try:\\n35 line.pop(2)\\n36 except:\\n37 pass\\n38\\n39 # Split values\\n40 try:\\n49', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 49}), Document(page_content='41 temp = line[1].split(\"\\\\t\")\\n42 except:\\n43 print(line)\\n44\\n45 line[1] = temp[0]\\n46\\n47 # Refractor numbers\\n48 line.append(fractor_number(temp[1]))\\n49\\n50 output.write(f\" {line[0] },{line[1] },{line[2] }\\\\n\")\\n51\\n52def fractor_number(number):\\n53 temp = number.split(\".\")\\n54\\n55 if len(temp) == 3:\\n56 return f\" {temp[0] } {temp[1] }.{temp[2] }\"\\n57 else:\\n58 return number\\n59\\n60if __name__ == \"__main__\":\\n61 main()\\n50', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 50}), Document(page_content='A continuaci´ on el script que nos permite representar tantos clusters como genere el Weka, en tres\\ndimensiones:\\n1import argparse\\n2import matplotlib.pyplot as plt\\n3import numpy as np\\n4\\n5colors = (\"r\", \"g\", \"b\")\\n6\\n7parser = argparse.ArgumentParser()\\n8parser.add_argument(\"-c\", \"--cluster\", help=\"Select cluster number\",\\n9 default=3, type=int)\\n10args = parser.parse_args()\\n11\\n12\\n13def main():\\n14 # Get number of clusters from keyboard input\\n15 num_clusters = args.cluster\\n16\\n17 plt.figure()\\n18 ax = plt.axes(projection=\\'3d\\')\\n19\\n20 # Get cluster data and make a scatter plot\\n21 for i in range(num_clusters):\\n22 x_norm, y_norm, z_norm = get_cluster_norm_values(i)\\n23 ax.scatter3D(x_norm, y_norm, z_norm,\\n24 label=f\"Cluster {i}\", c=colors[i], marker=\"o\")\\n25\\n26 # Plot data\\n27 ax.set_title(\\n28 f\"Representation of {args.cluster }clusters | K-Means Clustering with\\nEuclidean Distance\") ,→\\n29 ax.set_xlabel(\\'Size (MB)\\')\\n30 ax.set_ylabel(\\'Time (h)\\')\\n31 ax.set_zlabel(\\'Speed (MB/s)\\')\\n32 ax.legend(bbox_to_anchor=(1.05, 1), ncol=num_clusters)\\n33 plt.savefig(\"cube.png\")\\n34\\n35\\n36def get_cluster_norm_values(value):\\n37 with open(\"cluster.arff\", \"r\") as file:\\n38 data = file.read().splitlines()\\n39\\n40 # Remove header\\n51', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 51}), Document(page_content='41 data = data[9:]\\n42\\n43 # Create an array with the cluster data\\n44 cluster_value = []\\n45 for line in data:\\n46 line = line.split(\\',\\')\\n47 if line[4] == f\"cluster {value }\":\\n48 cluster_value.append([line[1], line[2], line[3]])\\n49\\n50 # Create diferent arrays for each axis\\n51 cluster_x = [float(x[0]) for x in cluster_value]\\n52 cluster_y = [float(x[1]) for x in cluster_value]\\n53 cluster_z = [float(x[2]) for x in cluster_value]\\n54\\n55 # Get min and max values\\n56 x_mn = [np.min(cluster_x), np.max(cluster_x)]\\n57 y_mn = [np.min(cluster_y), np.max(cluster_y)]\\n58 z_mn = [np.min(cluster_z), np.max(cluster_z)]\\n59\\n60 # Normalize data\\n61 x_norm = [normalize(data, x_mn[0], x_mn[1]) for data in cluster_x]\\n62 y_norm = [normalize(data, y_mn[0], y_mn[1]) for data in cluster_y]\\n63 z_norm = [normalize(data, z_mn[0], z_mn[1]) for data in cluster_z]\\n64\\n65 # Return a tuple\\n66 return x_norm, y_norm, z_norm\\n67\\n68\\n69def normalize(value, min, max):\\n70 return (value - min) / (max - min)\\n71\\n72\\n73if __name__ == \"__main__\":\\n74 main()\\n52', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 52}), Document(page_content='A continuaci´ on el script que nos permite representar tantos clusters como genere el Weka, en dos\\ndimensiones:\\n1import argparse\\n2import matplotlib.pyplot as plt\\n3\\n4colors = (\"red\", \"green\", \"blue\", \"yellow\", \"purple\")\\n5\\n6parser = argparse.ArgumentParser()\\n7parser.add_argument(\"-c\", \"--cluster\", help=\"Select cluster number\",\\n8 default=0, type=int)\\n9args = parser.parse_args()\\n10\\n11# Get number of clusters from keyboard input\\n12num_clusters = args.cluster\\n13\\n14\\n15def main():\\n16 plt.figure()\\n17 plt.rcParams.update({\"font.family\": \"serif\"})\\n18\\n19 # Get cluster data and make a scatter plot\\n20 for i in range(num_clusters):\\n21 x_norm, y_norm = get_cluster_norm_values(i)\\n22 plt.plot(x_norm, y_norm, \\'o\\', color=colors[i], markersize=3,\\nlabel=f\"Cluster {i}\") ,→\\n23\\n24 # Plot data\\n25 plt.xlabel(\"Tama~ no (MB)\")\\n26 plt.ylabel(\"Velocidad (MB/s)\")\\n27 plt.title(\\n28 f\"K-Means Algorithm with Euclidean Distance of {num_clusters }\\nclusters\") ,→\\n29 plt.legend(loc=\"upper right\")\\n30 plt.savefig(f\"cluster_ {num_clusters }.png\")\\n31\\n32\\n33def get_cluster_norm_values(value):\\n34 with open(f\"cluster {num_clusters }.arff\", \"r\") as file:\\n35 data = file.read().splitlines()\\n36\\n37 # Remove header\\n38 data = data[8:]\\n39\\n53', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 53}), Document(page_content='40 # Create an array with the cluster data\\n41 cluster_value = []\\n42 for line in data:\\n43 line = line.split(\\',\\')\\n44 if line[4] == f\"cluster {value }\":\\n45 cluster_value.append([line[1], line[3]])\\n46\\n47 # Create diferent arrays for each axis\\n48 cluster_x = [float(x[0]) for x in cluster_value]\\n49 cluster_y = [float(x[1]) for x in cluster_value]\\n50\\n51 # Return a tuple\\n52 return cluster_x, cluster_y\\n53\\n54\\n55def normalize(value, min, max):\\n56 return (value - min) / (max - min)\\n57\\n58\\n59if __name__ == \"__main__\":\\n60 main()\\n54', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 54}), Document(page_content='Pr´ actica 7\\nUna empresa de almacenamiento en la nube monitoriza la actividad de sus usuarios, es decir, se\\nguarda la hora de acceso del cliente, el tama˜ no del fichero al que se ha accedido y la cantidad de\\ninformaci´ on transmitida por unidad de tiempo (hacer uso de los datos de la pr´ actica 6).\\nEl director del departamento de inform´ atica de la empresa solicita calcular la cantidad de infor-\\nmaci´ on transmitida por la red y el tama˜ no del fichero accedido para las 6 a.m. (recordar que la\\n´ ultima hora monitorizada son las 5 a.m.).\\n1. ¿Qu´ e patr´ on siguen los datos monitorizados? Proporciona una representaci´ on gr´ afica.\\n2. Calcula los valores solicitados para las 6 a.m. haciendo uso de la regresi´ on lineal, medias\\nm´ oviles (usar los 4 ´ ultimos valores) y suavizado exponencial (peso fijo del 60 %).\\n3. ¿Qu´ e t´ ecnica de predicci´ on funciona mejor? ¿Por qu´ e? ¿Cu´ al es la m´ as adecuada para los\\ndatos con los que contamos?\\nComentar que para la realizaci´ on de esta pr´ actica se ha implementado un script que realiza todos\\nlos c´ alculos necesarios. Este se encuentra adjunto al final del documento.\\n55', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 55}), Document(page_content='1. ¿Qu´ e patr´ on siguen los datos monitorizados? Proporciona una representaci´ on gr´ afi-\\nca.\\nPor lo que hace al tama˜ no de los ficheros, podemos observar dos grupos de datos. Por un lado,\\nlos referentes al rango de horas entre las 22 y las 23, donde el sistema trabaja con ficheros de un\\ntama˜ no relativamente peque˜ no. Sin embargo, el segundo grupo, referente al rango de horas entre la\\n1 y las 5 de la ma˜ nana, el sistema trabaja con ficheros de un tama˜ no mucho mayor. Esto suele ser\\nhabitual en los sistemas (tipo servidores) que, durante las horas de la noche, realizan los trabajos\\nm´ as pesados. Esto se hace as´ ı porque si se hicieran de d´ ıa (mientras el usuario tambi´ en hace uso\\ndel sistema) los usuarios podr´ ıan ser los perjudicados.\\nPor otro lado, tenemos la velocidad a la cual se transfieren dichos ficheros. N´ otese que pr´ acticamente\\ndurante toda la monitorizaci´ on del sistema, este transfiere los archivos lo m´ as r´ apido que puede, ya\\nque pr´ acticamente es el mismo valor en todo el eje x. Observamos, pero, una bajada importante a\\nlas 23h. Esto podr´ ıa ser por el cambio de pasar a trabajar con ficheros de tama˜ no considerablemente\\nmayor; ya que si nos fijamos en la gr´ afica anterior, dicho cambio se efect´ ua sobre la misma hora.\\n56', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 56}), Document(page_content='2. Calcula los valores solicitados para las 6 a.m. haciendo uso de la regresi´ on lineal,\\nmedias m´ oviles (usar los 4 ´ ultimos valores) y suavizado exponencial (peso fijo del\\n60 %).\\nC´ alculos para el Tama˜ no\\nPara construir la recta que representara la regresion lineal se rige por la ecuaci´ on de la recta\\ny=a+bx, donde\\nb=nX\\ni=1xi×yi−n×¯x×¯y\\nnX\\ni=1x2\\ni−n×¯x2\\na= ¯y−b×¯x\\nEntonces, nos quedarian los siguientes resultados:\\ny= 3669 ,2544 + 236 ,6961x\\n¯x= 4\\n¯y= 4379 ,3427\\nY por tanto, la prediccion de la hora 6 seria:\\ny= 3669 ,2544 + 236 ,6961∗(8) = 5562 ,8232MB\\n57', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 57}), Document(page_content='Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=yt+yt−1+...+yt−n+1\\nn\\nDonde ft+1es la predicci´ on, ytnson los valores del eje y que queremos utilizar para realizar la\\nprediccion y nque es el n´ umero de ytque cojamos. Por tanto, la operaci´ on para calcular la sexta\\nhora (con los ´ ultimos cuatro valores) es el siguiente:\\nf6=4881,8906 + 4949 ,225 + 4611 ,4016 + 4775 ,2293\\n4= 4804 ,4366MB\\n58', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 58}), Document(page_content='Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=ft+α(yt+1−ft)\\nEl cual se tendra que aplicar para cada valor de y. En este caso aplicaremos un α= 0,6:\\nHora Media del tama˜ no (MB) Predicci´ on\\n1 3443.8934 3443.8934\\n2 3546.7858 3505.2288\\n3 4447.9735 4070.8756\\n4 4881.8906 4557.4846\\n5 4949.225 4792.5288\\n6 4611.4016 4683.8524\\n7 4775.2293 4738.6785\\nY, por tanto, el valor que le corresponde a la hora 6 es, 4738.6785 MB.\\n59', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 59}), Document(page_content='C´ alculos para la Velocidad\\nPara construir la recta que representara la regresion lineal se rige por la ecuaci´ on de la recta\\ny=a+bx, donde\\nb=nX\\ni=1xi×yi−n×¯x×¯y\\nnX\\ni=1x2\\ni−n×¯x2\\na= ¯y−b×¯x\\nEntonces, nos quedarian los siguientes resultados:\\ny= 817 ,4075 + 1 ,1535x\\n¯x= 4\\n¯y= 820 ,8680\\nY por tanto, la prediccion de la hora 6 seria:\\ny= 817 ,4075 + 1 ,1535∗(8) = 826 ,6355MBps\\n60', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 60}), Document(page_content='Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=yt+yt−1+...+yt−n+1\\nn\\nDonde ft+1es la predicci´ on, ytnson los valores del eje y que queremos utilizar para realizar la\\nprediccion y nque es el n´ umero de ytque cojamos. Por tanto, la operaci´ on para calcular la sexta\\nhora (con los ´ ultimos cuatro valores) es el siguiente:\\nf6=823,8627 + 822 ,9925 + 822 ,4515 + 823 ,3838\\n4= 823 ,1726MBps\\n61', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 61}), Document(page_content='Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=ft+α(yt+1−ft)\\nEl cual se tendra que aplicar para cada valor de y. En este caso aplicaremos un α= 0,6:\\nHora Media del tama˜ no (MB) Predicci´ on\\n1 822.5798 822.5798\\n2 807.7088 813.6572\\n3 823.3496 819.4726\\n4 823.8627 822.1066\\n5 822.9925 822.6381\\n6 822.4515 822.5261\\n7 823.3838 823.0407\\nY, por tanto, el valor que le corresponde a la hora 6 es, 823.0407 MBps.\\n3. ¿Qu´ e t´ ecnica de predicci´ on funciona mejor? ¿Por qu´ e? ¿Cu´ al es la m´ as adecuada\\npara los datos con los que contamos?\\nAntes de decidir que t´ ecnica de predicci´ on es la m´ as adecuada, debemos poner en perspectiva los\\ndatos que estamos analizando. Actualmente, estamos calculando el valor que corresponde a la hora\\n6, el cual se predice mediante los valores anteriores. Estos valores anteriores realmente son medias\\nde las decenas de miles de valores que ten´ ıamos previos a la realizaci´ on de las medias. Por tanto, en\\neste contexto, ahora mismo estamos trabajando con periodos de tiempo muy grandes (aunque sea\\nde 1h). Esto se debe a que antes ten´ ıamos miles de valores incluso por cada mil´ esima de segundo\\ny ahora solo tenemos uno por hora.\\nEsto significa que anteriormente el periodo de tiempo entre muestra y muestra era ´ ınfimo, y, por\\ntanto, aplicar una predicci´ on con medias m´ oviles ser´ ıa la opci´ on te´ oricamente m´ as acertada. Sin\\n62', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 62}), Document(page_content='embargo, ahora tenemos un periodo de tiempo de horas (miles de mil´ esimas de segundo), es decir,\\nun periodo exageradamente m´ as grande que el anterior. En consecuencia, esto nos indica que\\nla t´ ecnica de predicci´ on m´ as adecuada ser´ a el suavizado exponencial; que funciona mejor para\\nperiodos de tiempo grandes.\\nClaramente, si nos fijamos en los gr´ aficos, podemos observar como lo comentado hasta ahora se\\nrefleja claramente. En particular, en el caso del tama˜ no, la diferencia entre medias m´ oviles y\\nsuavizado exponencial es poca, pero existe. Sin embargo, en el caso de la velocidad, pr´ acticamente\\nes el mismo valor. Es por ello que esto puede llevarnos a la confusi´ on, pero aplicando los conceptos\\nte´ oricos vistos en clase, nos decantamos claramente por el suavizado exponencial en ambos casos.\\n63', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 63}), Document(page_content='Scripts\\nA continuaci´ on el script implementado:\\n1import numpy as np\\n2import statistics\\n3import matplotlib.pyplot as plt\\n4\\n5with open(\"data.arff\", \"r\") as file:\\n6 data = file.read().splitlines()\\n7\\n8data = data[8:]\\n9\\n10hours_label = [\"22\", \"23\", \"01\", \"02\", \"03\", \"04\", \"05\"]\\n11pred_hours_label = [\"22\", \"23\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\\n12hours = np.arange(len(hours_label))\\n13\\n14\\n15def size():\\n16 # Plot initialization\\n17 plt.figure()\\n18 plt.rcParams.update({\"font.family\": \"serif\"})\\n19\\n20 y_values = []\\n21\\n22 # Get data for especific hour\\n23 for hour in hours_label:\\n24 y = get_axes_mean(hour, 0)\\n25 plt.scatter(hour, y, s=10, c=\"blue\")\\n26 plt.xticks(hours, hours_label)\\n27\\n28 # Data for post-processing\\n29 y_values.append(y)\\n30\\n31 # Save plot\\n32 plt.title(\"Media de los Tama~ nos (MB) frente al Tiempo (h)\")\\n33 plt.xlabel(\\'Tiempo (h)\\')\\n34 plt.ylabel(\\'Tama~ no (MB)\\')\\n35 plt.savefig(f\"size.png\")\\n36\\n37 # Post-processing\\n38 linear_regression(y_values, \"Tama~ no (MB)\")\\n39 moving_means(y_values, \"Tama~ no (MB)\")\\n40 exponential_smoothing(y_values, \"Tama~ no (MB)\")\\n64', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 64}), Document(page_content='41\\n42\\n43def velocity():\\n44 # Plot initialization\\n45 plt.figure()\\n46 plt.rcParams.update({\"font.family\": \"serif\"})\\n47\\n48 y_values = []\\n49\\n50 # Get data for especific hour\\n51 for hour in hours_label:\\n52 y = get_axes_mean(hour, 2)\\n53 plt.scatter(hour, y, s=10, c=\"blue\")\\n54 plt.xticks(hours, hours_label)\\n55\\n56 # Data for post-processing\\n57 y_values.append(y)\\n58\\n59 # Save plot\\n60 plt.title(\"Media de las Velocidades (MBps) frente al Tiempo (h)\")\\n61 plt.xlabel(\\'Tiempo (h)\\')\\n62 plt.ylabel(\\'Velocidad (MBps)\\')\\n63 plt.savefig(f\"velocity.png\")\\n64\\n65 # Post-processing\\n66 linear_regression(y_values, \"Velocidad (MBps)\")\\n67 moving_means(y_values, \"Velocidad (MBps)\")\\n68 exponential_smoothing(y_values, \"Velocidad (MBps)\")\\n69\\n70\\n71def format(x):\\n72 return float((\\' %.4f \\' % x).rstrip(\\'0\\').rstrip(\\'.\\'))\\n73\\n74\\n75def get_axes_mean(hour, value):\\n76 y = []\\n77\\n78 # Get data for especific hour\\n79 for line in data:\\n80 line = line.split(\\',\\')\\n81 if line[1] == hour:\\n82 y.append(float(line[value]))\\n83\\n84 # Calculate mean\\n65', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 65}), Document(page_content='85 if value == 0:\\n86 return format(np.mean(y))\\n87 else:\\n88 return format(statistics.harmonic_mean(y))\\n89\\n90\\n91def linear_regression(y, type):\\n92 x = np.arange(len(y))\\n93\\n94 # Calculate means\\n95 x_mean = np.mean(x)\\n96 if type == \"Velocidad (MBps)\":\\n97 y_mean = statistics.harmonic_mean(y)\\n98 else:\\n99 y_mean = np.mean(y)\\n100\\n101 # Calculate b\\n102 b = (np.sum(y * x) - len(y) * x_mean * y_mean) / (np.sum(x * x) - len(x) *\\nx_mean * x_mean) ,→\\n103\\n104 # Calculate a\\n105 a = y_mean - b * x_mean\\n106\\n107 # Plot data\\n108 plt.figure()\\n109 plt.rcParams.update({\"font.family\": \"serif\"})\\n110 plt.scatter(x, y, s=10, c=\"blue\")\\n111\\n112 # Plot linear regression\\n113 x_plot = np.arange(len(pred_hours_label))\\n114 plt.plot(x_plot, a + b * x_plot, color=\\'red\\')\\n115\\n116 # Save plot\\n117 plt.xticks(x_plot, pred_hours_label)\\n118 plt.title(f\"Regresi´ on Lineal de {type }\")\\n119 plt.xlabel(\\'Tiempo (h)\\')\\n120 plt.ylabel(f\" {type }\")\\n121 plt.savefig(f\"linear_regression_ {type }.png\")\\n122\\n123\\n124def moving_means(y, type):\\n125 i = 1\\n126 moving_averages = []\\n127 cum_sum = np.cumsum(y)\\n66', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 66}), Document(page_content='128 x = np.arange(len(y))\\n129\\n130 # Calculate moving averages\\n131 i = 4\\n132 while i <= (len(y)):\\n133 window_average = round(cum_sum[i-1] / i, 2)\\n134 moving_averages.append(window_average)\\n135 i += 1\\n136\\n137 # Calulate moving averages for next hour\\n138 moving_averages.append(np.sum(y[-4:])/4)\\n139\\n140 # Plot data\\n141 plt.figure()\\n142 plt.rcParams.update({\"font.family\": \"serif\"})\\n143 plt.scatter(x, y, s=10, c=\"blue\")\\n144\\n145 # Plot moving averages\\n146 x_plot = np.arange(3, 8)\\n147 plt.plot(x_plot, moving_averages, color=\"red\")\\n148\\n149 # Save plot\\n150 x = np.arange(len(pred_hours_label))\\n151 plt.xticks(x, pred_hours_label)\\n152 plt.title(f\"Media M´ ovil de {type }\")\\n153 plt.xlabel(\\'Tiempo (h)\\')\\n154 plt.ylabel(f\" {type }\")\\n155 plt.savefig(f\"moving_means_ {type }.png\")\\n156\\n157\\n158def exponential_smoothing(y, type):\\n159 x = np.arange(len(y))\\n160\\n161 # Plot data\\n162 plt.figure()\\n163 plt.rcParams.update({\"font.family\": \"serif\"})\\n164 plt.scatter(x, y, s=10, c=\"blue\")\\n165\\n166 # Exponential smoothing\\n167 alpha = 0.6\\n168 smoothed = [y[0]]\\n169 for i in range(1, len(y)):\\n170 smoothed.append(alpha * y[i] + (1 - alpha) * smoothed[i-1])\\n171\\n67', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 67}), Document(page_content='172 # Calculate moving averages for next hour\\n173 smoothed.append(smoothed[-1])\\n174\\n175 # Plot exponential smoothing\\n176 x_plot = np.arange(8)\\n177 plt.plot(x_plot, smoothed, color=\"red\")\\n178\\n179 # Save plot\\n180 plt.xticks(x_plot, pred_hours_label)\\n181 plt.title(f\"Suavizado Exponencial de {type }\")\\n182 plt.xlabel(\\'Tiempo (h)\\')\\n183 plt.ylabel(f\" {type }\")\\n184 plt.savefig(f\"exponential_smoothing_ {type }.png\")\\n185\\n186\\n187if __name__ == \"__main__\":\\n188 size()\\n189 velocity()\\n68', metadata={'source': './data/Cuaderno_Practicas_ACSI.pdf', 'page': 68})], [Document(page_content='Grau en Enginyeria Inform `atica\\nSistemes de Gesti´ o de Bases de Dades\\nPr` actica Final Recuperaci´ o\\nLluis Barca Pons\\nlluis.barca1@estudiant.uib.es\\n6 de febrer de 2024', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 0}), Document(page_content='´Index\\n1 Introducci´ o 3\\n2 Neteja de les dades 4\\n2.1 Conversi´ o dels fitxers del format ODS a CSV . . . . . . . . . . . . . . . . . . . . . . 4\\n2.2 Format de les dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n3 An` alisi i modelat de les dades 5\\n3.1 Model conceptual . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.1.1 Aclariments i suposicions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.2 Model relacional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.2.1 Taules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.2.2 Normalitzaci´ o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.2.3 Elecci´ o de claus prim` aries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.2.4 Relacional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.3 Model conceptual normalitzat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.3.1 Aclariments i suposicions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n4 Implementaci´ o amb MySQL 11\\n4.1 Creaci´ o de l’espai d’emmagatzemament . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n4.2 Creaci´ o de la base de dades i l’usuari IMPBD . . . . . . . . . . . . . . . . . . . . . 11\\n4.2.1 Descripci´ o dels constraints ,checks itriggers implementats . . . . . . . . . . 12\\n4.3 Importaci´ o de les dades a IMPBD . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.4 Creaci´ o de la base de dades DEFBD i l’usuari MIGBD . . . . . . . . . . . . . . . . 16\\n4.5 Trasp` as de la informaci´ o de les taules creades amb l’usuari IMPBD a l’usuari MIGBD 16\\n4.6 Consulta SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.6.1 Definicio de la consulta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.6.2 Millores de rendiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n5 Migraci´ o a PostgreSQL 23\\n5.1 Configuraci´ o del FDW . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n5.1.1 Configuraci´ o a PostgreSQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n5.2 Creaci´ o de l’espai d’emmagatzemament . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n5.3 Creaci´ o de la base de dades FET i l’esquema Temp . . . . . . . . . . . . . . . . . . 24\\n5.4 Gesti´ o d’usuaris i inserci´ o de dades a FET . . . . . . . . . . . . . . . . . . . . . . . 24\\n5.5 Consultes SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n1', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 1}), Document(page_content='5.5.1 Mitjana de pes dels bous per any en qu` e es celebra la seva lidia . . . . . . . 24\\n5.5.2 Bous s’han lidiat a l’estat espanyol . . . . . . . . . . . . . . . . . . . . . . . 24\\n6 Migraci´ o a Oracle 25\\n6.1 Configuraci´ o del gestor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n6.2 Creaci´ o de l’usuari Utest i gesti´ o dels seus privilegis . . . . . . . . . . . . . . . . . . 26\\n6.3 Migraci´ o de dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.3.1 Exportaci´ o de dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.3.2 Creaci´ o de taules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.3.3 Importaci´ o de dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.4 Consulta SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n6.4.1 Definici´ o de la consulta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n7 Conclusions 29\\n8 Annex I: Codi SQL 31\\n8.1 Codi de MySQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n8.2 Aclariments sobre el codi SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n8.3 Codi d’Oracle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n8.4 Aclariments sobre el codi SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n9 Annex II: Scripts de neteja 36\\n2', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 2}), Document(page_content='1.Introducci´ o\\nLa Reial Federaci´ o Taurina d’Espanya, amb una hist` oria rica i complexa, ha acumulat un vast\\nllegat de dades des de la seva fundaci´ o el 1949. Des de l’assignatura de Sistemes de Gesti´ o de\\nBases de Dades se’ns ha proposat fer aquest treball que fa ` emfasi tant el disseny, la manipulaci´ o i\\nmigraci´ o de dades en un entorn semirealista. Comencem amb la construcci´ o d’un model de dades\\nrobust, dissenyat per reflectir la xarxa de relacions entre toreros, apoderats, actuacions, esdeveni-\\nments i les places de toros que s´ on l’escenari d’aquest art cultural. S’ha prestat especial atenci´ o a\\nles restriccions, verificacions necess` aries per preservar la integritat de les dades, aconseguint aix´ ı\\nla normalitzaci´ o desitjada sense sacrificar la flexibilitat operativa.\\nAmb una implementaci´ o meticulosa cap a MySQL, i posteriorment la migraci´ o cap a PostgreSQL\\ni finalment a Oracle, hem traslladat s` aviament la riquesa de la hist` oria taurina a una infraestruc-\\ntura digital moderna. La migraci´ o no nom´ es garanteix la preservaci´ o de les dades, sin´ o que tamb´ e\\nobre noves possibilitats per an` alisi i accessibilitat. Durant aquest proc´ es, s’han establert usuaris\\nespecialitzats i privilegis necessaris per facilitar la gesti´ o eficient i segura de les dades.\\nEn resum, aquest treball no sols documenta la transici´ o de registres hist` orics a un sistema gesti-\\nonable i consultable, sin´ o que posa en practica els diversos coneixements adquirits durant tot el\\ncurs.\\n3', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 3}), Document(page_content='2.Neteja de les dades\\n2.1 Conversi´ o dels fitxers del format ODS a CSV\\nEn primer lloc, consultant la documentaci´ o de MySQL, ens adonem que aquest sistema de gesti´ o\\nde base de dades no pot importar dades des d’un fitxer ODS de manera directa. ´Es per aix` o que\\ns’han convertit aquests fitxers a un format CSV, que s´ ı que accepta el gestor. Podeu consultar\\naquests scripts a la secci´ o 9.\\n2.2 Format de les dades\\nEn segon lloc, tenim que diversos arxius contenen elements encapsulats amb dobles cometes i altres\\nque no, columnes totalment buides o incl´ us formats de dates incorrectes (possiblement a causa de\\nla conversi´ o a CSV). Veure tamb´ e els scripts a la secci´ o 9\\nS´ on aquests els motius de la implementaci´ o d’aquesta neteja pr` evia i, amb l’objectiu de fer una\\ncorrecta importaci´ o posterior.\\n4', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 4}), Document(page_content='3.An` alisi i modelat de les dades\\n3.1 Model conceptual\\nAquest model reflecteix l’estructura de dades dels fitxers d’on s’importaran les dades i que ser` a\\nl’estructura de la base de dades IMPBD. Aquesta realitzar` a la funci´ o de data lake (llac de dades\\nen catal` a).\\n5', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 5}), Document(page_content='3.1.1 Aclariments i suposicions\\nAquest model representa les diferents taules i relacions de la base de dades d’importaci´ o d’aquest\\nprojecte\\nEn primer lloc, ens trobem les taules APODERAT iTORERO que tenen una relaci´ o 1..1 a0..* el\\nque ens suggereix que un apoderat pot tenir diversos toreros assignats (aix` o es dona, per exemple,\\nperqu` e un apoderat t´ e una escola i, per tant, mentoritza diversos toreros) i un torero ´ unica i ex-\\nclusivament pot tenir un apoderat associat (persona de total confian¸ ca). En segon lloc, trobem la\\nrelaci´ o TORERO aACTUACIO amb la mateixa cardinalitat que la relaci´ o anterior, on un torero pot\\nparticipar en diferents actuacions, per` o una actuaci´ o nom´ es pot tenir un torero assignat.\\nSeguidament, ens trobem amb la relaci´ o ACTUACIO aESDEVENIMENT on tamb´ e es repeteix la ma-\\nteixa cardinalitat i b` asicament una actuaci´ o pot formar part ´ unicament d’un esdeveniment, per` o\\nun esdeveniment pot donar lloc a diferents actuacions. Finalment, la relaci´ o PLAC ¸A DE BOUS amb\\nESDEVENIMENT que ens indica que una pla¸ ca de bous pot albergar diferents esdeveniments, per` o\\nque un esdeveniment nom´ es pot estar associat a una pla¸ ca concreta.\\nD’aquesta forma, aquesta base de dades ens servir` a per al ja comentat i mancar` a de constraints com\\nel de la clau forana, ja que no necessitem establir-lo en el nostre sistema degut a la funcionalitat\\nque dur` a a terme aquesta base de dades; importar informaci´ o per despr´ es migrar-la a una altra\\nbase de dades normalitzada. Aix` o ho veurem a les seg¨ uents seccions.\\n3.2 Model relacional\\nA continuaci´ o les diferents passes per dur a terme la correcta normalitzaci´ o de la nostra base de\\ndades:\\n3.2.1 Taules\\nAPODERAT(idapo, nomapo, co1apo, co2apo, maiapo, dirapo, ciuapo, paiapo)\\nTORERO(idetor, nomtor, co1tor, co2tor, maitor, dirtor, ciutor, paitor, ideapo)\\nACTUACIO(idetor, datcor, nompla)\\nESDEVENIMENT(fircor, datcor, nompla, nombou, anybou, pesbou, cifram, nomram)\\nPLAC ¸A DE BOUS(nompla, anypla, locpla, tippla, ciupla, paipla, estpla, muspla)\\n6', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 6}), Document(page_content='3.2.2 Normalitzaci´ o\\nPERSONA(nom, cog, mai, dir)\\nAPODERAT(ideapo)\\nTORERO(idetor, ideapo)\\nACTUACIO(idetor, datcor, nompla)\\nESDEVENIMENT(fircor, datcor, nompla)\\nRAMADERIA(cifram, nomram)\\nBOU(nombou, anybou, pesbou)\\nPLAC ¸A DE BOUS(nompla, anypla, locpla, tippla, estpla, muspla)\\nUBICACIO(ciu, pai)\\n3.2.3 Elecci´ o de claus prim` aries\\nD’aqu´ ı en endavant es marcaran les claus prim` aries en negreta.\\nPERSONA( ideper , nom, cog, mai, dir)\\nAPODERAT( ideapo )\\nTORERO( idetor , ideapo)\\nACTUACIO( idact , idetor, datcor, nompla)\\nESDEVENIMENT( idesd , fircor, datcor, nompla)\\nRAMADERIA( cifram , nomram)\\nBOU( idbou , nombou, anybou, pesbou)\\nPLAC ¸A DE BOUS( nompla , anypla, locpla, tippla, estpla, muspla)\\nUBICACIO( ciu, pai )\\n7', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 7}), Document(page_content='3.2.4 Relacional\\nD’aqu´ ı en endavant es marcaran les claus foranes en cursiva.\\nPERSONA( ideper , nom, cog, mai, dir, ciu, pai )\\n{(ciu, pai) FK de la taula UBICACIO }\\nAPODERAT( ideapo )\\n{ideapo FK de la taula PERSONA }\\nTORERO( idetor ,ideapo )\\n{ideapo FK de la taula APODERAT }\\n{idetor FK de la taula PERSONA }\\nACTUACIO( idact ,idetor , datcor, idesd )\\n{idetor FK de la taula TORERO }\\n{idesd FK de la taula ESDEVENIMENT }\\nESDEVENIMENT( idesd , fircor, datcor, nompla ,idbou )\\n{idbou FK de la taula BOU }\\n{nompla FK de la taula PLAC ¸A DE BOUS }\\nRAMADERIA( cifram , nomram)\\nBOU( idbou , nombou, anybou, pesbou, cifram )\\n{cifram FK de la taula RAMADERIA }\\nPLAC ¸A DE BOUS( nompla , anypla, locpla, tippla, ciupla, paipla , estpla, muspla)\\n{(ciupla, paipla) FK de la taula UBICACIO }\\nUBICACIO( ciu, pai )\\n8', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 8}), Document(page_content='3.3 Model conceptual normalitzat\\nA continuaci´ o una imatge de com quedaria el model de dades normalitzat de la nostra base de dades:\\n3.3.1 Aclariments i suposicions\\nEn el model conceptual podem observar, en primer lloc, una her` encia anomenada PERSONA , que ens\\npermet encapsular tots aquells atributs que engloben un objecte persona. En aquest cas es tracta-\\nria tant de l’apoderat com el torero, ambd´ os amb pr` acticament els mateixos atributs, a excepci´ o\\ndels seus identificadors. Aquesta her` encia tindr` a una restricci´ o Mandatory, OR , la qual assegura\\nque, una persona, pot ser tant torero com apoderat en qualque moment de la seva vida. Aix` o\\n9', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 9}), Document(page_content='s’ha implementat aix´ ı perqu` e habitualment els apoderats solen ser persones amb experi` encia dins\\nel sector de la taurom` aquia i, per tant, poden haver estat toreros. Amb aquesta implementaci´ o,\\naconseguim una reducci´ o de la redund` ancia de dades a la nostra base de dades.\\nSeguidament, ens trobem les taules APODERAT iTORERO , les quals tenen una relaci´ o 1..1 i1..* .\\n´Es a dir, un torero podr` a tenir un ´ unic apoderat, per` o un apoderat podr` a tenir diversos toreros;\\nperqu` e els apoderats viuen pr` acticament de mentoritzar a aquests toreros i incl´ us tenen escoles\\ndedicades exclusivament. A continuaci´ o ens trobem amb la taula ACTUACIO , que est` a relacionada\\namb la taula TORERO amb una relaci´ o 1..* a0..* , la qual cosa significa que un torero pot haver\\nparticipat a zero actuacions o a moltes i que una actuaci´ o pot tenir com a protagonista un ´ unic\\ntorero; en cas d’estar torejant dos toreros en una mateixa actuaci´ o, tindr´ ıem dues actuacions al\\nmateix moment (la qual cosa ´ es molt poc probable).\\nA continuaci´ o trobem una relaci´ o entre les taules ACTUACIO iESDEVENIMENT , on una actuaci´ o\\nnom´ es pot estar assignada a esdeveniment i que un esdeveniment pot tenir definides de zero a\\nmoltes actuacions; per poder tenir en compte les noves actuacions que encara no han estat dutes\\na terme a un esdeveniment. Despr´ es tenim que la taula PLAC ¸A DE BOUS est` a relacionada amb la\\ntaula ESDEVENIMENT per una relaci´ o 0..* i1..1 .´Es a dir, una pla¸ ca de bous pot tenir de zero a\\nmolts esdeveniments i un esdeveniment pot tenir ´ unicament una pla¸ ca de bous associada. Despr´ es\\nla taula BOUque representa el bou que participa en l’esdeveniment concret. En aquest cas tindrem\\nuna relaci´ o 0..* a1..1 , ja que a un mateix esdeveniment nom´ es participar` a un bou, per` o un bou\\npodria participar en zero (en cas de no haver participat en cap) o m´ es d’un; ja que de vegades pot\\npassar. Despr´ es, a la taula RAMADERIA ens trobem una relaci´ o tamb´ e 0..* a1..1 que reflecteix\\ncom la ramaderia pot tenir en crian¸ ca diversos bous, per` o un bou nom´ es pot formar d’una rama-\\nderia.\\nD’altra banda, tenim la taula PLAC ¸A DE BOUS , la qual est` a relacionada amb ESDEVENIMENT amb\\nuna relaci´ o 0..* a1..1 ,´ es a dir, que una pla¸ ca de bous pot albergar diferents esdeveniments,\\nper` o un esdeveniment nom´ es es pot dur a terme a una pla¸ ca. Finalment, tenim la taula UBICACI ´O\\nque est` a relacionada tant amb la taula PLAC ¸A DE TOROS com amb PERSONA . Ambdues relacions\\nes componen d’una cardinalitat 1..* a1..1 , el que ens indica que una persona o una pla¸ ca\\nnom´ es podran tenir assignat una ´ unica ubicaci´ o (pa´ ıs i ciutat), per` o que una ubicaci´ o pot albergar\\ndiferents persones com places.\\n10', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 10}), Document(page_content=\"4.Implementaci´ o amb MySQL\\n4.1 Creaci´ o de l’espai d’emmagatzemament\\nPer a la creaci´ o de l’espai d’emmagatzemament de 5GB i fita m` axima de 10GB, haurem d’utilitzar\\nunTABLESPACE amb diversos par` ametres.\\n1 CREATE TABLESPACE tb_1\\n2 ADD DATAFILE 'tb_1.ibd'\\n3 ENGINE = InnoDB\\n4 INITIAL_SIZE = 5G\\n5 MAX_SIZE = 10G;\\nAquest ser` a creat al directori per defecte que t´ e MySQL a macOS /usr/local/var/mysql .\\n4.2 Creaci´ o de la base de dades i l’usuari IMPBD\\nPer crear la base de dades a MySQL Server haurem d’executar el seg¨ uent codi SQL:\\n1 CREATE DATABASE IF NOT EXISTS IMPBD\\n2 CHARACTER SET = 'utf8';\\n3\\n4 # Podem comprovar la correcta creaci´ o amb la comanda:\\n5 SHOW DATABASES;\\nA continuaci´ o creem l’usuari IMPBD i li donem permisos:\\n1 CREATE USER 'impbd' @'localhost' IDENTIFIED BY 'admin';\\n2 GRANT CREATE, INSERT, UPDATE, DELETE, REFERENCES ON IMPBD.* TO\\n'impbd' @'localhost'; ,→\\n3 FLUSH PRIVILEGES;\\n11\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 11}), Document(page_content='Ara, haurem d’iniciar mysql des de l’usuari creat i crear les respectives taules de la base de dades,\\nsegons els fitxers .csv aportats per la Real Federaci´ o Taurina d’Espanya.\\nPrimer haurem de seleccionar la base de dades:\\n1 USE IMPBD;\\nDespr´ es executarem el script SQL que crear` a les respectives taules que va adjunt a aquest treball\\ni est` a anomenat com Lluis Barca bdcorregudes bous mysql.sql .\\n4.2.1 Descripci´ o dels constraints ,checks itriggers implementats\\n•PERSONA\\n– Constraints\\n∗PRIMARY KEY :ideper ser` a la clau prim` aria per identificar a totes les persones.\\nAquesta clau realment ser` a l’identificador o del torero o de l’apoderat.\\n∗NOT NULL : Pr` acticament tots els atributs no poden ser NULL, per` o maiidir\\ns´ ı que ho poden ser, ja que tenim qualque persona que no t´ e aquestes dades.\\n•APODERAT\\n– Constraints\\n∗PRIMARY KEY :ideapo ser` a la clau prim` aria per identificar a una persona que\\n´ es apoderat.\\n∗FOREIGN KEY: ideapo ser` a tamb´ e la clau forana a la taula PERSONA .\\n∗NOT NULL : Aquesta taula nom´ es t´ e una columna i es tracta de la clau prim` aria,\\nper tant, no pot ser NULL mai.\\n•TORERO\\n– Constraints\\n∗PRIMARY KEY :idetor ser` a la clau prim` aria per identificar a una persona que\\n´ es torero.\\n∗FOREIG KEY :\\n·ideapo ser` a la clau forana de la taula APODERAT .\\n·idetor tamb´ e ser` a clau forana de la taula PERSONA .\\n∗NOT NULL : Totes les columnes seran NOT NULL, ja que s´ on o claus prim` aries\\no foranes.\\n12', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 12}), Document(page_content='•ACTUACIO\\n– Constraints\\n∗PRIMARY KEY :idact ser` a la clau prim` aria que ens permetr` a identificar les\\ndiferents actuacions. Aquesta s’autoincrementa cada vegada que s’insereix una\\nactuaci´ o.\\n∗FOREIGN KEY :\\n·idetor ser` a clau forana a la taula TORERO .\\n·idesd ser` a clau forana a la taula ESDEVENIMENT .\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•ESDEVENIMENT\\n– Constraints\\n∗PRIMARY KEY :idesd ser` a la clau prim` aria que ens permetr` a identificar els\\ndiferents esdeveniments. Aquesta s’autoincrementa cada vegada que s’insereix un\\nesdeveniment.\\n∗FOREIGN KEY :\\n·idbou ser` a la clau forana a la taula BOU.\\n·nompla ser` a la clau forana a la taula PLAC ¸A DEBOUS .\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•RAMADERIA\\n– Constraints\\n∗PRIMARY KEY :cifram ´ es el codi que identifica cada ramaderia faria de clau\\nprim` aria; vindria a ser una esp` ecie de NIF.\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•BOU\\n– Constraints\\n∗PRIMARY KEY :idbou ´ es el codi que identifica cada bou faria de clau prim` aria\\ni s’incrementa de forma autom` atica.\\n∗FOREIGN KEY :cifram ´ es la clau forana a la taula RAMADERIA .\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•PLAC ¸A DEBOUS\\n– Constraints\\n∗PRIMARY KEY :nompla ´ es el nom de la pla¸ ca que seria la nostra clau prim` aria,\\nja que no volem tenir places duplicades.\\n∗FOREIGN KEY : La tupla ciupla, paipla ´ es la clau forana a la taula UBICACIO .\\n13', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 13}), Document(page_content=\"– Checks\\n∗tippla : Verifica que el valor d’aquesta columna sigui 0 o 1. Aquests valors ens\\ninformen de si la pla¸ ca de bous ´ es fixa o m` obil.\\n∗muspla : Verifica que el valor d’aquesta columna sigui 0 o 1. Aquests valors ens\\ninformen de si la pla¸ ca de bous t´ e o no museu.\\n•UBICACIO\\n– Constraints\\n∗PRIMARY KEY : La dupla ciu, pai efectuarien la funci´ o de clau prim` aria.\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n4.3 Importaci´ o de les dades a IMPBD\\nEn primer lloc, s’ha fet una feina pr` evia d’exportaci´ o dels fitxers en format ODS al format CSV,\\namb la finalitat que es puguin importar les dades amb la comanda LOAD DATA LOCAL INFILE .\\nDespr´ es, per poder inserir dades de forma “autom` atica”, s’ha de modificar l’arxiu de configuraci´ o\\nde MySQL. Concretament s’ha d’afegir la seg¨ uent l´ ınia:\\n1 local_infile = 1\\nLa qual activa la funci´ o perqu` e el sistema de gesti´ o de base de dades permeti la inserci´ o de dades a\\ntrav´ es de la comanda descrita anteriorment. A continuaci´ o s’ha d’entrar a la terminal de MySQL\\namb l’usuari corresponent, per` o marcant el par` ametre local-infile a 1:\\n1 mysql --local-infile=1 -u IMPBD -p\\nA partir d’aqu´ ı, ja podem utilitzar els seg¨ uents scripts que s’han implementat per a la importaci´ o\\ntotal de les dades:\\n•APODERAT\\n1 LOAD DATA LOCAL INFILE\\n'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/APODERATS.csv' ,→\\n2 INTO TABLE APODERAT\\n3 FIELDS TERMINATED BY ','\\n4 LINES TERMINATED BY '\\\\n'\\n5 IGNORE 1 ROWS;\\n14\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 14}), Document(page_content='•TORERO\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/TOREROS.csv\\' ,→\\n2 INTO TABLE TORERO\\n3 FIELDS TERMINATED BY \\',\\'\\n4 LINES TERMINATED BY \\'\\\\n\\'\\n5 IGNORE 1 ROWS;\\n•PLAC ¸A DE BOUS\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/PLACES_BOUS.csv\\' ,→\\n2 INTO TABLE PLAC ¸A_DE_BOUS\\n3 FIELDS TERMINATED BY \\',\\'\\n4 LINES TERMINATED BY \\'\\\\n\\'\\n5 IGNORE 1 ROWS;\\n•ESDEVENIMENT\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/esdeveniments.csv\\' ,→\\n2 INTO TABLE ESDEVENIMENT\\n3 FIELDS TERMINATED BY \\',\\'\\n4 ENCLOSED BY \\'\"\\'\\n5 LINES TERMINATED BY \\'\\\\n\\';\\n•ACTUACIO\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/ACTUACIONS.csv\\' ,→\\n2 INTO TABLE ACTUACIO\\n3 FIELDS TERMINATED BY \\',\\'\\n4 LINES TERMINATED BY \\'\\\\n\\'\\n5 IGNORE 1 ROWS;\\n15', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 15}), Document(page_content=\"4.4 Creaci´ o de la base de dades DEFBD i l’usuari MIGBD\\nCrearem la base de dades utilitzant l’usuari root :\\n1 CREATE DATABASE IF NOT EXISTS DEFBD\\n2 CHARACTER SET = 'utf8';\\nI li assignarem els permisos pertinents a l’usuari MIGBD perqu` e pugui interactuar amb aquesta:\\n1 CREATE USER 'migbd' @'localhost' IDENTIFIED BY 'admin';\\n2 GRANT CREATE, SELECT, INSERT, REFERENCES ON DEFBD.* TO 'migbd' @'localhost';\\n3 FLUSH PRIVILEGES;\\nLlavors amb aquest usuari, podem inserir les taules a la base de dades DEFBD, utilitzant el codi\\nSQL que adjunt a la secci´ o 8.\\n4.5 Trasp` as de la informaci´ o de les taules creades amb l’u-\\nsuari IMPBD a l’usuari MIGBD\\nPer a efectuar la transfer` encia de les dades d’IMPBD a DEFBD, primer haurem d’accedir a MySQL\\namb l’usuari MIGBD i a continuaci´ o especificar la base de dades on importarem les dades:\\n1 USE DEFBD;\\nAra ja podem executar els diferents inserts que efectuaran la migraci´ o:\\n1 -- Taula UBICACIO\\n2 INSERT INTO DEFBD.UBICACIO (ciu, pai)\\n3 SELECT DISTINCT ciuapo, paiapo FROM IMPBD.APODERAT\\n4 UNION\\n5 SELECT DISTINCT ciutor, paitor FROM IMPBD.TORERO\\n6 UNION\\n7 SELECT DISTINCT ciupla, paipla FROM IMPBD.PLAC ¸A_DE_BOUS;\\n8\\n9 -- Taula PERSONA\\n10 DELIMITER $$\\n11\\n12 CREATE PROCEDURE migracio_persona()\\n13 BEGIN\\n14 DECLARE finished INTEGER DEFAULT 0;\\n15 DECLARE newID VARCHAR(10);\\n16\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 16}), Document(page_content=\"16 DECLARE exist INT;\\n17 DECLARE baseID INT DEFAULT 100000000;\\n18 DECLARE suffix CHAR(1);\\n19 DECLARE nom VARCHAR(255);\\n20 DECLARE cog VARCHAR(255);\\n21 DECLARE mai VARCHAR(255);\\n22 DECLARE dir VARCHAR(255);\\n23 DECLARE ciu VARCHAR(255);\\n24 DECLARE pai VARCHAR(255);\\n25 DECLARE cur CURSOR FOR\\n26 SELECT nomapo, CONCAT_WS(' ', co1apo, co2apo) AS cog, maiapo,\\ndirapo, ciuapo, paiapo FROM IMPBD.APODERAT ,→\\n27 UNION ALL\\n28 SELECT nomtor, CONCAT_WS(' ', co1tor, co2tor) AS cog, maitor,\\ndirtor, ciutor, paitor FROM IMPBD.TORERO; ,→\\n29 DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = 1;\\n30\\n31 OPEN cur;\\n32\\n33 read_loop: LOOP\\n34 FETCH cur INTO nom, cog, mai, dir, ciu, pai;\\n35 IF finished = 1 THEN\\n36 LEAVE read_loop;\\n37 END IF;\\n38\\n39 SET exist = 1;\\n40 WHILE exist = 1 DO\\n41 SET baseID = baseID + 1;\\n42 SET suffix = CHAR(65 + FLOOR(RAND() * 26));\\n43 SET newID = CONCAT(CAST(baseID AS CHAR(9)), suffix);\\n44\\n45 SELECT COUNT(*) INTO exist FROM DEFBD.PERSONA WHERE ideper =\\nnewID; ,→\\n46\\n47 IF exist = 0 THEN\\n48 INSERT INTO DEFBD.PERSONA (ideper, nom, cog, mai, dir, ciu,\\npai) ,→\\n49 VALUES (newID, nom, cog, mai, dir, ciu, pai);\\n50 SET exist = 0;\\n51 END IF;\\n52 END WHILE;\\n53 END LOOP read_loop;\\n54\\n55 CLOSE cur;\\n17\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 17}), Document(page_content=\"56 END$$\\n57\\n58 DELIMITER ;\\n59\\n60 -- Taula APODERAT\\n61 DELIMITER $$\\n62\\n63 CREATE PROCEDURE migracio_apoderat()\\n64 BEGIN\\n65 DECLARE apodID VARCHAR(10);\\n66 DECLARE personID VARCHAR(10);\\n67 DECLARE nom VARCHAR(255);\\n68 DECLARE co1 VARCHAR(255);\\n69 DECLARE co2 VARCHAR(255);\\n70 DECLARE mai VARCHAR(255);\\n71 DECLARE dir VARCHAR(255);\\n72 DECLARE ciu VARCHAR(255);\\n73 DECLARE pai VARCHAR(255);\\n74 DECLARE finished INT DEFAULT 0;\\n75 DECLARE cur CURSOR FOR SELECT ideapo, nomapo, co1apo, co2apo, maiapo,\\ndirapo, ciuapo, paiapo FROM IMPBD.APODERAT; ,→\\n76 DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = 1;\\n77\\n78 OPEN cur;\\n79\\n80 my_loop: LOOP\\n81 FETCH cur INTO apodID, nom, co1, co2, mai, dir, ciu, pai;\\n82 IF finished THEN\\n83 LEAVE my_loop;\\n84 END IF;\\n85\\n86 SELECT ideper INTO personID FROM DEFBD.PERSONA\\n87 WHERE nom = nom AND cog = CONCAT_WS(co1, ' ', co2) AND mai = mai AND\\ndir = dir AND ciu = ciu AND pai = pai ,→\\n88 LIMIT 1;\\n89\\n90 IF personID IS NOT NULL THEN\\n91 INSERT INTO DEFBD.APODERAT (ideapo) VALUES (personID);\\n92 END IF;\\n93 END LOOP;\\n94\\n95 CLOSE cur;\\n96 END$$\\n97\\n18\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 18}), Document(page_content=\"98 DELIMITER ;\\n99\\n100 -- Taula TORERO\\n101 DELIMITER $$\\n102\\n103 CREATE PROCEDURE migracio_torero()\\n104 BEGIN\\n105 DECLARE torID VARCHAR(10);\\n106 DECLARE personID VARCHAR(10);\\n107 DECLARE apoderatID VARCHAR(10);\\n108 DECLARE nom VARCHAR(255);\\n109 DECLARE co1 VARCHAR(255);\\n110 DECLARE co2 VARCHAR(255);\\n111 DECLARE mai VARCHAR(255);\\n112 DECLARE dir VARCHAR(255);\\n113 DECLARE ciu VARCHAR(255);\\n114 DECLARE pai VARCHAR(255);\\n115 DECLARE finished INT DEFAULT 0;\\n116 DECLARE cur CURSOR FOR SELECT idetor, nomtor, co1tor, co2tor, maitor,\\ndirtor, ciutor, paitor, ideapo FROM IMPBD.TORERO; ,→\\n117 DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = 1;\\n118\\n119 OPEN cur;\\n120\\n121 torero_loop: LOOP\\n122 FETCH cur INTO torID, nom, co1, co2, mai, dir, ciu, pai, apoderatID;\\n123 IF finished THEN\\n124 LEAVE torero_loop;\\n125 END IF;\\n126\\n127 SELECT ideper INTO personID FROM DEFBD.PERSONA\\n128 WHERE nom = nom AND cog = CONCAT_WS(' ', co1, co2) AND mai = mai AND\\ndir = dir AND ciu = ciu AND pai = pai ,→\\n129 LIMIT 1;\\n130\\n131 SELECT ideapo INTO apoderatID FROM DEFBD.APODERAT\\n132 JOIN DEFBD.PERSONA ON DEFBD.PERSONA.ideper = DEFBD.APODERAT.ideapo\\n133 JOIN IMPBD.APODERAT ON IMPBD.APODERAT.ideapo = apoderatID\\n134 WHERE IMPBD.APODERAT.nomapo = nom AND IMPBD.APODERAT.ciuapo = ciu\\nAND IMPBD.APODERAT.paiapo = pai ,→\\n135 LIMIT 1;\\n136\\n137 IF personID IS NOT NULL THEN\\n138 INSERT INTO DEFBD.TORERO (idetor, ideapo)\\n19\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 19}), Document(page_content='139 VALUES (personID, apoderatID);\\n140 END IF;\\n141 END LOOP;\\n142\\n143 CLOSE cur;\\n144 END$$\\n145\\n146 DELIMITER ;\\n147\\n148 -- Taula PLAC ¸A DE BOUS\\n149 INSERT INTO DEFBD.PLAC ¸A_DE_BOUS (nompla, anypla, locpla, tippla, ciupla,\\npaipla, estpla, muspla) ,→\\n150 SELECT nompla, anypla, locpla, tippla, ciupla, paipla, estpla, muspla FROM\\nIMPBD.PLAC ¸A_DE_BOUS; ,→\\n151\\n152 -- Taula RAMADERIA\\n153 INSERT INTO DEFBD.RAMADERIA (cifram, nomram)\\n154 SELECT DISTINCT cifram, nomram\\n155 FROM IMPBD.ESDEVENIMENT;\\n156\\n157 -- Taula BOU\\n158 INSERT INTO DEFBD.BOU (nombou, anybou, pesbou, cifram)\\n159 SELECT nombou, anybou, pesbou, cifram\\n160 FROM IMPBD.ESDEVENIMENT;\\n161\\n162 -- Taula ESDEVENIMENT\\n163 INSERT INTO DEFBD.ESDEVENIMENT (fircor, datcor, nompla, idbou)\\n164 SELECT\\n165 e.fircor,\\n166 e.datcor,\\n167 e.nompla,\\n168 (SELECT b.idbou\\n169 FROM DEFBD.BOU b\\n170 WHERE b.nombou = e.nombou AND b.anybou = e.anybou AND b.pesbou =\\ne.pesbou ,→\\n171 LIMIT 1)\\n172 FROM IMPBD.ESDEVENIMENT e;\\n173\\n174 -- Taula ACTUACIO\\n175 INSERT INTO DEFBD.ACTUACIO (idetor, datcor, idesd)\\n176 SELECT\\n177 t.idetor,\\n178 a.datcor,\\n179 e.idesd\\n20', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 20}), Document(page_content='180 FROM\\n181 IMPBD.ACTUACIO a\\n182 JOIN DEFBD.TORERO t ON a.idetor = t.idetor\\n183 JOIN DEFBD.ESDEVENIMENT e ON a.datcor = e.datcor AND a.nompla =\\ne.nompla; ,→\\n4.6 Consulta SQL\\nA continuaci´ o s’implementar` a la consulta per a la actualitzacio de les dates de naixement dels\\nbous.\\n4.6.1 Definicio de la consulta\\n1 UPDATE BOU b\\n2 JOIN ESDEVENIMENT e ON b.idbou = e.idbou\\n3 SET b.anybou = DATE_SUB(e.datcor, INTERVAL 2.5 YEAR)\\n4 WHERE DATE_SUB(e.datcor, INTERVAL 2.5 YEAR) > b.anybou;\\n4.6.2 Millores de rendiment\\nA continuaci´ o podem analitzar el pla d’execuci´ o de la consulta per intentar optimizar-la:\\n1 EXPLAIN UPDATE BOU b\\n2 JOIN ESDEVENIMENT e ON b.idbou = e.idbou\\n3 SET b.anybou = DATE_SUB(e.datcor, INTERVAL 2.5 YEAR)\\n4 WHERE DATE_SUB(e.datcor, INTERVAL 2.5 YEAR) > b.anybou;\\n21', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 21}), Document(page_content='En aquest cas afegirem dos ´ ındex i una condici´ o extra per millorar el filtratge:\\n1 ALTER TABLE IMPBD.ESDEVENIMENT ADD INDEX idx_datcor (datcor);\\n2 ALTER TABLE DEFBD.BOU ADD INDEX idx_anybou (anybou);\\n3\\n4 EXPLAIN UPDATE BOU b\\n5 JOIN ESDEVENIMENT e ON b.idbou = e.idbou\\n6 SET b.anybou = DATE_SUB(e.datcor, INTERVAL 2.5 YEAR)\\n7 WHERE e.datcor > fecha inicioANDe.datcor < =fecha final\\n8 AND b.anybou < DATE_SUB(e.datcor, INTERVAL 2.5 YEAR);\\n22', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 22}), Document(page_content=\"5.Migraci´ o a PostgreSQL\\n5.1 Configuraci´ o del FDW\\n5.1.1 Configuraci´ o a PostgreSQL\\nInstal ·lar l’extensi´ o (si no est` a instal ·lada):\\n1 CREATE EXTENSION IF NOT EXISTS postgres_fdw;\\nCrear un servidor FDW que apunti al servidor MySQL:\\n1 CREATE SERVER mysql_server FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host\\n'localhost', port '3306', dbname 'defbd'); ,→\\nEstablir l’usuari i contrasenya per a la connexi´ o:\\n1 CREATE USER mapping\\n2 FOR postgres\\n3 SERVER mysql_server\\n4 OPTIONS (user 'mysql_user', password 'admin');\\n5.2 Creaci´ o de l’espai d’emmagatzemament\\nAquest TABLESPACE quedar` a emmagatzemat a la ruta indicada, dins el directori espec´ ıfic per\\nemmagatzemar aquest tipus d’objectes.\\n1 CREATE TABLESPACE data\\n2 OWNER postgres\\n3 LOCATION '/usr/local/var/postgresql@14/pg_tblspc';\\n23\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 23}), Document(page_content=\"5.3 Creaci´ o de la base de dades FET i l’esquema Temp\\nCreem la base de dades assignant-li el TABLESPACE creat anteriorment:\\n1 CREATE DATABASE fet\\n2 WITH OWNER = postgres\\n3 TABLESPACE data;\\nA continuaci´ o l’esquema temp :\\n1 CREATE SCHEMA temp AUTHORIZATION postgres;\\n5.4 Gesti´ o d’usuaris i inserci´ o de dades a FET\\nPer a gestionar aquesta base de dades, crearem un usuari amb uns privilegis espec´ ıfics que podr` a\\ncrear, inserir i consultar les taules d’aquesta base de dades.\\n1 CREATE USER ufdw WITH PASSWORD 'admin';\\n2\\n3 GRANT CREATE, INSERT, SELECT ON ALL TABLES IN SCHEMA temp TO ufdw;\\n5.5 Consultes SQL\\n5.5.1 Mitjana de pes dels bous per any en qu` e es celebra la seva lidia\\n1 SELECT AVG(pesbou), EXTRACT(YEAR FROM datcor) AS any_lidia\\n2 FROM Temp.bous\\n3 GROUP BY any_lidia;\\n5.5.2 Bous s’han lidiat a l’estat espanyol\\n1 SELECT COUNT(*)\\n2 FROM Temp.bous;\\n24\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 24}), Document(page_content='6.Migraci´ o a Oracle\\nPer a la migraci´ o a Oracle, es far` a servir un contenidor de Docker amb la imatge d’Oracle en la\\nseva versi´ o 19.3.0 Standard 2 amb l’arquitectura Single Instance . Per tant, s’ha de tenir instal ·lat\\nDocker pr` eviament. En aquest cas, s’ha instal ·lat la versi´ o d’escriptori per a macOS que inclou la\\ninterf´ ıcie gr` afica per manejar Docker.\\n6.1 Configuraci´ o del gestor\\nEn primer lloc, haurem de clonar el repositori oficial d’Oracle, on est` a la imatge desitjada.\\n1 git clone https://github.com/oracle/docker-images.git\\nA continuaci´ o baixarem la versi´ o d’Oracle indicada anteriorment, des de la p` agina web oficial, i\\nl’inserirem dins el directori /19.3.0 de la imatge clonada.\\nAra executarem el programa corresponent per construir el contenidor:\\n1 sudo ./buildContainerImage.sh -v 19.3.0 -s\\nHem de treure la mem` oria virtual total al meu sistema (macOS):\\n1 sysctl vm.swapusage\\nQue ens retorna el valor de 2048M. Per tant, els valors de:\\n•SGA = 2048 * 0.5 = 1024 MB\\n•PGA = 2048 * 0.15 = 307 MB\\n25', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 25}), Document(page_content='Per tant, la comanda quedar` a tal que aix´ ı:\\n1 sudo docker run -d --name oracle_bd \\\\\\n2 -p 1521:1521 -p 5500:5500 \\\\\\n3 -e ORACLE_SID=FET \\\\\\n4 -e ORACLE_PDB=FETPDB1 \\\\\\n5 -e INIT_SGA_SIZE=1024 \\\\\\n6 -e INIT_PGA_SIZE=307 \\\\\\n7 -e ENABLE_ARCHIVING=true \\\\\\n8 oracle/database:19.3.0-se2\\n6.2 Creaci´ o de l’usuari Utest i gesti´ o dels seus privilegis\\nA continuaci´ o creem l’usuari amb els privilegis corresponents per gestionar la base de dades:\\n1 CREATE USER utest IDENTIFIED BY admin;\\n2 GRANT CREATE SESSION, CREATE TABLE, INSERT, SELECT ON utest.* TO utest;\\n6.3 Migraci´ o de dades\\nAquesta part, com nom´ es necessitem unes quantes taules, ho farem mitjan¸ cant l’exportaci´ o a ar-\\nxius CSV de la base de dades de MySQL. Aquests arxius despr´ es els importarem a la base de dades\\nd’oracle.\\n6.3.1 Exportaci´ o de dades\\nA continuaci´ o els diferents codis SQL per a cada una de les taules de la base de dades de MySQL\\nper a efectuar la correcta exportacio:\\n1 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/UBICACIO.csv\\' ,→\\n2 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n3 LINES TERMINATED BY \\'\\\\n\\'\\n4 FROM UBICACIO;\\n5\\n6 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/PLAC ¸A_DE_BOUS.csv\\' ,→\\n7 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n26', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 26}), Document(page_content='8 LINES TERMINATED BY \\'\\\\n\\'\\n9 FROM PLAC ¸A_DE_BOUS;\\n10\\n11 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/ESDEVENIMENT.csv\\' ,→\\n12 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n13 LINES TERMINATED BY \\'\\\\n\\'\\n14 FROM ESDEVENIMENT;\\n15\\n16 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/BOU.csv\\' ,→\\n17 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n18 LINES TERMINATED BY \\'\\\\n\\'\\n19 FROM BOU;\\n6.3.2 Creaci´ o de taules\\nLa creaci´ o de taules s’ha dut a terme com ´ es habitual i trobarem el codi implementat a la secci´ o 8.\\n6.3.3 Importaci´ o de dades\\nPer tant, s’haur` a de crear un arxiu per a cada fitxer del qual vulguem importar les dades. A\\ncontinuaci´ o el codi corresponent a cada un dels fitxers per a la seva corresponents taula:\\n1 LOAD DATA\\n2 INFILE \\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/UBICACIO.csv\\'\\n3 INTO TABLE UBICACIO\\n4 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n5 (ciu, pai)\\n6\\n7 LOAD DATA\\n8 INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/PLAC ¸A_DE_BOUS.csv\\' ,→\\n9 INTO TABLE PLAC ¸A_DE_BOUS\\n10 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n11 (nompla, anypla, locpla, tippla, ciupla, paipla, estpla, muspla)\\n12\\n13 LOAD DATA\\n14 INFILE \\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/BOU.csv\\'\\n15 INTO TABLE BOU\\n16 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n17 (idbou, nombou, anybou, pesbou, cifram)\\n27', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 27}), Document(page_content='18\\n19 LOAD DATA\\n20 INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/ESDEVENIMENT.csv\\' ,→\\n21 INTO TABLE ESDEVENIMENT\\n22 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n23 (idesd, fircor, datcor, nompla, idbou)\\nA continuaci´ o utilitzem SQL Loader que ens permetr` a amb la seg¨ uent comanda, importar cada un\\ndels fitxers:\\n1 sqlldr USERID=utest/admin @oracle_db CONTROL=nom_fitxer.ctl\\nLOG=nom_fitxer.log ,→\\nElnomfitxer fa refer` encia a cada un dels diferents CSV.\\n6.4 Consulta SQL\\n6.4.1 Definici´ o de la consulta\\nNom i ubicaci´ o de la pla¸ ca de bous, juntament amb el nombre de bous que s’han torejat al llarg\\nde tota la hist` oria en ella.\\n1 SELECT\\n2 pb.nompla AS \"Nom de la Pla¸ ca de Bous\",\\n3 u.ciu AS \"Ciutat\",\\n4 u.pai AS \"Pa´ ıs\",\\n5 COUNT(b.idbou) AS \"Nombre de Bous Torejats\"\\n6 FROM PLAC ¸A_DE_BOUS pb\\n7 JOIN UBICACIO u ON pb.ciu = u.ciu AND pb.pai = u.pai\\n8 JOIN ESDEVENIMENT e ON pb.nompla = e.nompla\\n9 JOIN BOU b ON e.idbou = b.idbou\\n10 GROUP BY\\n11 pb.nompla, u.ciu, u.pai;\\n28', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 28}), Document(page_content='7.Conclusions\\nAquest treball ha evidenciat la interacci´ o entre la teoria i la pr` actica en el domini de la gesti´ o de\\nbases de dades, cosa que conjuntament amb l’enfrontament amb desafiaments reals i la resoluci´ o\\nde problemes inesperats han afavorit una comprensi´ o profunda dels sistemes de gesti´ o de bases de\\ndades. La necessitat d’adaptabilitat i un enfocament anal´ ıtic per superar obstacles s’ha convertit\\nen una pedra angular del proc´ es d’aprenentatge.\\nDurant el desenvolupament del projecte, s’han identificat i superat m´ ultiples reptes, des de q¨ uesti-\\nons de normalitzaci´ o de dades fins a l’optimitzaci´ o de consultes SQL. La implementaci´ o d’un model\\nde dades en un escenari real ha proporcionat una bona oportunitat per aplicar els coneixements\\nadquirits i ha demostrat ser una experi` encia enriquidora.\\nEn resum, els objectius establerts a l’inici han estat assolits amb ` exit, confirmant la relaci´ o entre\\nla teoria apresa i la seva aplicaci´ o pr` actica. El treball no nom´ es compleix amb les expectatives\\nacad` emiques sin´ o que tamb´ e serveix com a testimoni del valor de l’experi` encia pr` actica adquirida.\\nEls resultats obtinguts i les habilitats desenvolupades formen ara part de la meva preparaci´ o\\nprofessional, sent testimonis del meu creixement i evoluci´ o en l’` ambit de la inform` atica i la gesti´ o\\nde dades.\\n29', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 29}), Document(page_content='Bibliografia\\n[1] Documentaci´ o de MySQL, 2023, Manual de MySQL 8.3 Recuperat de https://dev.mysql.\\ncom/doc/refman/8.3/en/\\n[2] Documentaci´ o de PostgreSQL 2023, Manual de PostgreSQL 14 Recuperat de https://www.\\npostgresql.org/docs/14/index.html\\n[3] Oracle Database container images, 2023, Installation, configuration, and environment setup\\nRecuperat de https://github.com/oracle/docker-images/blob/main/OracleDatabase/\\nSingleInstance/README.md\\n30', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 30}), Document(page_content='8.Annex I: Codi SQL\\n8.1 Codi de MySQL\\n*Important llegir els aclariments sobre algunes decisions al final del codi*\\n1 CREATE TABLE UBICACIO (\\n2 ciu VARCHAR(255) NOT NULL,\\n3 pai VARCHAR(255) NOT NULL,\\n4 PRIMARY KEY (ciu, pai)\\n5 );\\n6\\n7 CREATE TABLE PERSONA (\\n8 ideper VARCHAR(10) NOT NULL,\\n9 nom VARCHAR(255) NOT NULL,\\n10 cog VARCHAR(255) NOT NULL,\\n11 mai VARCHAR(255),\\n12 dir VARCHAR(255),\\n13 ciu VARCHAR(255) NOT NULL,\\n14 pai VARCHAR(255) NOT NULL,\\n15 PRIMARY KEY (ideper),\\n16 FOREIGN KEY (ciu, pai) REFERENCES UBICACIO(ciu, pai)\\n17 );\\n18\\n19 CREATE TABLE APODERAT (\\n20 ideapo VARCHAR(10) NOT NULL,\\n21 PRIMARY KEY (ideapo),\\n22 FOREIGN KEY (ideapo) REFERENCES PERSONA(ideper)\\n23 );\\n24\\n25 CREATE TABLE TORERO (\\n26 idetor VARCHAR(10) NOT NULL,\\n27 ideapo VARCHAR(10) NOT NULL,\\n28 PRIMARY KEY (idetor),\\n29 FOREIGN KEY (ideapo) REFERENCES APODERAT(ideapo),\\n30 FOREIGN KEY (idetor) REFERENCES PERSONA(ideper)\\n31', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 31}), Document(page_content='31 );\\n32\\n33 CREATE TABLE PLAC ¸A_DE_BOUS (\\n34 nompla VARCHAR(255) NOT NULL,\\n35 anypla DATE NOT NULL,\\n36 locpla INT NOT NULL,\\n37 tippla BOOLEAN NOT NULL,\\n38 ciupla VARCHAR(255) NOT NULL,\\n39 paipla VARCHAR(255) NOT NULL,\\n40 estpla TEXT,\\n41 muspla BOOLEAN NOT NULL,\\n42 PRIMARY KEY (nompla),\\n43 FOREIGN KEY (ciupla, paipla) REFERENCES UBICACIO(ciu, pai),\\n44 CHECK (tippla IN (True, False)),\\n45 CHECK (muspla IN (True, False))\\n46 );\\n47\\n48 CREATE TABLE RAMADERIA (\\n49 cifram INT NOT NULL,\\n50 nomram VARCHAR(255) NOT NULL,\\n51 PRIMARY KEY (cifram)\\n52 );\\n53\\n54 CREATE TABLE BOU (\\n55 idbou INT NOT NULL AUTO_INCREMENT,\\n56 nombou VARCHAR(255) NOT NULL,\\n57 anybou DATE NOT NULL,\\n58 pesbou NUMERIC(5, 2) NOT NULL,\\n59 cifram INT NOT NULL,\\n60 PRIMARY KEY (idbou),\\n61 FOREIGN KEY (cifram) REFERENCES RAMADERIA(cifram)\\n62 );\\n63\\n64 CREATE TABLE ESDEVENIMENT (\\n65 idesd INT NOT NULL AUTO_INCREMENT,\\n66 fircor VARCHAR(255) NOT NULL,\\n67 datcor DATE NOT NULL,\\n68 nompla VARCHAR(255) NOT NULL,\\n69 idbou INT NOT NULL,\\n70 PRIMARY KEY (idesd),\\n71 FOREIGN KEY (idbou) REFERENCES BOU(idbou),\\n72 FOREIGN KEY (nompla) REFERENCES PLAC ¸A_DE_BOUS(nompla)\\n73 );\\n74\\n32', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 32}), Document(page_content='75 CREATE TABLE ACTUACIO (\\n76 idact INT NOT NULL AUTO_INCREMENT,\\n77 idetor VARCHAR(10) NOT NULL,\\n78 datcor DATE NOT NULL,\\n79 idesd INT NOT NULL,\\n80 PRIMARY KEY (idact),\\n81 FOREIGN KEY (idetor) REFERENCES TORERO(idetor),\\n82 FOREIGN KEY (idesd) REFERENCES ESDEVENIMENT(idesd)\\n83 );\\n8.2 Aclariments sobre el codi SQL\\nLa majoria de les columnes amb el tipus de dades VARCHAR tenen una longitud m` axima de 255\\nbytes. Aix` o ´ es aix´ ı perqu` e aquest tipus d’estructura de dades a MySQL utilitzen la mem` oria\\nper emmagatzemar les dades en funci´ o del que hagin d’emmagatzemar. Per` o, utilitzen un byte\\nextra per emmagatzemar la longitud m` axima, es dona el cas que 255 ´ es el m` axim per a 1 byte\\n(segons la documentaci´ o oficial) i, per tant, tindria el mateix impacte un VARCHAR(20) que un de\\nVARCHAR(255) . D’aquesta forma, en les columnes on no s’especifica una llarg` aria m` axima, oferim\\nun rang bastant ampli per si un cas.\\n33', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 33}), Document(page_content='8.3 Codi d’Oracle\\n1 CREATE TABLE UBICACIO (\\n2 ciu VARCHAR2(255) NOT NULL,\\n3 pai VARCHAR2(255) NOT NULL,\\n4 CONSTRAINT pk_ubicacio PRIMARY KEY (ciu, pai)\\n5 );\\n6\\n7 CREATE TABLE PLAC ¸A_DE_BOUS (\\n8 nompla VARCHAR2(255) NOT NULL,\\n9 anypla DATE NOT NULL,\\n10 locpla NUMBER NOT NULL,\\n11 tippla NUMBER(1) NOT NULL,\\n12 ciupla VARCHAR2(255) NOT NULL,\\n13 paipla VARCHAR2(255) NOT NULL,\\n14 estpla CLOB,\\n15 muspla NUMBER(1) NOT NULL,\\n16 CONSTRAINT pk_pla¸ ca_de_bous PRIMARY KEY (nompla),\\n17 CONSTRAINT fk_pla¸ ca_de_bous_ubicacio FOREIGN KEY (ciupla, paipla)\\nREFERENCES UBICACIO(ciu, pai), ,→\\n18 CONSTRAINT ck_pla¸ ca_de_bous_tippla CHECK (tippla IN (0, 1)),\\n19 CONSTRAINT ck_pla¸ ca_de_bous_muspla CHECK (muspla IN (0, 1))\\n20 );\\n21\\n22 CREATE TABLE BOU (\\n23 idbou NUMBER NOT NULL,\\n24 nombou VARCHAR2(255) NOT NULL,\\n25 anybou DATE NOT NULL,\\n26 pesbou NUMBER(7, 2) NOT NULL,\\n27 cifram NUMBER NOT NULL,\\n28 CONSTRAINT pk_bou PRIMARY KEY (idbou),\\n29 CONSTRAINT fk_bou_ramaderia FOREIGN KEY (cifram) REFERENCES\\nRAMADERIA(cifram) ,→\\n30 );\\n31\\n32 CREATE TABLE ESDEVENIMENT (\\n33 idesd NUMBER NOT NULL,\\n34 fircor VARCHAR2(255) NOT NULL,\\n35 datcor DATE NOT NULL,\\n36 nompla VARCHAR2(255) NOT NULL,\\n37 idbou NUMBER NOT NULL,\\n38 CONSTRAINT pk_esdeveniment PRIMARY KEY (idesd),\\n39 CONSTRAINT fk_esdeveniment_bou FOREIGN KEY (idbou) REFERENCES\\nBOU(idbou), ,→\\n34', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 34}), Document(page_content='40 CONSTRAINT fk_esdeveniment_pla¸ ca_de_bous FOREIGN KEY (nompla) REFERENCES\\nPLAC ¸A_DE_BOUS(nompla) ,→\\n41 );\\n8.4 Aclariments sobre el codi SQL\\nNom´ es s’han implementat les taules necess` aries per fer la consulta demanada, tal com s’especifica\\nals requisits del treball.\\nCal afegir que, a Oracle per exemple, no existeixen els valors AUTO INCREMENT i, per tant, s’haurien\\nde crear seq¨ u` encies i posteriorment triggers que fessin aquesta funci´ o. Per` o per temes de simplicitat,\\nno s’ha dut a terme perqu` e no s’utilitzarien.\\n35', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 35}), Document(page_content='9.Annex II: Scripts de neteja\\n•ACTUACIONS\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n9\\n10 # Eliminem les columnes que no ens interessen\\n11 data = pd.read_csv(output_file)\\n12 data[\"DATCOR\"] = data[\"DATCOR\"].str[:10] # Nom´ es ens quedam amb la\\ndata ,→\\n13 data.to_csv(output_file, index=False)\\n14\\n15 if __name__ == \"__main__\":\\n16 convert_ods_csv(\"./ACTUACIONS.ods\", \"./csv/ACTUACIONS.csv\")\\n•APODERATS\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n9\\n10 # Eliminem les columnes que no ens interessen\\n11 data = pd.read_csv(output_file)\\n36', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 36}), Document(page_content='12 data = data.iloc[:, :-2]\\n13\\n14 # Eliminem les cometes dobles i els espais en blanc de la\\ncolumna DIRAPO ,→\\n15 data[\"DIRAPO\"] = data[\"DIRAPO\"].str.strip().str.replace(\\'\"\\',\\n\\'\\') ,→\\n16 data.to_csv(output_file, index=False)\\n17\\n18 if __name__ == \"__main__\":\\n19 convert_ods_csv(\"./APODERATS.ods\", \"./csv/APODERATS.csv\")\\n•PLACES BOUS\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n9\\n10 # Eliminem l\\'hora de la columna ANYPLA\\n11 data = pd.read_csv(output_file)\\n12 data[\"ANYPLA\"] = data[\"ANYPLA\"].str[:10] # Mantenim nom´ es la\\ndata ,→\\n13 data.to_csv(output_file, index=False)\\n14\\n15 if __name__ == \"__main__\":\\n16 convert_ods_csv(\"./PLACES_BOUS.ods\", \"./csv/PLACES_BOUS.csv\")\\n•TORERO\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n37', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 37}), Document(page_content='9\\n10 # Eliminem les dues ´ ultimes columnes buides\\n11 data = pd.read_csv(output_file)\\n12 data = data.iloc[:, :-2]\\n13\\n14 # Eliiminam les cometes dobles i els espais en blanc de la\\ncolumna DIRTOR ,→\\n15 data[\"DIRTOR\"] = data[\"DIRTOR\"].str.strip().str.replace(\\'\"\\',\\n\\'\\') ,→\\n16 data.to_csv(output_file, index=False)\\n17\\n18 if __name__ == \"__main__\":\\n19 convert_ods_csv(\"./TOREROS.ods\", \"./csv/TOREROS.csv\")\\n38', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 38})]]\n",
      "2\n",
      "Pr´ actica 1\n",
      "Para la realizaci´ on de esta pr´ actica contaremos con los servidores A y B los cuales est´ an dedicados\n",
      "a tareas de c´ alculo cient´ ıfico. Es decir, las cargas que ejecutan son intensivas en CPU, y, por lo\n",
      "tanto, este es su dispositivo m´ as demandado. A continuaci´ on, se detallan las caracter´ ısticas de\n",
      "cada uno de los servidores.\n",
      "Servidor A\n",
      "Nombre del servidor: Dell Power Edge T430\n",
      "N´ umero de CPUs: 16\n",
      "Tama˜ no de la memoria RAM: 7753Mib ( ≈8GB)\n",
      "Coste: 1245 e\n",
      "Servidor B\n",
      "Nombre del servidor: Dell Power Edge T330\n",
      "N´ umero de CPUs: 8\n",
      "Tama˜ no de la memoria RAM: 15258,8Mib ( ≈16GB)\n",
      "Coste: 907 e\n",
      "El administrador de un centro de datos se enfrenta al reto de decidir qu´ e servidor es m´ as adecuado\n",
      "para la ejecuci´ on de una carga intensiva de CPU, el servidor A o el servidor B. Actualmente, el\n",
      "tiempo medio para ejecutar la carga en el servidor es de 31,01 segundos. Para realizar una justa\n",
      "comparaci´ on, se ha ejecutado la carga intensiva de CPU en los servidores A y B un total de 10\n",
      "veces, obteniendo los resultados mostrados a continuaci´ on.\n",
      "Tiempo de ejecuci´ on (s)\n",
      "Servidor A Servidor B\n",
      "24,15 27,01\n",
      "23,18 26,18\n",
      "25,01 26,56\n",
      "23,34 28,02\n",
      "22,65 26,78\n",
      "24,54 27,43\n",
      "23,46 27,34\n",
      "22,38 26,04\n",
      "23,54 27,19\n",
      "23,59 27,43\n",
      "Tiempo medio: 23,584 26,998\n",
      "1\n",
      "[Document(page_content='Grau en Enginyeria Inform `atica\\nSistemes de Gesti´ o de Bases de Dades\\nPr` actica Final Recuperaci´ o\\nLluis Barca Pons\\nlluis.barca1@estudiant.uib.es\\n6 de febrer de 2024', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 0}), Document(page_content='´Index\\n1 Introducci´ o 3\\n2 Neteja de les dades 4\\n2.1 Conversi´ o dels fitxers del format ODS a CSV . . . . . . . . . . . . . . . . . . . . . . 4\\n2.2 Format de les dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n3 An` alisi i modelat de les dades 5\\n3.1 Model conceptual . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.1.1 Aclariments i suposicions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.2 Model relacional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.2.1 Taules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.2.2 Normalitzaci´ o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.2.3 Elecci´ o de claus prim` aries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.2.4 Relacional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.3 Model conceptual normalitzat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.3.1 Aclariments i suposicions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n4 Implementaci´ o amb MySQL 11\\n4.1 Creaci´ o de l’espai d’emmagatzemament . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n4.2 Creaci´ o de la base de dades i l’usuari IMPBD . . . . . . . . . . . . . . . . . . . . . 11\\n4.2.1 Descripci´ o dels constraints ,checks itriggers implementats . . . . . . . . . . 12\\n4.3 Importaci´ o de les dades a IMPBD . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.4 Creaci´ o de la base de dades DEFBD i l’usuari MIGBD . . . . . . . . . . . . . . . . 16\\n4.5 Trasp` as de la informaci´ o de les taules creades amb l’usuari IMPBD a l’usuari MIGBD 16\\n4.6 Consulta SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.6.1 Definicio de la consulta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.6.2 Millores de rendiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n5 Migraci´ o a PostgreSQL 23\\n5.1 Configuraci´ o del FDW . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n5.1.1 Configuraci´ o a PostgreSQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n5.2 Creaci´ o de l’espai d’emmagatzemament . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n5.3 Creaci´ o de la base de dades FET i l’esquema Temp . . . . . . . . . . . . . . . . . . 24\\n5.4 Gesti´ o d’usuaris i inserci´ o de dades a FET . . . . . . . . . . . . . . . . . . . . . . . 24\\n5.5 Consultes SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n1', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 1}), Document(page_content='5.5.1 Mitjana de pes dels bous per any en qu` e es celebra la seva lidia . . . . . . . 24\\n5.5.2 Bous s’han lidiat a l’estat espanyol . . . . . . . . . . . . . . . . . . . . . . . 24\\n6 Migraci´ o a Oracle 25\\n6.1 Configuraci´ o del gestor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n6.2 Creaci´ o de l’usuari Utest i gesti´ o dels seus privilegis . . . . . . . . . . . . . . . . . . 26\\n6.3 Migraci´ o de dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.3.1 Exportaci´ o de dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n6.3.2 Creaci´ o de taules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.3.3 Importaci´ o de dades . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.4 Consulta SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n6.4.1 Definici´ o de la consulta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n7 Conclusions 29\\n8 Annex I: Codi SQL 31\\n8.1 Codi de MySQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n8.2 Aclariments sobre el codi SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n8.3 Codi d’Oracle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n8.4 Aclariments sobre el codi SQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n9 Annex II: Scripts de neteja 36\\n2', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 2}), Document(page_content='1.Introducci´ o\\nLa Reial Federaci´ o Taurina d’Espanya, amb una hist` oria rica i complexa, ha acumulat un vast\\nllegat de dades des de la seva fundaci´ o el 1949. Des de l’assignatura de Sistemes de Gesti´ o de\\nBases de Dades se’ns ha proposat fer aquest treball que fa ` emfasi tant el disseny, la manipulaci´ o i\\nmigraci´ o de dades en un entorn semirealista. Comencem amb la construcci´ o d’un model de dades\\nrobust, dissenyat per reflectir la xarxa de relacions entre toreros, apoderats, actuacions, esdeveni-\\nments i les places de toros que s´ on l’escenari d’aquest art cultural. S’ha prestat especial atenci´ o a\\nles restriccions, verificacions necess` aries per preservar la integritat de les dades, aconseguint aix´ ı\\nla normalitzaci´ o desitjada sense sacrificar la flexibilitat operativa.\\nAmb una implementaci´ o meticulosa cap a MySQL, i posteriorment la migraci´ o cap a PostgreSQL\\ni finalment a Oracle, hem traslladat s` aviament la riquesa de la hist` oria taurina a una infraestruc-\\ntura digital moderna. La migraci´ o no nom´ es garanteix la preservaci´ o de les dades, sin´ o que tamb´ e\\nobre noves possibilitats per an` alisi i accessibilitat. Durant aquest proc´ es, s’han establert usuaris\\nespecialitzats i privilegis necessaris per facilitar la gesti´ o eficient i segura de les dades.\\nEn resum, aquest treball no sols documenta la transici´ o de registres hist` orics a un sistema gesti-\\nonable i consultable, sin´ o que posa en practica els diversos coneixements adquirits durant tot el\\ncurs.\\n3', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 3}), Document(page_content='2.Neteja de les dades\\n2.1 Conversi´ o dels fitxers del format ODS a CSV\\nEn primer lloc, consultant la documentaci´ o de MySQL, ens adonem que aquest sistema de gesti´ o\\nde base de dades no pot importar dades des d’un fitxer ODS de manera directa. ´Es per aix` o que\\ns’han convertit aquests fitxers a un format CSV, que s´ ı que accepta el gestor. Podeu consultar\\naquests scripts a la secci´ o 9.\\n2.2 Format de les dades\\nEn segon lloc, tenim que diversos arxius contenen elements encapsulats amb dobles cometes i altres\\nque no, columnes totalment buides o incl´ us formats de dates incorrectes (possiblement a causa de\\nla conversi´ o a CSV). Veure tamb´ e els scripts a la secci´ o 9\\nS´ on aquests els motius de la implementaci´ o d’aquesta neteja pr` evia i, amb l’objectiu de fer una\\ncorrecta importaci´ o posterior.\\n4', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 4}), Document(page_content='3.An` alisi i modelat de les dades\\n3.1 Model conceptual\\nAquest model reflecteix l’estructura de dades dels fitxers d’on s’importaran les dades i que ser` a\\nl’estructura de la base de dades IMPBD. Aquesta realitzar` a la funci´ o de data lake (llac de dades\\nen catal` a).\\n5', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 5}), Document(page_content='3.1.1 Aclariments i suposicions\\nAquest model representa les diferents taules i relacions de la base de dades d’importaci´ o d’aquest\\nprojecte\\nEn primer lloc, ens trobem les taules APODERAT iTORERO que tenen una relaci´ o 1..1 a0..* el\\nque ens suggereix que un apoderat pot tenir diversos toreros assignats (aix` o es dona, per exemple,\\nperqu` e un apoderat t´ e una escola i, per tant, mentoritza diversos toreros) i un torero ´ unica i ex-\\nclusivament pot tenir un apoderat associat (persona de total confian¸ ca). En segon lloc, trobem la\\nrelaci´ o TORERO aACTUACIO amb la mateixa cardinalitat que la relaci´ o anterior, on un torero pot\\nparticipar en diferents actuacions, per` o una actuaci´ o nom´ es pot tenir un torero assignat.\\nSeguidament, ens trobem amb la relaci´ o ACTUACIO aESDEVENIMENT on tamb´ e es repeteix la ma-\\nteixa cardinalitat i b` asicament una actuaci´ o pot formar part ´ unicament d’un esdeveniment, per` o\\nun esdeveniment pot donar lloc a diferents actuacions. Finalment, la relaci´ o PLAC ¸A DE BOUS amb\\nESDEVENIMENT que ens indica que una pla¸ ca de bous pot albergar diferents esdeveniments, per` o\\nque un esdeveniment nom´ es pot estar associat a una pla¸ ca concreta.\\nD’aquesta forma, aquesta base de dades ens servir` a per al ja comentat i mancar` a de constraints com\\nel de la clau forana, ja que no necessitem establir-lo en el nostre sistema degut a la funcionalitat\\nque dur` a a terme aquesta base de dades; importar informaci´ o per despr´ es migrar-la a una altra\\nbase de dades normalitzada. Aix` o ho veurem a les seg¨ uents seccions.\\n3.2 Model relacional\\nA continuaci´ o les diferents passes per dur a terme la correcta normalitzaci´ o de la nostra base de\\ndades:\\n3.2.1 Taules\\nAPODERAT(idapo, nomapo, co1apo, co2apo, maiapo, dirapo, ciuapo, paiapo)\\nTORERO(idetor, nomtor, co1tor, co2tor, maitor, dirtor, ciutor, paitor, ideapo)\\nACTUACIO(idetor, datcor, nompla)\\nESDEVENIMENT(fircor, datcor, nompla, nombou, anybou, pesbou, cifram, nomram)\\nPLAC ¸A DE BOUS(nompla, anypla, locpla, tippla, ciupla, paipla, estpla, muspla)\\n6', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 6}), Document(page_content='3.2.2 Normalitzaci´ o\\nPERSONA(nom, cog, mai, dir)\\nAPODERAT(ideapo)\\nTORERO(idetor, ideapo)\\nACTUACIO(idetor, datcor, nompla)\\nESDEVENIMENT(fircor, datcor, nompla)\\nRAMADERIA(cifram, nomram)\\nBOU(nombou, anybou, pesbou)\\nPLAC ¸A DE BOUS(nompla, anypla, locpla, tippla, estpla, muspla)\\nUBICACIO(ciu, pai)\\n3.2.3 Elecci´ o de claus prim` aries\\nD’aqu´ ı en endavant es marcaran les claus prim` aries en negreta.\\nPERSONA( ideper , nom, cog, mai, dir)\\nAPODERAT( ideapo )\\nTORERO( idetor , ideapo)\\nACTUACIO( idact , idetor, datcor, nompla)\\nESDEVENIMENT( idesd , fircor, datcor, nompla)\\nRAMADERIA( cifram , nomram)\\nBOU( idbou , nombou, anybou, pesbou)\\nPLAC ¸A DE BOUS( nompla , anypla, locpla, tippla, estpla, muspla)\\nUBICACIO( ciu, pai )\\n7', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 7}), Document(page_content='3.2.4 Relacional\\nD’aqu´ ı en endavant es marcaran les claus foranes en cursiva.\\nPERSONA( ideper , nom, cog, mai, dir, ciu, pai )\\n{(ciu, pai) FK de la taula UBICACIO }\\nAPODERAT( ideapo )\\n{ideapo FK de la taula PERSONA }\\nTORERO( idetor ,ideapo )\\n{ideapo FK de la taula APODERAT }\\n{idetor FK de la taula PERSONA }\\nACTUACIO( idact ,idetor , datcor, idesd )\\n{idetor FK de la taula TORERO }\\n{idesd FK de la taula ESDEVENIMENT }\\nESDEVENIMENT( idesd , fircor, datcor, nompla ,idbou )\\n{idbou FK de la taula BOU }\\n{nompla FK de la taula PLAC ¸A DE BOUS }\\nRAMADERIA( cifram , nomram)\\nBOU( idbou , nombou, anybou, pesbou, cifram )\\n{cifram FK de la taula RAMADERIA }\\nPLAC ¸A DE BOUS( nompla , anypla, locpla, tippla, ciupla, paipla , estpla, muspla)\\n{(ciupla, paipla) FK de la taula UBICACIO }\\nUBICACIO( ciu, pai )\\n8', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 8}), Document(page_content='3.3 Model conceptual normalitzat\\nA continuaci´ o una imatge de com quedaria el model de dades normalitzat de la nostra base de dades:\\n3.3.1 Aclariments i suposicions\\nEn el model conceptual podem observar, en primer lloc, una her` encia anomenada PERSONA , que ens\\npermet encapsular tots aquells atributs que engloben un objecte persona. En aquest cas es tracta-\\nria tant de l’apoderat com el torero, ambd´ os amb pr` acticament els mateixos atributs, a excepci´ o\\ndels seus identificadors. Aquesta her` encia tindr` a una restricci´ o Mandatory, OR , la qual assegura\\nque, una persona, pot ser tant torero com apoderat en qualque moment de la seva vida. Aix` o\\n9', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 9}), Document(page_content='s’ha implementat aix´ ı perqu` e habitualment els apoderats solen ser persones amb experi` encia dins\\nel sector de la taurom` aquia i, per tant, poden haver estat toreros. Amb aquesta implementaci´ o,\\naconseguim una reducci´ o de la redund` ancia de dades a la nostra base de dades.\\nSeguidament, ens trobem les taules APODERAT iTORERO , les quals tenen una relaci´ o 1..1 i1..* .\\n´Es a dir, un torero podr` a tenir un ´ unic apoderat, per` o un apoderat podr` a tenir diversos toreros;\\nperqu` e els apoderats viuen pr` acticament de mentoritzar a aquests toreros i incl´ us tenen escoles\\ndedicades exclusivament. A continuaci´ o ens trobem amb la taula ACTUACIO , que est` a relacionada\\namb la taula TORERO amb una relaci´ o 1..* a0..* , la qual cosa significa que un torero pot haver\\nparticipat a zero actuacions o a moltes i que una actuaci´ o pot tenir com a protagonista un ´ unic\\ntorero; en cas d’estar torejant dos toreros en una mateixa actuaci´ o, tindr´ ıem dues actuacions al\\nmateix moment (la qual cosa ´ es molt poc probable).\\nA continuaci´ o trobem una relaci´ o entre les taules ACTUACIO iESDEVENIMENT , on una actuaci´ o\\nnom´ es pot estar assignada a esdeveniment i que un esdeveniment pot tenir definides de zero a\\nmoltes actuacions; per poder tenir en compte les noves actuacions que encara no han estat dutes\\na terme a un esdeveniment. Despr´ es tenim que la taula PLAC ¸A DE BOUS est` a relacionada amb la\\ntaula ESDEVENIMENT per una relaci´ o 0..* i1..1 .´Es a dir, una pla¸ ca de bous pot tenir de zero a\\nmolts esdeveniments i un esdeveniment pot tenir ´ unicament una pla¸ ca de bous associada. Despr´ es\\nla taula BOUque representa el bou que participa en l’esdeveniment concret. En aquest cas tindrem\\nuna relaci´ o 0..* a1..1 , ja que a un mateix esdeveniment nom´ es participar` a un bou, per` o un bou\\npodria participar en zero (en cas de no haver participat en cap) o m´ es d’un; ja que de vegades pot\\npassar. Despr´ es, a la taula RAMADERIA ens trobem una relaci´ o tamb´ e 0..* a1..1 que reflecteix\\ncom la ramaderia pot tenir en crian¸ ca diversos bous, per` o un bou nom´ es pot formar d’una rama-\\nderia.\\nD’altra banda, tenim la taula PLAC ¸A DE BOUS , la qual est` a relacionada amb ESDEVENIMENT amb\\nuna relaci´ o 0..* a1..1 ,´ es a dir, que una pla¸ ca de bous pot albergar diferents esdeveniments,\\nper` o un esdeveniment nom´ es es pot dur a terme a una pla¸ ca. Finalment, tenim la taula UBICACI ´O\\nque est` a relacionada tant amb la taula PLAC ¸A DE TOROS com amb PERSONA . Ambdues relacions\\nes componen d’una cardinalitat 1..* a1..1 , el que ens indica que una persona o una pla¸ ca\\nnom´ es podran tenir assignat una ´ unica ubicaci´ o (pa´ ıs i ciutat), per` o que una ubicaci´ o pot albergar\\ndiferents persones com places.\\n10', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 10}), Document(page_content=\"4.Implementaci´ o amb MySQL\\n4.1 Creaci´ o de l’espai d’emmagatzemament\\nPer a la creaci´ o de l’espai d’emmagatzemament de 5GB i fita m` axima de 10GB, haurem d’utilitzar\\nunTABLESPACE amb diversos par` ametres.\\n1 CREATE TABLESPACE tb_1\\n2 ADD DATAFILE 'tb_1.ibd'\\n3 ENGINE = InnoDB\\n4 INITIAL_SIZE = 5G\\n5 MAX_SIZE = 10G;\\nAquest ser` a creat al directori per defecte que t´ e MySQL a macOS /usr/local/var/mysql .\\n4.2 Creaci´ o de la base de dades i l’usuari IMPBD\\nPer crear la base de dades a MySQL Server haurem d’executar el seg¨ uent codi SQL:\\n1 CREATE DATABASE IF NOT EXISTS IMPBD\\n2 CHARACTER SET = 'utf8';\\n3\\n4 # Podem comprovar la correcta creaci´ o amb la comanda:\\n5 SHOW DATABASES;\\nA continuaci´ o creem l’usuari IMPBD i li donem permisos:\\n1 CREATE USER 'impbd' @'localhost' IDENTIFIED BY 'admin';\\n2 GRANT CREATE, INSERT, UPDATE, DELETE, REFERENCES ON IMPBD.* TO\\n'impbd' @'localhost'; ,→\\n3 FLUSH PRIVILEGES;\\n11\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 11}), Document(page_content='Ara, haurem d’iniciar mysql des de l’usuari creat i crear les respectives taules de la base de dades,\\nsegons els fitxers .csv aportats per la Real Federaci´ o Taurina d’Espanya.\\nPrimer haurem de seleccionar la base de dades:\\n1 USE IMPBD;\\nDespr´ es executarem el script SQL que crear` a les respectives taules que va adjunt a aquest treball\\ni est` a anomenat com Lluis Barca bdcorregudes bous mysql.sql .\\n4.2.1 Descripci´ o dels constraints ,checks itriggers implementats\\n•PERSONA\\n– Constraints\\n∗PRIMARY KEY :ideper ser` a la clau prim` aria per identificar a totes les persones.\\nAquesta clau realment ser` a l’identificador o del torero o de l’apoderat.\\n∗NOT NULL : Pr` acticament tots els atributs no poden ser NULL, per` o maiidir\\ns´ ı que ho poden ser, ja que tenim qualque persona que no t´ e aquestes dades.\\n•APODERAT\\n– Constraints\\n∗PRIMARY KEY :ideapo ser` a la clau prim` aria per identificar a una persona que\\n´ es apoderat.\\n∗FOREIGN KEY: ideapo ser` a tamb´ e la clau forana a la taula PERSONA .\\n∗NOT NULL : Aquesta taula nom´ es t´ e una columna i es tracta de la clau prim` aria,\\nper tant, no pot ser NULL mai.\\n•TORERO\\n– Constraints\\n∗PRIMARY KEY :idetor ser` a la clau prim` aria per identificar a una persona que\\n´ es torero.\\n∗FOREIG KEY :\\n·ideapo ser` a la clau forana de la taula APODERAT .\\n·idetor tamb´ e ser` a clau forana de la taula PERSONA .\\n∗NOT NULL : Totes les columnes seran NOT NULL, ja que s´ on o claus prim` aries\\no foranes.\\n12', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 12}), Document(page_content='•ACTUACIO\\n– Constraints\\n∗PRIMARY KEY :idact ser` a la clau prim` aria que ens permetr` a identificar les\\ndiferents actuacions. Aquesta s’autoincrementa cada vegada que s’insereix una\\nactuaci´ o.\\n∗FOREIGN KEY :\\n·idetor ser` a clau forana a la taula TORERO .\\n·idesd ser` a clau forana a la taula ESDEVENIMENT .\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•ESDEVENIMENT\\n– Constraints\\n∗PRIMARY KEY :idesd ser` a la clau prim` aria que ens permetr` a identificar els\\ndiferents esdeveniments. Aquesta s’autoincrementa cada vegada que s’insereix un\\nesdeveniment.\\n∗FOREIGN KEY :\\n·idbou ser` a la clau forana a la taula BOU.\\n·nompla ser` a la clau forana a la taula PLAC ¸A DEBOUS .\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•RAMADERIA\\n– Constraints\\n∗PRIMARY KEY :cifram ´ es el codi que identifica cada ramaderia faria de clau\\nprim` aria; vindria a ser una esp` ecie de NIF.\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•BOU\\n– Constraints\\n∗PRIMARY KEY :idbou ´ es el codi que identifica cada bou faria de clau prim` aria\\ni s’incrementa de forma autom` atica.\\n∗FOREIGN KEY :cifram ´ es la clau forana a la taula RAMADERIA .\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n•PLAC ¸A DEBOUS\\n– Constraints\\n∗PRIMARY KEY :nompla ´ es el nom de la pla¸ ca que seria la nostra clau prim` aria,\\nja que no volem tenir places duplicades.\\n∗FOREIGN KEY : La tupla ciupla, paipla ´ es la clau forana a la taula UBICACIO .\\n13', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 13}), Document(page_content=\"– Checks\\n∗tippla : Verifica que el valor d’aquesta columna sigui 0 o 1. Aquests valors ens\\ninformen de si la pla¸ ca de bous ´ es fixa o m` obil.\\n∗muspla : Verifica que el valor d’aquesta columna sigui 0 o 1. Aquests valors ens\\ninformen de si la pla¸ ca de bous t´ e o no museu.\\n•UBICACIO\\n– Constraints\\n∗PRIMARY KEY : La dupla ciu, pai efectuarien la funci´ o de clau prim` aria.\\n∗NOT NULL : Cap columna pot ser NULL, ja que contenen informaci´ o necess` aria.\\n4.3 Importaci´ o de les dades a IMPBD\\nEn primer lloc, s’ha fet una feina pr` evia d’exportaci´ o dels fitxers en format ODS al format CSV,\\namb la finalitat que es puguin importar les dades amb la comanda LOAD DATA LOCAL INFILE .\\nDespr´ es, per poder inserir dades de forma “autom` atica”, s’ha de modificar l’arxiu de configuraci´ o\\nde MySQL. Concretament s’ha d’afegir la seg¨ uent l´ ınia:\\n1 local_infile = 1\\nLa qual activa la funci´ o perqu` e el sistema de gesti´ o de base de dades permeti la inserci´ o de dades a\\ntrav´ es de la comanda descrita anteriorment. A continuaci´ o s’ha d’entrar a la terminal de MySQL\\namb l’usuari corresponent, per` o marcant el par` ametre local-infile a 1:\\n1 mysql --local-infile=1 -u IMPBD -p\\nA partir d’aqu´ ı, ja podem utilitzar els seg¨ uents scripts que s’han implementat per a la importaci´ o\\ntotal de les dades:\\n•APODERAT\\n1 LOAD DATA LOCAL INFILE\\n'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/APODERATS.csv' ,→\\n2 INTO TABLE APODERAT\\n3 FIELDS TERMINATED BY ','\\n4 LINES TERMINATED BY '\\\\n'\\n5 IGNORE 1 ROWS;\\n14\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 14}), Document(page_content='•TORERO\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/TOREROS.csv\\' ,→\\n2 INTO TABLE TORERO\\n3 FIELDS TERMINATED BY \\',\\'\\n4 LINES TERMINATED BY \\'\\\\n\\'\\n5 IGNORE 1 ROWS;\\n•PLAC ¸A DE BOUS\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/PLACES_BOUS.csv\\' ,→\\n2 INTO TABLE PLAC ¸A_DE_BOUS\\n3 FIELDS TERMINATED BY \\',\\'\\n4 LINES TERMINATED BY \\'\\\\n\\'\\n5 IGNORE 1 ROWS;\\n•ESDEVENIMENT\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/esdeveniments.csv\\' ,→\\n2 INTO TABLE ESDEVENIMENT\\n3 FIELDS TERMINATED BY \\',\\'\\n4 ENCLOSED BY \\'\"\\'\\n5 LINES TERMINATED BY \\'\\\\n\\';\\n•ACTUACIO\\n1 LOAD DATA LOCAL INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv/ACTUACIONS.csv\\' ,→\\n2 INTO TABLE ACTUACIO\\n3 FIELDS TERMINATED BY \\',\\'\\n4 LINES TERMINATED BY \\'\\\\n\\'\\n5 IGNORE 1 ROWS;\\n15', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 15}), Document(page_content=\"4.4 Creaci´ o de la base de dades DEFBD i l’usuari MIGBD\\nCrearem la base de dades utilitzant l’usuari root :\\n1 CREATE DATABASE IF NOT EXISTS DEFBD\\n2 CHARACTER SET = 'utf8';\\nI li assignarem els permisos pertinents a l’usuari MIGBD perqu` e pugui interactuar amb aquesta:\\n1 CREATE USER 'migbd' @'localhost' IDENTIFIED BY 'admin';\\n2 GRANT CREATE, SELECT, INSERT, REFERENCES ON DEFBD.* TO 'migbd' @'localhost';\\n3 FLUSH PRIVILEGES;\\nLlavors amb aquest usuari, podem inserir les taules a la base de dades DEFBD, utilitzant el codi\\nSQL que adjunt a la secci´ o 8.\\n4.5 Trasp` as de la informaci´ o de les taules creades amb l’u-\\nsuari IMPBD a l’usuari MIGBD\\nPer a efectuar la transfer` encia de les dades d’IMPBD a DEFBD, primer haurem d’accedir a MySQL\\namb l’usuari MIGBD i a continuaci´ o especificar la base de dades on importarem les dades:\\n1 USE DEFBD;\\nAra ja podem executar els diferents inserts que efectuaran la migraci´ o:\\n1 -- Taula UBICACIO\\n2 INSERT INTO DEFBD.UBICACIO (ciu, pai)\\n3 SELECT DISTINCT ciuapo, paiapo FROM IMPBD.APODERAT\\n4 UNION\\n5 SELECT DISTINCT ciutor, paitor FROM IMPBD.TORERO\\n6 UNION\\n7 SELECT DISTINCT ciupla, paipla FROM IMPBD.PLAC ¸A_DE_BOUS;\\n8\\n9 -- Taula PERSONA\\n10 DELIMITER $$\\n11\\n12 CREATE PROCEDURE migracio_persona()\\n13 BEGIN\\n14 DECLARE finished INTEGER DEFAULT 0;\\n15 DECLARE newID VARCHAR(10);\\n16\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 16}), Document(page_content=\"16 DECLARE exist INT;\\n17 DECLARE baseID INT DEFAULT 100000000;\\n18 DECLARE suffix CHAR(1);\\n19 DECLARE nom VARCHAR(255);\\n20 DECLARE cog VARCHAR(255);\\n21 DECLARE mai VARCHAR(255);\\n22 DECLARE dir VARCHAR(255);\\n23 DECLARE ciu VARCHAR(255);\\n24 DECLARE pai VARCHAR(255);\\n25 DECLARE cur CURSOR FOR\\n26 SELECT nomapo, CONCAT_WS(' ', co1apo, co2apo) AS cog, maiapo,\\ndirapo, ciuapo, paiapo FROM IMPBD.APODERAT ,→\\n27 UNION ALL\\n28 SELECT nomtor, CONCAT_WS(' ', co1tor, co2tor) AS cog, maitor,\\ndirtor, ciutor, paitor FROM IMPBD.TORERO; ,→\\n29 DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = 1;\\n30\\n31 OPEN cur;\\n32\\n33 read_loop: LOOP\\n34 FETCH cur INTO nom, cog, mai, dir, ciu, pai;\\n35 IF finished = 1 THEN\\n36 LEAVE read_loop;\\n37 END IF;\\n38\\n39 SET exist = 1;\\n40 WHILE exist = 1 DO\\n41 SET baseID = baseID + 1;\\n42 SET suffix = CHAR(65 + FLOOR(RAND() * 26));\\n43 SET newID = CONCAT(CAST(baseID AS CHAR(9)), suffix);\\n44\\n45 SELECT COUNT(*) INTO exist FROM DEFBD.PERSONA WHERE ideper =\\nnewID; ,→\\n46\\n47 IF exist = 0 THEN\\n48 INSERT INTO DEFBD.PERSONA (ideper, nom, cog, mai, dir, ciu,\\npai) ,→\\n49 VALUES (newID, nom, cog, mai, dir, ciu, pai);\\n50 SET exist = 0;\\n51 END IF;\\n52 END WHILE;\\n53 END LOOP read_loop;\\n54\\n55 CLOSE cur;\\n17\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 17}), Document(page_content=\"56 END$$\\n57\\n58 DELIMITER ;\\n59\\n60 -- Taula APODERAT\\n61 DELIMITER $$\\n62\\n63 CREATE PROCEDURE migracio_apoderat()\\n64 BEGIN\\n65 DECLARE apodID VARCHAR(10);\\n66 DECLARE personID VARCHAR(10);\\n67 DECLARE nom VARCHAR(255);\\n68 DECLARE co1 VARCHAR(255);\\n69 DECLARE co2 VARCHAR(255);\\n70 DECLARE mai VARCHAR(255);\\n71 DECLARE dir VARCHAR(255);\\n72 DECLARE ciu VARCHAR(255);\\n73 DECLARE pai VARCHAR(255);\\n74 DECLARE finished INT DEFAULT 0;\\n75 DECLARE cur CURSOR FOR SELECT ideapo, nomapo, co1apo, co2apo, maiapo,\\ndirapo, ciuapo, paiapo FROM IMPBD.APODERAT; ,→\\n76 DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = 1;\\n77\\n78 OPEN cur;\\n79\\n80 my_loop: LOOP\\n81 FETCH cur INTO apodID, nom, co1, co2, mai, dir, ciu, pai;\\n82 IF finished THEN\\n83 LEAVE my_loop;\\n84 END IF;\\n85\\n86 SELECT ideper INTO personID FROM DEFBD.PERSONA\\n87 WHERE nom = nom AND cog = CONCAT_WS(co1, ' ', co2) AND mai = mai AND\\ndir = dir AND ciu = ciu AND pai = pai ,→\\n88 LIMIT 1;\\n89\\n90 IF personID IS NOT NULL THEN\\n91 INSERT INTO DEFBD.APODERAT (ideapo) VALUES (personID);\\n92 END IF;\\n93 END LOOP;\\n94\\n95 CLOSE cur;\\n96 END$$\\n97\\n18\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 18}), Document(page_content=\"98 DELIMITER ;\\n99\\n100 -- Taula TORERO\\n101 DELIMITER $$\\n102\\n103 CREATE PROCEDURE migracio_torero()\\n104 BEGIN\\n105 DECLARE torID VARCHAR(10);\\n106 DECLARE personID VARCHAR(10);\\n107 DECLARE apoderatID VARCHAR(10);\\n108 DECLARE nom VARCHAR(255);\\n109 DECLARE co1 VARCHAR(255);\\n110 DECLARE co2 VARCHAR(255);\\n111 DECLARE mai VARCHAR(255);\\n112 DECLARE dir VARCHAR(255);\\n113 DECLARE ciu VARCHAR(255);\\n114 DECLARE pai VARCHAR(255);\\n115 DECLARE finished INT DEFAULT 0;\\n116 DECLARE cur CURSOR FOR SELECT idetor, nomtor, co1tor, co2tor, maitor,\\ndirtor, ciutor, paitor, ideapo FROM IMPBD.TORERO; ,→\\n117 DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = 1;\\n118\\n119 OPEN cur;\\n120\\n121 torero_loop: LOOP\\n122 FETCH cur INTO torID, nom, co1, co2, mai, dir, ciu, pai, apoderatID;\\n123 IF finished THEN\\n124 LEAVE torero_loop;\\n125 END IF;\\n126\\n127 SELECT ideper INTO personID FROM DEFBD.PERSONA\\n128 WHERE nom = nom AND cog = CONCAT_WS(' ', co1, co2) AND mai = mai AND\\ndir = dir AND ciu = ciu AND pai = pai ,→\\n129 LIMIT 1;\\n130\\n131 SELECT ideapo INTO apoderatID FROM DEFBD.APODERAT\\n132 JOIN DEFBD.PERSONA ON DEFBD.PERSONA.ideper = DEFBD.APODERAT.ideapo\\n133 JOIN IMPBD.APODERAT ON IMPBD.APODERAT.ideapo = apoderatID\\n134 WHERE IMPBD.APODERAT.nomapo = nom AND IMPBD.APODERAT.ciuapo = ciu\\nAND IMPBD.APODERAT.paiapo = pai ,→\\n135 LIMIT 1;\\n136\\n137 IF personID IS NOT NULL THEN\\n138 INSERT INTO DEFBD.TORERO (idetor, ideapo)\\n19\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 19}), Document(page_content='139 VALUES (personID, apoderatID);\\n140 END IF;\\n141 END LOOP;\\n142\\n143 CLOSE cur;\\n144 END$$\\n145\\n146 DELIMITER ;\\n147\\n148 -- Taula PLAC ¸A DE BOUS\\n149 INSERT INTO DEFBD.PLAC ¸A_DE_BOUS (nompla, anypla, locpla, tippla, ciupla,\\npaipla, estpla, muspla) ,→\\n150 SELECT nompla, anypla, locpla, tippla, ciupla, paipla, estpla, muspla FROM\\nIMPBD.PLAC ¸A_DE_BOUS; ,→\\n151\\n152 -- Taula RAMADERIA\\n153 INSERT INTO DEFBD.RAMADERIA (cifram, nomram)\\n154 SELECT DISTINCT cifram, nomram\\n155 FROM IMPBD.ESDEVENIMENT;\\n156\\n157 -- Taula BOU\\n158 INSERT INTO DEFBD.BOU (nombou, anybou, pesbou, cifram)\\n159 SELECT nombou, anybou, pesbou, cifram\\n160 FROM IMPBD.ESDEVENIMENT;\\n161\\n162 -- Taula ESDEVENIMENT\\n163 INSERT INTO DEFBD.ESDEVENIMENT (fircor, datcor, nompla, idbou)\\n164 SELECT\\n165 e.fircor,\\n166 e.datcor,\\n167 e.nompla,\\n168 (SELECT b.idbou\\n169 FROM DEFBD.BOU b\\n170 WHERE b.nombou = e.nombou AND b.anybou = e.anybou AND b.pesbou =\\ne.pesbou ,→\\n171 LIMIT 1)\\n172 FROM IMPBD.ESDEVENIMENT e;\\n173\\n174 -- Taula ACTUACIO\\n175 INSERT INTO DEFBD.ACTUACIO (idetor, datcor, idesd)\\n176 SELECT\\n177 t.idetor,\\n178 a.datcor,\\n179 e.idesd\\n20', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 20}), Document(page_content='180 FROM\\n181 IMPBD.ACTUACIO a\\n182 JOIN DEFBD.TORERO t ON a.idetor = t.idetor\\n183 JOIN DEFBD.ESDEVENIMENT e ON a.datcor = e.datcor AND a.nompla =\\ne.nompla; ,→\\n4.6 Consulta SQL\\nA continuaci´ o s’implementar` a la consulta per a la actualitzacio de les dates de naixement dels\\nbous.\\n4.6.1 Definicio de la consulta\\n1 UPDATE BOU b\\n2 JOIN ESDEVENIMENT e ON b.idbou = e.idbou\\n3 SET b.anybou = DATE_SUB(e.datcor, INTERVAL 2.5 YEAR)\\n4 WHERE DATE_SUB(e.datcor, INTERVAL 2.5 YEAR) > b.anybou;\\n4.6.2 Millores de rendiment\\nA continuaci´ o podem analitzar el pla d’execuci´ o de la consulta per intentar optimizar-la:\\n1 EXPLAIN UPDATE BOU b\\n2 JOIN ESDEVENIMENT e ON b.idbou = e.idbou\\n3 SET b.anybou = DATE_SUB(e.datcor, INTERVAL 2.5 YEAR)\\n4 WHERE DATE_SUB(e.datcor, INTERVAL 2.5 YEAR) > b.anybou;\\n21', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 21}), Document(page_content='En aquest cas afegirem dos ´ ındex i una condici´ o extra per millorar el filtratge:\\n1 ALTER TABLE IMPBD.ESDEVENIMENT ADD INDEX idx_datcor (datcor);\\n2 ALTER TABLE DEFBD.BOU ADD INDEX idx_anybou (anybou);\\n3\\n4 EXPLAIN UPDATE BOU b\\n5 JOIN ESDEVENIMENT e ON b.idbou = e.idbou\\n6 SET b.anybou = DATE_SUB(e.datcor, INTERVAL 2.5 YEAR)\\n7 WHERE e.datcor > fecha inicioANDe.datcor < =fecha final\\n8 AND b.anybou < DATE_SUB(e.datcor, INTERVAL 2.5 YEAR);\\n22', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 22}), Document(page_content=\"5.Migraci´ o a PostgreSQL\\n5.1 Configuraci´ o del FDW\\n5.1.1 Configuraci´ o a PostgreSQL\\nInstal ·lar l’extensi´ o (si no est` a instal ·lada):\\n1 CREATE EXTENSION IF NOT EXISTS postgres_fdw;\\nCrear un servidor FDW que apunti al servidor MySQL:\\n1 CREATE SERVER mysql_server FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host\\n'localhost', port '3306', dbname 'defbd'); ,→\\nEstablir l’usuari i contrasenya per a la connexi´ o:\\n1 CREATE USER mapping\\n2 FOR postgres\\n3 SERVER mysql_server\\n4 OPTIONS (user 'mysql_user', password 'admin');\\n5.2 Creaci´ o de l’espai d’emmagatzemament\\nAquest TABLESPACE quedar` a emmagatzemat a la ruta indicada, dins el directori espec´ ıfic per\\nemmagatzemar aquest tipus d’objectes.\\n1 CREATE TABLESPACE data\\n2 OWNER postgres\\n3 LOCATION '/usr/local/var/postgresql@14/pg_tblspc';\\n23\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 23}), Document(page_content=\"5.3 Creaci´ o de la base de dades FET i l’esquema Temp\\nCreem la base de dades assignant-li el TABLESPACE creat anteriorment:\\n1 CREATE DATABASE fet\\n2 WITH OWNER = postgres\\n3 TABLESPACE data;\\nA continuaci´ o l’esquema temp :\\n1 CREATE SCHEMA temp AUTHORIZATION postgres;\\n5.4 Gesti´ o d’usuaris i inserci´ o de dades a FET\\nPer a gestionar aquesta base de dades, crearem un usuari amb uns privilegis espec´ ıfics que podr` a\\ncrear, inserir i consultar les taules d’aquesta base de dades.\\n1 CREATE USER ufdw WITH PASSWORD 'admin';\\n2\\n3 GRANT CREATE, INSERT, SELECT ON ALL TABLES IN SCHEMA temp TO ufdw;\\n5.5 Consultes SQL\\n5.5.1 Mitjana de pes dels bous per any en qu` e es celebra la seva lidia\\n1 SELECT AVG(pesbou), EXTRACT(YEAR FROM datcor) AS any_lidia\\n2 FROM Temp.bous\\n3 GROUP BY any_lidia;\\n5.5.2 Bous s’han lidiat a l’estat espanyol\\n1 SELECT COUNT(*)\\n2 FROM Temp.bous;\\n24\", metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 24}), Document(page_content='6.Migraci´ o a Oracle\\nPer a la migraci´ o a Oracle, es far` a servir un contenidor de Docker amb la imatge d’Oracle en la\\nseva versi´ o 19.3.0 Standard 2 amb l’arquitectura Single Instance . Per tant, s’ha de tenir instal ·lat\\nDocker pr` eviament. En aquest cas, s’ha instal ·lat la versi´ o d’escriptori per a macOS que inclou la\\ninterf´ ıcie gr` afica per manejar Docker.\\n6.1 Configuraci´ o del gestor\\nEn primer lloc, haurem de clonar el repositori oficial d’Oracle, on est` a la imatge desitjada.\\n1 git clone https://github.com/oracle/docker-images.git\\nA continuaci´ o baixarem la versi´ o d’Oracle indicada anteriorment, des de la p` agina web oficial, i\\nl’inserirem dins el directori /19.3.0 de la imatge clonada.\\nAra executarem el programa corresponent per construir el contenidor:\\n1 sudo ./buildContainerImage.sh -v 19.3.0 -s\\nHem de treure la mem` oria virtual total al meu sistema (macOS):\\n1 sysctl vm.swapusage\\nQue ens retorna el valor de 2048M. Per tant, els valors de:\\n•SGA = 2048 * 0.5 = 1024 MB\\n•PGA = 2048 * 0.15 = 307 MB\\n25', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 25}), Document(page_content='Per tant, la comanda quedar` a tal que aix´ ı:\\n1 sudo docker run -d --name oracle_bd \\\\\\n2 -p 1521:1521 -p 5500:5500 \\\\\\n3 -e ORACLE_SID=FET \\\\\\n4 -e ORACLE_PDB=FETPDB1 \\\\\\n5 -e INIT_SGA_SIZE=1024 \\\\\\n6 -e INIT_PGA_SIZE=307 \\\\\\n7 -e ENABLE_ARCHIVING=true \\\\\\n8 oracle/database:19.3.0-se2\\n6.2 Creaci´ o de l’usuari Utest i gesti´ o dels seus privilegis\\nA continuaci´ o creem l’usuari amb els privilegis corresponents per gestionar la base de dades:\\n1 CREATE USER utest IDENTIFIED BY admin;\\n2 GRANT CREATE SESSION, CREATE TABLE, INSERT, SELECT ON utest.* TO utest;\\n6.3 Migraci´ o de dades\\nAquesta part, com nom´ es necessitem unes quantes taules, ho farem mitjan¸ cant l’exportaci´ o a ar-\\nxius CSV de la base de dades de MySQL. Aquests arxius despr´ es els importarem a la base de dades\\nd’oracle.\\n6.3.1 Exportaci´ o de dades\\nA continuaci´ o els diferents codis SQL per a cada una de les taules de la base de dades de MySQL\\nper a efectuar la correcta exportacio:\\n1 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/UBICACIO.csv\\' ,→\\n2 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n3 LINES TERMINATED BY \\'\\\\n\\'\\n4 FROM UBICACIO;\\n5\\n6 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/PLAC ¸A_DE_BOUS.csv\\' ,→\\n7 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n26', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 26}), Document(page_content='8 LINES TERMINATED BY \\'\\\\n\\'\\n9 FROM PLAC ¸A_DE_BOUS;\\n10\\n11 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/ESDEVENIMENT.csv\\' ,→\\n12 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n13 LINES TERMINATED BY \\'\\\\n\\'\\n14 FROM ESDEVENIMENT;\\n15\\n16 SELECT * INTO OUTFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/BOU.csv\\' ,→\\n17 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n18 LINES TERMINATED BY \\'\\\\n\\'\\n19 FROM BOU;\\n6.3.2 Creaci´ o de taules\\nLa creaci´ o de taules s’ha dut a terme com ´ es habitual i trobarem el codi implementat a la secci´ o 8.\\n6.3.3 Importaci´ o de dades\\nPer tant, s’haur` a de crear un arxiu per a cada fitxer del qual vulguem importar les dades. A\\ncontinuaci´ o el codi corresponent a cada un dels fitxers per a la seva corresponents taula:\\n1 LOAD DATA\\n2 INFILE \\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/UBICACIO.csv\\'\\n3 INTO TABLE UBICACIO\\n4 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n5 (ciu, pai)\\n6\\n7 LOAD DATA\\n8 INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/PLAC ¸A_DE_BOUS.csv\\' ,→\\n9 INTO TABLE PLAC ¸A_DE_BOUS\\n10 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n11 (nompla, anypla, locpla, tippla, ciupla, paipla, estpla, muspla)\\n12\\n13 LOAD DATA\\n14 INFILE \\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/BOU.csv\\'\\n15 INTO TABLE BOU\\n16 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n17 (idbou, nombou, anybou, pesbou, cifram)\\n27', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 27}), Document(page_content='18\\n19 LOAD DATA\\n20 INFILE\\n\\'/Users/luisbarcap/Desktop/sgbd_recu_final/csv_oracle/ESDEVENIMENT.csv\\' ,→\\n21 INTO TABLE ESDEVENIMENT\\n22 FIELDS TERMINATED BY \\',\\' OPTIONALLY ENCLOSED BY \\'\"\\'\\n23 (idesd, fircor, datcor, nompla, idbou)\\nA continuaci´ o utilitzem SQL Loader que ens permetr` a amb la seg¨ uent comanda, importar cada un\\ndels fitxers:\\n1 sqlldr USERID=utest/admin @oracle_db CONTROL=nom_fitxer.ctl\\nLOG=nom_fitxer.log ,→\\nElnomfitxer fa refer` encia a cada un dels diferents CSV.\\n6.4 Consulta SQL\\n6.4.1 Definici´ o de la consulta\\nNom i ubicaci´ o de la pla¸ ca de bous, juntament amb el nombre de bous que s’han torejat al llarg\\nde tota la hist` oria en ella.\\n1 SELECT\\n2 pb.nompla AS \"Nom de la Pla¸ ca de Bous\",\\n3 u.ciu AS \"Ciutat\",\\n4 u.pai AS \"Pa´ ıs\",\\n5 COUNT(b.idbou) AS \"Nombre de Bous Torejats\"\\n6 FROM PLAC ¸A_DE_BOUS pb\\n7 JOIN UBICACIO u ON pb.ciu = u.ciu AND pb.pai = u.pai\\n8 JOIN ESDEVENIMENT e ON pb.nompla = e.nompla\\n9 JOIN BOU b ON e.idbou = b.idbou\\n10 GROUP BY\\n11 pb.nompla, u.ciu, u.pai;\\n28', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 28}), Document(page_content='7.Conclusions\\nAquest treball ha evidenciat la interacci´ o entre la teoria i la pr` actica en el domini de la gesti´ o de\\nbases de dades, cosa que conjuntament amb l’enfrontament amb desafiaments reals i la resoluci´ o\\nde problemes inesperats han afavorit una comprensi´ o profunda dels sistemes de gesti´ o de bases de\\ndades. La necessitat d’adaptabilitat i un enfocament anal´ ıtic per superar obstacles s’ha convertit\\nen una pedra angular del proc´ es d’aprenentatge.\\nDurant el desenvolupament del projecte, s’han identificat i superat m´ ultiples reptes, des de q¨ uesti-\\nons de normalitzaci´ o de dades fins a l’optimitzaci´ o de consultes SQL. La implementaci´ o d’un model\\nde dades en un escenari real ha proporcionat una bona oportunitat per aplicar els coneixements\\nadquirits i ha demostrat ser una experi` encia enriquidora.\\nEn resum, els objectius establerts a l’inici han estat assolits amb ` exit, confirmant la relaci´ o entre\\nla teoria apresa i la seva aplicaci´ o pr` actica. El treball no nom´ es compleix amb les expectatives\\nacad` emiques sin´ o que tamb´ e serveix com a testimoni del valor de l’experi` encia pr` actica adquirida.\\nEls resultats obtinguts i les habilitats desenvolupades formen ara part de la meva preparaci´ o\\nprofessional, sent testimonis del meu creixement i evoluci´ o en l’` ambit de la inform` atica i la gesti´ o\\nde dades.\\n29', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 29}), Document(page_content='Bibliografia\\n[1] Documentaci´ o de MySQL, 2023, Manual de MySQL 8.3 Recuperat de https://dev.mysql.\\ncom/doc/refman/8.3/en/\\n[2] Documentaci´ o de PostgreSQL 2023, Manual de PostgreSQL 14 Recuperat de https://www.\\npostgresql.org/docs/14/index.html\\n[3] Oracle Database container images, 2023, Installation, configuration, and environment setup\\nRecuperat de https://github.com/oracle/docker-images/blob/main/OracleDatabase/\\nSingleInstance/README.md\\n30', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 30}), Document(page_content='8.Annex I: Codi SQL\\n8.1 Codi de MySQL\\n*Important llegir els aclariments sobre algunes decisions al final del codi*\\n1 CREATE TABLE UBICACIO (\\n2 ciu VARCHAR(255) NOT NULL,\\n3 pai VARCHAR(255) NOT NULL,\\n4 PRIMARY KEY (ciu, pai)\\n5 );\\n6\\n7 CREATE TABLE PERSONA (\\n8 ideper VARCHAR(10) NOT NULL,\\n9 nom VARCHAR(255) NOT NULL,\\n10 cog VARCHAR(255) NOT NULL,\\n11 mai VARCHAR(255),\\n12 dir VARCHAR(255),\\n13 ciu VARCHAR(255) NOT NULL,\\n14 pai VARCHAR(255) NOT NULL,\\n15 PRIMARY KEY (ideper),\\n16 FOREIGN KEY (ciu, pai) REFERENCES UBICACIO(ciu, pai)\\n17 );\\n18\\n19 CREATE TABLE APODERAT (\\n20 ideapo VARCHAR(10) NOT NULL,\\n21 PRIMARY KEY (ideapo),\\n22 FOREIGN KEY (ideapo) REFERENCES PERSONA(ideper)\\n23 );\\n24\\n25 CREATE TABLE TORERO (\\n26 idetor VARCHAR(10) NOT NULL,\\n27 ideapo VARCHAR(10) NOT NULL,\\n28 PRIMARY KEY (idetor),\\n29 FOREIGN KEY (ideapo) REFERENCES APODERAT(ideapo),\\n30 FOREIGN KEY (idetor) REFERENCES PERSONA(ideper)\\n31', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 31}), Document(page_content='31 );\\n32\\n33 CREATE TABLE PLAC ¸A_DE_BOUS (\\n34 nompla VARCHAR(255) NOT NULL,\\n35 anypla DATE NOT NULL,\\n36 locpla INT NOT NULL,\\n37 tippla BOOLEAN NOT NULL,\\n38 ciupla VARCHAR(255) NOT NULL,\\n39 paipla VARCHAR(255) NOT NULL,\\n40 estpla TEXT,\\n41 muspla BOOLEAN NOT NULL,\\n42 PRIMARY KEY (nompla),\\n43 FOREIGN KEY (ciupla, paipla) REFERENCES UBICACIO(ciu, pai),\\n44 CHECK (tippla IN (True, False)),\\n45 CHECK (muspla IN (True, False))\\n46 );\\n47\\n48 CREATE TABLE RAMADERIA (\\n49 cifram INT NOT NULL,\\n50 nomram VARCHAR(255) NOT NULL,\\n51 PRIMARY KEY (cifram)\\n52 );\\n53\\n54 CREATE TABLE BOU (\\n55 idbou INT NOT NULL AUTO_INCREMENT,\\n56 nombou VARCHAR(255) NOT NULL,\\n57 anybou DATE NOT NULL,\\n58 pesbou NUMERIC(5, 2) NOT NULL,\\n59 cifram INT NOT NULL,\\n60 PRIMARY KEY (idbou),\\n61 FOREIGN KEY (cifram) REFERENCES RAMADERIA(cifram)\\n62 );\\n63\\n64 CREATE TABLE ESDEVENIMENT (\\n65 idesd INT NOT NULL AUTO_INCREMENT,\\n66 fircor VARCHAR(255) NOT NULL,\\n67 datcor DATE NOT NULL,\\n68 nompla VARCHAR(255) NOT NULL,\\n69 idbou INT NOT NULL,\\n70 PRIMARY KEY (idesd),\\n71 FOREIGN KEY (idbou) REFERENCES BOU(idbou),\\n72 FOREIGN KEY (nompla) REFERENCES PLAC ¸A_DE_BOUS(nompla)\\n73 );\\n74\\n32', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 32}), Document(page_content='75 CREATE TABLE ACTUACIO (\\n76 idact INT NOT NULL AUTO_INCREMENT,\\n77 idetor VARCHAR(10) NOT NULL,\\n78 datcor DATE NOT NULL,\\n79 idesd INT NOT NULL,\\n80 PRIMARY KEY (idact),\\n81 FOREIGN KEY (idetor) REFERENCES TORERO(idetor),\\n82 FOREIGN KEY (idesd) REFERENCES ESDEVENIMENT(idesd)\\n83 );\\n8.2 Aclariments sobre el codi SQL\\nLa majoria de les columnes amb el tipus de dades VARCHAR tenen una longitud m` axima de 255\\nbytes. Aix` o ´ es aix´ ı perqu` e aquest tipus d’estructura de dades a MySQL utilitzen la mem` oria\\nper emmagatzemar les dades en funci´ o del que hagin d’emmagatzemar. Per` o, utilitzen un byte\\nextra per emmagatzemar la longitud m` axima, es dona el cas que 255 ´ es el m` axim per a 1 byte\\n(segons la documentaci´ o oficial) i, per tant, tindria el mateix impacte un VARCHAR(20) que un de\\nVARCHAR(255) . D’aquesta forma, en les columnes on no s’especifica una llarg` aria m` axima, oferim\\nun rang bastant ampli per si un cas.\\n33', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 33}), Document(page_content='8.3 Codi d’Oracle\\n1 CREATE TABLE UBICACIO (\\n2 ciu VARCHAR2(255) NOT NULL,\\n3 pai VARCHAR2(255) NOT NULL,\\n4 CONSTRAINT pk_ubicacio PRIMARY KEY (ciu, pai)\\n5 );\\n6\\n7 CREATE TABLE PLAC ¸A_DE_BOUS (\\n8 nompla VARCHAR2(255) NOT NULL,\\n9 anypla DATE NOT NULL,\\n10 locpla NUMBER NOT NULL,\\n11 tippla NUMBER(1) NOT NULL,\\n12 ciupla VARCHAR2(255) NOT NULL,\\n13 paipla VARCHAR2(255) NOT NULL,\\n14 estpla CLOB,\\n15 muspla NUMBER(1) NOT NULL,\\n16 CONSTRAINT pk_pla¸ ca_de_bous PRIMARY KEY (nompla),\\n17 CONSTRAINT fk_pla¸ ca_de_bous_ubicacio FOREIGN KEY (ciupla, paipla)\\nREFERENCES UBICACIO(ciu, pai), ,→\\n18 CONSTRAINT ck_pla¸ ca_de_bous_tippla CHECK (tippla IN (0, 1)),\\n19 CONSTRAINT ck_pla¸ ca_de_bous_muspla CHECK (muspla IN (0, 1))\\n20 );\\n21\\n22 CREATE TABLE BOU (\\n23 idbou NUMBER NOT NULL,\\n24 nombou VARCHAR2(255) NOT NULL,\\n25 anybou DATE NOT NULL,\\n26 pesbou NUMBER(7, 2) NOT NULL,\\n27 cifram NUMBER NOT NULL,\\n28 CONSTRAINT pk_bou PRIMARY KEY (idbou),\\n29 CONSTRAINT fk_bou_ramaderia FOREIGN KEY (cifram) REFERENCES\\nRAMADERIA(cifram) ,→\\n30 );\\n31\\n32 CREATE TABLE ESDEVENIMENT (\\n33 idesd NUMBER NOT NULL,\\n34 fircor VARCHAR2(255) NOT NULL,\\n35 datcor DATE NOT NULL,\\n36 nompla VARCHAR2(255) NOT NULL,\\n37 idbou NUMBER NOT NULL,\\n38 CONSTRAINT pk_esdeveniment PRIMARY KEY (idesd),\\n39 CONSTRAINT fk_esdeveniment_bou FOREIGN KEY (idbou) REFERENCES\\nBOU(idbou), ,→\\n34', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 34}), Document(page_content='40 CONSTRAINT fk_esdeveniment_pla¸ ca_de_bous FOREIGN KEY (nompla) REFERENCES\\nPLAC ¸A_DE_BOUS(nompla) ,→\\n41 );\\n8.4 Aclariments sobre el codi SQL\\nNom´ es s’han implementat les taules necess` aries per fer la consulta demanada, tal com s’especifica\\nals requisits del treball.\\nCal afegir que, a Oracle per exemple, no existeixen els valors AUTO INCREMENT i, per tant, s’haurien\\nde crear seq¨ u` encies i posteriorment triggers que fessin aquesta funci´ o. Per` o per temes de simplicitat,\\nno s’ha dut a terme perqu` e no s’utilitzarien.\\n35', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 35}), Document(page_content='9.Annex II: Scripts de neteja\\n•ACTUACIONS\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n9\\n10 # Eliminem les columnes que no ens interessen\\n11 data = pd.read_csv(output_file)\\n12 data[\"DATCOR\"] = data[\"DATCOR\"].str[:10] # Nom´ es ens quedam amb la\\ndata ,→\\n13 data.to_csv(output_file, index=False)\\n14\\n15 if __name__ == \"__main__\":\\n16 convert_ods_csv(\"./ACTUACIONS.ods\", \"./csv/ACTUACIONS.csv\")\\n•APODERATS\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n9\\n10 # Eliminem les columnes que no ens interessen\\n11 data = pd.read_csv(output_file)\\n36', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 36}), Document(page_content='12 data = data.iloc[:, :-2]\\n13\\n14 # Eliminem les cometes dobles i els espais en blanc de la\\ncolumna DIRAPO ,→\\n15 data[\"DIRAPO\"] = data[\"DIRAPO\"].str.strip().str.replace(\\'\"\\',\\n\\'\\') ,→\\n16 data.to_csv(output_file, index=False)\\n17\\n18 if __name__ == \"__main__\":\\n19 convert_ods_csv(\"./APODERATS.ods\", \"./csv/APODERATS.csv\")\\n•PLACES BOUS\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n9\\n10 # Eliminem l\\'hora de la columna ANYPLA\\n11 data = pd.read_csv(output_file)\\n12 data[\"ANYPLA\"] = data[\"ANYPLA\"].str[:10] # Mantenim nom´ es la\\ndata ,→\\n13 data.to_csv(output_file, index=False)\\n14\\n15 if __name__ == \"__main__\":\\n16 convert_ods_csv(\"./PLACES_BOUS.ods\", \"./csv/PLACES_BOUS.csv\")\\n•TORERO\\n1 import pandas as pd\\n2\\n3 def convert_ods_csv(input_file, output_file):\\n4 # Llegim el fitxer ODS\\n5 data = pd.read_excel(input_file, engine=\"odf\")\\n6\\n7 # Salvem el fitxer com a CSV\\n8 data.to_csv(output_file, index=False)\\n37', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 37}), Document(page_content='9\\n10 # Eliminem les dues ´ ultimes columnes buides\\n11 data = pd.read_csv(output_file)\\n12 data = data.iloc[:, :-2]\\n13\\n14 # Eliiminam les cometes dobles i els espais en blanc de la\\ncolumna DIRTOR ,→\\n15 data[\"DIRTOR\"] = data[\"DIRTOR\"].str.strip().str.replace(\\'\"\\',\\n\\'\\') ,→\\n16 data.to_csv(output_file, index=False)\\n17\\n18 if __name__ == \"__main__\":\\n19 convert_ods_csv(\"./TOREROS.ods\", \"./csv/TOREROS.csv\")\\n38', metadata={'source': './data/Practica_Final_Recuperació.pdf', 'page': 38})]\n"
     ]
    }
   ],
   "source": [
    "pdf_files = []\n",
    "for file_ in os.listdir(DATA_PATH):\n",
    "    if file_.endswith(\".pdf\"):\n",
    "        pdf_files.append(file_)\n",
    "\n",
    "files = []\n",
    "for file_ in pdf_files:\n",
    "    loader = PyPDFLoader(file_path=os.path.join(DATA_PATH, file_))\n",
    "    pages = loader.load()\n",
    "    files.append(pages)\n",
    "\n",
    "print(files)\n",
    "print(len(files))\n",
    "print(files[0][1].page_content)\n",
    "print(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grado en Ingenier ´ıa Inform ´atica\\nEvaluaci´ on y Comportamiento de los Sistemas Inform´ aticos\\nCuaderno de Pr´ acticas\\nLluis Barca Pons\\nlluis.barca1@estudiant.uib.es\\n6 de junio de 2022', 'Pr´ actica 1\\nPara la realizaci´ on de esta pr´ actica contaremos con los servidores A y B los cuales est´ an dedicados\\na tareas de c´ alculo cient´ ıfico. Es decir, las cargas que ejecutan son intensivas en CPU, y, por lo\\ntanto, este es su dispositivo m´ as demandado. A continuaci´ on, se detallan las caracter´ ısticas de\\ncada uno de los servidores.\\nServidor A\\nNombre del servidor: Dell Power Edge T430\\nN´ umero de CPUs: 16\\nTama˜ no de la memoria RAM: 7753Mib ( ≈8GB)\\nCoste: 1245 e\\nServidor B\\nNombre del servidor: Dell Power Edge T330\\nN´ umero de CPUs: 8\\nTama˜ no de la memoria RAM: 15258,8Mib ( ≈16GB)\\nCoste: 907 e\\nEl administrador de un centro de datos se enfrenta al reto de decidir qu´ e servidor es m´ as adecuado\\npara la ejecuci´ on de una carga intensiva de CPU, el servidor A o el servidor B. Actualmente, el\\ntiempo medio para ejecutar la carga en el servidor es de 31,01 segundos. Para realizar una justa\\ncomparaci´ on, se ha ejecutado la carga intensiva de CPU en los servidores A y B un total de 10\\nveces, obteniendo los resultados mostrados a continuaci´ on.\\nTiempo de ejecuci´ on (s)\\nServidor A Servidor B\\n24,15 27,01\\n23,18 26,18\\n25,01 26,56\\n23,34 28,02\\n22,65 26,78\\n24,54 27,43\\n23,46 27,34\\n22,38 26,04\\n23,54 27,19\\n23,59 27,43\\nTiempo medio: 23,584 26,998\\n1', '1. ¿Qu´ e servidor resulta m´ as adecuado para el cambio solamente considerando el\\nrendimiento? ¿Por qu´ e? ¿En qu´ e m´ etrica o valor determina la decisi´ on?\\nPara decidir que servidor es el m´ as adecuado con respecto al actual, tenemos que comprar la\\naceleraci´ on de los respectivos servidores.\\nA:TO\\nTA=31,01\\n23,584= 1,3149\\nB:TO\\nTB=31,01\\n26,998= 1,1490\\nFinalmente, podemos concluir que, considerando ´ unicamente el rendimiento, el servidor A ofrecer´ ıa\\nuna mayor mejora. Concretamente, el servidor A es aproximadamente 1,3149 veces m´ as r´ apido, o\\nun 31,49 % mejor, respecto al servidor original.\\n2. ¿Y si adem´ as tenemos en cuenta el coste del servidor? ¿Cu´ al ser´ ıa m´ as adecuado?\\n¿Por qu´ e? ¿En qu´ e m´ etrica o valor te basas?\\nSi ahora tenemos en cuenta el coste de dichos servidores, deberemos analizarlo con otro ´ ındice. En\\neste caso, si le damos m´ as importancia al coste del servidor, obtendremos los siguientes ´ ındices de\\ncada uno de ellos. En primer lugar, el ´ ındice del servidor A:\\nRatio−Rendimiento/Coste A=1\\nCoste A∗TA=1\\n1245e∗23,584s= 0,000034058 = 3 ,4058∗10−5\\nY, por otro lado, el ´ ındice del servidor B:\\nRatio−Rendimiento/Coste B=1\\nCoste B∗TB=1\\n907e∗26,998s= 0,000040838 = 4 ,0838∗10−5\\nAhora, si dividimos los ´ ındices\\nIndice B\\nIndice A=4,0838∗10−5\\n3,4058∗10−5= 1,2\\nPodemos observar que el servidor A es un 20 % m´ as rentable que el servidor B.\\n3. ¿C´ omo crees que afectan los recursos hardware de los servidores? ¿Tienen alg´ un\\ntipo de trascendencia en la decisi´ on?\\nEn efecto, los recursos hardware en los servidores son un factor importante a la hora de decidir si\\nun servidor es mejor o peor para el uso que le queramos dar\\nHabitualmente podemos pensar que la mejora de hardware en un servidor se manifestar´ a como\\nuna mejor lineal del rendimiento. Por ejemplo, si tenemos un servidor que ejecuta una carga en\\nun tiempo de ejecuci´ on tcon una mejora del hardware k, el tiempo de ejecuci´ on no ser´ at\\n2si la\\nmejora realizada es 2 k; esta mejora en funci´ on del tiempo no suele seguir una funci´ on lineal\\nEn conclusi´ on, la decisi´ on a tomar si tiene alg´ un tipo de transcendencia porque esta mejora de\\nrendimiento se tiene que ver compensada con el coste de dicha mejora.\\n2', 'Pr´ actica 2\\nPara la realizaci´ on de esta pr´ actica, el alumno ya contar´ a con el entorno Ubuntu (o el que ha-\\nya considerado) instalado, siendo totalmente funcional. Para asegurarnos de que el entorno est´ a\\ntotalmente listo, se deber´ a poder acceder al directorio /proc. Adem´ as, se contar´ a ya con una he-\\nrramienta para filtrar y limpiar los ficheros de datos como para realizar representaciones gr´ aficas.\\nEn esta pr´ actica no se tendr´ a en cuenta qu´ e tipo de actividad est´ a realizando el sistema mientras\\nse realiza la monitorizaci´ on del mismo. Antes de empezar a responder las diferentes partes, se\\nrecomienda probar los monitores, sus filtros, el volcado de ficheros y el tratamiento de los mismos.\\nMonitorizaci´ on de la CPU\\nEn esta primera parte, se pide monitorizar la CPU durante 1 hora haciendo uso del monitor TOP.\\nLos datos obtenidos ( ´UTILES) deber´ an ser guardados en un fichero de salida para posteriormente\\ntratarlos y responder a las siguientes preguntas:\\n1. ¿Cu´ antas CPUs tiene el sistema que se ha monitorizado? ¿De d´ onde se ha obtenido\\nesa informaci´ on?\\nEl sistema monitorizado tiene 8 CPUs dedicadas a soportar la carga del trabajo. Esta informaci´ on\\nse ha obtenido utilizando el comando que se muestra a continuaci´ on:\\nDonde claramente nos indica que el n´ umero de CPUs es 8.\\n2. ¿Cu´ al es la utilizaci´ on media de la CPU en modo usuario, sistema y en global?\\nPara obtener los datos que se nos pide, se ha monitorizado la CPU durante 1h con intervalos\\nde muestreo de 15 minutos. Se ha decidido tomar este intervalo para poder compararlo con los\\ndatos obtenidos de la monitorizaci´ on de la memoria principal. De esta forma mantendremos una\\nconsistencia en los datos presentados.\\nConcretamente, utilizaremos el monitor TOP para registrar los valores de la CPU del sistema, en\\nmodo usuario y la global. El comando concreto es el siguiente:\\n1 top -b -d 15 -n 242 | grep -i \"Cpu(s)\" > topCPU.txt\\n3', \"Podemos observar que en los par´ ametros le indicamos la frecuencia de muestreo en primer lugar y\\nel total de muestras a realizar, que equivalen a 1h. Observamos un aumento en dos unidades del\\ntotal de muestras a realizar; esto se debe a que la primera y la ´ ultima muestra las descartamos para\\nuna menor contaminaci´ on de los datos (esto se aplicara en todos los procesos de monitorizaci´ on\\nque se realicen). A continuaci´ on, con el comando grep indicamos los datos del comando TOP que\\nqueremos almacenar; en este caso los de la CPU. Todo ello transferido a un fichero de texto que\\npodremos consultar al final del proceso de monitorizaci´ on.\\nAhora necesitamos sacar la columna que nos interese en cada caso. Para ello utilizaremos el si-\\nguiente comando:\\n1 cat topCPU.txt | awk '{print $x}' > columnaX.txt\\nEl comando catnos permite coger el fichero deseado y meterlo en la terminal. A continuaci´ on con\\nel comando awkpodemos filtrar la columna que nos interese. En este caso, filtraremos por colum-\\nnas, donde xes el n´ umero de la columna que queramos almacenar. Concretamente nos interesan\\nlas columnas 2, 4 y 6, que son respectivamente la de usuario, de sistema y inactiva. Para obtener\\nla utilizaci´ on de CPU global se ha restado la inactiva a la total (en este caso 100 %). Finalmente\\nenviamos esta informaci´ on filtrada a un nuevo fichero para no sobreescribir el de origen.\\nCon todos estos datos a disposici´ on, podemos realizar las correspondientes medias utilizando una\\nhoja de Excel. Los resultados obtenidos son los siguientes:\\nMedias en %\\nCPU Global CPU Sistema CPU Usuario\\n0,17 0,02 0,12\\nCabe a˜ nadir que este proceso de filtrado por columna se llevara a cabo cuando sea necesario, sin\\nmencionarlo expl´ ıcitamente, en las pr´ oximas monitorizaciones.\\n3. ¿C´ omo se comportan las medidas anteriores a lo largo del tiempo de observaci´ on?\\nMuestra las tres m´ etricas de forma gr´ afica.\\nLas m´ etricas expuestas a continuaci´ on muestran un comportamiento similar entre ellas. Esto se\\ndebe a que en los primeros 15 minutos, se ha realizado alg´ un uso del sistema (aunque sea bajo)\\ny en el resto de tiempo este se encuentra pr´ acticamente inutilizado, ya que no realizaba ning´ un\\ntrabajo.\\nEs necesario comentar que los ejes Y de las gr´ aficas no tienen el mismo valor m´ aximo. Estos valores\\nson din´ amicos con el objetivo de poder observar con mayor detalle las gr´ aficas que tienen valores\\nm´ as peque˜ nos. En cambio, si se mantuviera un valor m´ aximo fijo e igual, alguna detalles de la\\ngr´ afica no podrian ser apreciados.\\n4\", '4. ¿Cu´ al es la sobrecarga provocada por el monitor TOP?\\nLa sobrecarga del monitor la obtendremos registrando la informaci´ on que nos devuelve el monitor\\nTIME cuando ejecutamos el monitor TOP para una ´ unica muestra.\\n1 time top -b -d 1 -n 1 | grep -i \"Cpu(s)\" > sobrecargaTOP.txt\\nPor tanto, obtendremos la sobrecarga dividiendo el tiempo real que tarda el monitor en realizar\\nuna muestra (obtenido con el monitor TIME), entre el tiempo de muestreo; como se muestra en\\nla siguiente f´ ormula:\\nSobrecarga =0,182s\\n15s∗100 = 1 ,21 %\\n5', 'Monitorizaci´ on de la memoria principal\\nEn esta segunda parte, se pide monitorizar la memoria principal del sistema durante 1 hora hacien-\\ndo uso del monitor VMSTAT con un intervalo de muestreo de 15 segundos. Los datos obtenidos\\n(´UTILES) deber´ an ser guardados en un fichero de salida para posteriormente tratarlos y responder\\na las siguientes preguntas:\\n1. ¿Qu´ e capacidad total tiene la memoria principal del sistema? ¿De d´ onde se ha\\nobtenido ese dato?\\nPara saber la capacidad total de memoria principal que tiene el sistema, utilizaremos monitor\\nTOP, que entre muchas cosas tambi´ en nos muestra la memoria total. Esto lo obtendremos con el\\nsiguiente comando:\\n1 top -b -d 1 -n 1 | grep -i \"KiB Mem\"\\nAl monitor TOP le asignamos unos par´ ametros, simplemente para que no este activo constante-\\nmente, y a continuaci´ on con el comando grep podemos extraer el valor de la memoria principal; el\\ncual nos dar´ a: 8074700 KiB .\\n2. ¿Cu´ al es la utilizaci´ on media de la memoria? ¿Y la capacidad media utilizada?\\nPara obtener los datos para realizar las respectivas medias, se ha monitorizado la memoria principal\\ndurante 1h en un intervalo de 15 segundos. Concretamente, utilizaremos el monitor VMSTAT para\\nregistrar los valores de la memoria libre. El comando concreto es el siguiente:\\n1 vmstat 15 242 -n > vmstatMEM.txt\\nUna vez recogidos todos los datos, podemos obtener la columna que nos informa del valor de la\\nmemoria libre del sistema realizando el siguiente comando, para efectuar el filtrado:\\n1 cat vmstatMEM.txt | awk \\'{print $4}\\' > MEMlibre.txt\\nFinalmente, en este ´ ultimo fichero tendremos todos los valores de memoria libre que ha registrado\\nel monitor. Para obtener la memoria utilizada, debemos restar al total de la memoria principal el\\nvalor de la memoria libre. Es con este valor con el que se ha calculado tanto la utilizaci´ on media\\ncomo la capacidad media utilizada de la memoria, utilizando una hoja de Excel. Los resultados\\nobtenidos son los siguientes:\\nUtilizaci´ on Media (KiB) Capacidad Media ( %)\\n3.806.916 47,15\\n6', '3. ¿C´ omo se comporta la utilizaci´ on de la memoria y la capacidad utilizada? Repre-\\nsenta estas m´ etricas gr´ aficamente.\\nDurante el proceso de monitorizaci´ on, observamos dos picos en las gr´ aficas. Estos se deben a que\\nen los primeros minutos del proceso de monitorizaci´ on, estaban abiertas ciertas ventanas del gestor\\nde ficheros; adem´ as de realizarse algunos movimientos de ficheros entre directorios. El resto del\\ntiempo no se realiz´ o ning´ un trabajo concreto, por tanto, la carga de trabajo que vemos se deber´ a\\na los procesos internos del propio sistema operativo.\\n4. ¿Cu´ al es la sobrecarga provocada por el monitor VMSTAT?\\nPara obtener la sobrecarga del monitor, primero deberemos registrar el tiempo de ejecuci´ on del\\nmonitor VMSTAT; para luego dividirlo entre el tiempo de muestreo. Para lo comentado en primera\\ninstancia, utilizaremos el monitor TIME, el cual nos permitir´ a registrar el tiempo de ejecuci´ on del\\nmonitor TOP para una ´ unica muestra.\\n1 time vmstat 1 1 -n > sobrecarga_VMSTAT.txt\\nPor tanto, obtendremos la sobrecarga como se muestra en la siguiente f´ ormula:\\nSobrecarga =0,007s\\n15s∗100 = 0 ,05 %\\n7', 'Monitorizaci´ on de la CPU y de la memoria principal al mismo tiempo\\nSe desea monitorizar un sistema inform´ atico con el fin de conocer el comportamiento de la CPU\\ny la memoria principal. De la CPU se desea estudiar la utilizaci´ on en modo usuario, sistema y la\\nutilizaci´ on de forma global. Por otra parte, de la memoria principal se desea estudiar la capacidad\\ny la utilizaci´ on de la misma.\\n1. Determinar el monitor o monitores m´ as adecuados para obtener la informaci´ on\\nsolicitada.\\nLos monitores m´ as adecuados para obtener dicha informaci´ on son, por un lado, el TOP para\\nmonitorizar los valores de la CPU y el VMSTAT para la memoria principal.\\n2. Monitorizar el sistema durante 90 minutos, recogiendo la informaci´ on ´ util cada 30\\nsegundos. La informaci´ on ´ util deber´ a ser almacenada en un fichero de salida.\\nPara monitorizar el sistema se utilizar´ an los monitores comentados en el apartado anterior, ambos\\nejecutados a la vez, en terminales diferentes. Por un lado, el monitor TOP:\\n1 top -b -d 30 -n 182 | grep -i \"Cpu(s)\" > topCPU.txt\\nSus par´ ametros nos indica que la frecuencia de muestreo ser´ a cada 30 segundos y en total se rea-\\nlizaran 182 muestras. Todo ello almacenado en un fichero de texto de salida, para su posterior\\nfiltrado y tratado de datos.\\nEsto equivale a los 90 minutos exigidos en el enunciado. Aunque como siempre, realizamos dos\\nmuestras extras para descartar los extremos, con la finalidad de tener unos datos menos contami-\\nnados.\\nY, por otro lado, el monitor VMSTAT:\\n1 vmstat 30 182 -n > vmstatMEM.txt\\nEl cual tambi´ en vemos una semejanza con el monitor VMSTAT en cuanto a los par´ ametros es-\\ntablecidos. Toda la informaci´ on recogida, al igual que con el otro monitor, se almacenara en un\\nfichero de texto de salida para su posterior filtrado y tratado.\\n8', '3. Calcular la media para la utilizaci´ on de la CPU en modo usuario, sistema y la\\nutilizaci´ on global. Tambi´ en, calcular la media para la capacidad y la utilizaci´ on de la\\nmemoria principal.\\nEn este apartado, con todo el trabajo realizado en los apartados anteriores, solo tendremos que\\nintroducir los datos en un Excel para calcular las medias. Los resultados son los que se muestran\\na continuaci´ on:\\nMedias\\nCPU Memoria Principal\\nGlobal Sistema Usuario Capacidad Utilizaci´ on\\n0,28 % 0,03 % 0,21 % 3.953.994 KiB 48,97 %\\n4. Graficar todos los resultados obtenidos durante los 90 minutos de monitorizaci´ on\\ndel sistema.\\nA continuaci´ on los datos graficados de la CPU:\\n9', 'Y aqu´ ı los datos de la memoria principal:\\n5. Calcular la sobrecarga que ejerce el monitor (o los monitores) sobre el sistema.\\nLa sobrecarga en este caso ser´ a la de los dos monitores a la vez. Esto es as´ ı porque tenemos dos\\nmonitores ejecut´ andose en paralelo, que consumir´ an recursos a la vez. Por tanto, la sobrecarga\\nfinal que ejercer´ an estos monitores sobre el sistema ser´ a la suma de ambos monitores.\\nVM TOP\\n0s 0,007s 0,182s 30s\\nCon esta imagen se intenta mostrar de forma gr´ afica el paralelismo de los monitores. Es por eso\\nque debemos realizar la suma de ambos, para obtener la sobrecarga total sobre el sistema.\\nPrimero calcularemos la sobrecarga que ejerce el monitor TOP:\\nSobrecarga =0,182s\\n30s∗100 = 0 ,6 %\\nY ahora la sobrecarga que ejerce el monitor VMSTAT:\\nSobrecarga =0,007s\\n30s∗100 = 0 ,02 %\\nFinalmente, nos queda esta sobrecarga:\\nSobrecarga =Sobrecarga TOP+Sobrecarga V MSTAT = 0,6 % + 0 ,02 % = 0 ,62 %\\n10', 'Pr´ actica 3\\nEn la pr´ actica 1 se presentaron los servidores A y B como alternativas al sistema actual. Adem´ as,\\nse afirm´ o que los dos servidores ejecutaban cargas de CPU, concretamente, el servidor A ejecuta la\\ncarga Sysbench CPU y el servidor B la carga Stress-ng. A continuaci´ on, se muestran los tiempos\\nde ejecuci´ on de cada servidor para determinadas configuraciones de carga y % de uso de la CPU:\\nTiempos de ejecuci´ on (s)\\nServidor A Servidor B\\nConfiguraci´ onCarga = 250000\\n% CPU = 50Carga = 300000\\n% CPU = 100\\nEjecuci´ on 1 24,15 27,01\\nEjecuci´ on 2 23,18 26,18\\nEjecuci´ on 3 25,01 26,56\\nEjecuci´ on 4 23,34 28,02\\nEjecuci´ on 5 22,65 26,78\\nEjecuci´ on 6 24,54 27,43\\nEjecuci´ on 7 23,46 27,34\\nEjecuci´ on 8 22,38 26,04\\nEjecuci´ on 9 23,54 27,19\\nEjecuci´ on 10 23,59 27,43\\nTiempo medio 23,584 26,998\\n11', 'Evaluaci´ on del sistema actual\\nPara la evaluaci´ on del sistema actual, se utilizar´ a la carga Sysbench CPU con un porcentaje de\\nuso de la CPU del 50 %, la cual se ejecutar´ a en el sistema actual y se har´ an uso de las t´ ecnicas\\nde monitorizaci´ on ya aprendidas en la pr´ actica anterior. De este modo, se pide responder a las\\nsiguientes preguntas.\\n1. Explica con detalle c´ omo es el dise˜ no y la implementaci´ on del experimento para\\nevaluar el sistema actual. Se deben justificar las decisiones tomadas, desde el n´ umero\\nde muestras que se van a tomar hasta qu´ e monitores se van a lazar y por qu´ e.\\nPara llevar a cabo el dise˜ no y la implementaci´ on de este experimento, se seguir´ a el siguiente\\ndiagrama que representa una metodolog´ ıa para el estudio del rendimiento de sistemas.\\n12', 'En primer lugar, el sistema que vamos a evaluar tiene las siguientes propiedades; todas ellas\\nobtenidas a trav´ es del comando lscpu u obtenidas de pr´ acticas anteriores:\\nPropiedas Sistema Actual\\nArquitectura 64 bits\\nCapacidad de memoria 8074700 KiB\\nProcesador Intel Core i5-8250U 1.6-3.4GHz\\nN´ umero de CPUs 8\\nA continuaci´ on definimos las cargas a ejecutar en el sistema actual. Estas ser´ an lanzadas con\\nel benchmark sysbench (centrado en la obtenci´ on de n´ umeros primos) y ser´ an de 25000, 50000,\\n100000, 150000 y 250000. Las cuatro primeras se ejecutar´ an porque b´ asicamente es lo que se nos\\npide en el enunciado y la ´ ultima ser´ a para, en los siguientes apartados, poder comparar el sistema\\nactual con uno de los propuestos; que se ha estresado con el mismo benchmark y con una carga de\\n250000. Tambi´ en se configurara el benchmark para que estrese el 50 % de la CPU, lo que quiere\\ndecir que estresara un total de 4 CPUs.\\nCon este conjunto de cargas podremos observar si al aumentar el n´ umero de n´ umeros primos a\\nbuscar, el tiempo de respuesta del sistema aumenta de forma lineal o no. Dependiendo de dichos\\nresultados, podremos afirmar que no hay la misma cantidad de n´ umeros primos entre los distintos\\nrangos, a pesar de ser una carga el doble que la otra.\\nPara realizar el experimento, se utilizar´ a el sysbench (como se ha comentado anteriormente) para\\nestresar la CPU y los monitores que recoger´ an las muestras necesarias son el top, para la CPU y\\nvmstat para la memoria. Para calcular la frecuencia de muestreo de los monitores, se ha ejecutado\\nunsysbench para cada carga mencionada anteriormente, para as´ ı obtener el tiempo que tarda\\ncada una. A continuaci´ on esta carga se ejecuta 5 veces para posteriormente hacer una media del\\ntiempo de respuesta resultante. Esto se realiza de esta forma para garantizar, estad´ ısticamente,\\nque esos tiempos de respuesta son realmente los que tardan cada carga (aunque para un estudio\\nreal se deber´ ıan hacer 10 o m´ as ejecuciones). Se ha decidido la frecuencia de muestreo en funci´ on\\ndel tiempo de respuesta m´ as bajo; en este caso el de la primera carga. A continuaci´ on los diferentes\\ntiempos de respuesta:\\nCarga Tiempo de respuesta (s) Ejecuciones Total (s)\\n25000 8 + 2 5 50\\n50000 20 + 2 5 110\\n100000 55 + 2 5 285\\n150000 100 + 2 5 510\\n250000 202 + 2 5 1020\\nSuma total: 1975\\nPodemos observar un tiempo a˜ nadido en cada carga de 2 segundos. Este es porque realizamos una\\nmonitorizaci´ on (tanto de la CPU como de la memoria) y en el script de monitorizaci´ on tenemos un\\nsleep de 2 segundos cada vez que acaba una ejecuci´ on de cualquier carga. Con esto conseguimos\\n13', 'saber cuando inicia y finaliza una ejecuci´ on de una carga por los picos que se producen en las\\ngr´ aficas. Por tanto, para saber cuantas veces deber´ an registrar los monitores el total de muestras,\\nse calcula dividiendo el tiempo total de respuesta entre la frecuencia de muestreo.\\nMuestras =1975\\n2= 988\\nDe todas formas, para realizar la monitorizaci´ on real, se han cogido algunas muestras extras por si\\nun caso alg´ un monitor tuviera alg´ un tipo de problema o para corregir el redondeo de los tiempos\\nde respuesta de cada carga obtenidos anteriormente. Una vez obtenidos todos estos par´ ametros,\\npodremos ejecutar los respectivos scripts que nos realizaran el trabajo de forma secuencial y au-\\ntom´ atica.\\nCabe mencionar que las condiciones del sistema actual han intentado ser las m´ as ´ optimas posibles.\\nSe ha mantenido el sistema con un 100 % de carga, enchufado a la corriente el´ ectrica y a tempera-\\ntura ambiente, durante todo el transcurso del experimento. Adem´ as, no se ha utilizado el sistema\\npara realizar ninguna otra tarea que no fuese ejecutar el respectivo benchmark o los monitores.\\n´Unicamente pod´ ıa haber procesos propios del sistema operativo de autogesti´ on en los cuales el\\nusuario no tiene acceso. Todo ello con el objetivo de conseguir unas muestras fiables y aptas para\\npoder comparar posteriormente con otros sistemas de la forma m´ as igualada posible.\\n2. ¿C´ omo se comporta el sistema actual si variamos la carga var´ ıa en 25000, 50000,\\n100000 y 150000 n´ umeros primos? ¿C´ omo es el comportamiento del tiempo de respues-\\nta y la productividad? Indica el valor para cada una de las ejecuciones del experimento\\ny la media entre todos ellas.\\nSi variamos la carga entre los valores expuestos, el sistema se va a comportar de la misma forma,\\ncomo vemos en las gr´ aficas generales a continuaci´ on:\\nEn la primera observamos la utilizaci´ on de CPU que se mantiene al 50 %, como era de esperar.\\nAl lanzar un benchmark que estresa este componente al 50 %, lo esperado es que durante todas\\nlas cargas el tanto por ciento de CPU sea ese. Cabe mencionar que se nos pide observar como\\n14', 'se comporta el sistema en cada carga, pero en las gr´ aficas se muestra el conjunto de ellas. El\\nobjetivo es poder visualizar con mayor perspectiva y no mostrar tantas representaciones gr´ aficas\\nque podr´ ıan dificultar el entendimiento de los datos recogidos. Por tanto, con esta representaci´ on\\npodemos apreciar las diferentes ejecuciones y/o cargas y sus respectivos valles.\\nPor otro lado, por lo que hace a la memoria, tambi´ en se ha representado con una perspectiva global\\nde todas las cargas. Apreciamos que dicha memoria se mantiene pr´ acticamente igual durante el\\ntranscurso del experimento. De hecho, era lo esperado, ya que las cargas inyectadas (b´ usquedas\\nde n´ umeros primos) no intervienen en dicha memoria y, por tanto, su uso solo se debe a lo que el\\npropio sistema necesita para estar funcionando.\\nA continuaci´ on los valores obtenidos de cada carga tanto de los tiempos de respuesta como de la\\nproductividad:\\nCarga Tiempo de respuesta (s) Productividad (W/T)\\n25000 8 3333\\n50000 20 2500\\n100000 55 1818\\n150000 100 1500\\n250000 202 1238\\nMedias 77 1822\\nSeguidamente los gr´ aficos respectivos:\\nEl tiempo de respuesta, como podemos observar en los valores obtenidos, tiende subir de forma\\nbastante pronunciada. Por otro lado, la productividad tiende a bajar a medida que la carga au-\\nmenta. Esto nos indica que a un mayor n´ umero de cargas, el sistema tiende a tardar m´ as y a ser\\nmenos productivo; pero no sigue una tendencia lineal. Esto se debe realmente a que cada vez nos\\nencontramos con un menor n´ umero de n´ umeros primos. Adem´ as de que al no tener ”memoria”, ca-\\nda vez que aumentamos la carga, el sistema debe recorrer los n´ umeros primos que ya ha recorrido.\\n15', '3. ¿Cu´ al es el porcentaje de CPU y de memoria del sistema para cada una de las\\ncargas ejecutadas? ¿Por qu´ e se produce ese comportamiento? Mu´ estralo gr´ aficamente\\na lo largo del tiempo de ejecuci´ on de la carga.\\nA continuaci´ on las respectivas gr´ aficas de la utilizaci´ on de CPU de cada carga:\\n16', 'Seguidamente, las gr´ aficas de la capacidad de memoria utilizada:\\nComo observamos, tanto en la CPU como en la memoria, los valores se mantienen igual. Esto,\\ncomo se ha comentado durante el experimento, es lo esperado; ya que el sysbench estresa el 50 %\\nde la CPU y la memoria no se utiliza para realizar la b´ usqueda de n´ umeros primos.\\n17', 'Comparaci´ on del sistema actual con el servidor A y B\\nPara la comparaci´ on del sistema actual con los servidores A y B se har´ an uso de los datos propor-\\ncionados anteriormente en la tabla. Se deber´ a aplicar la t´ ecnica de benchmarking para realizar la\\ncomparaci´ on teniendo en cuenta la carga que ejecuta cada uno de los servidores, as´ ı como su nivel\\nde uso de los recursos de CPU. Adem´ as, se deber´ an contestar las siguientes cuestiones.\\n1. Explica detalladamente c´ omo se va a realizar el proceso de benchmarking. Se de-\\nber´ an justificar todas las decisiones que se han tomado al respecto.\\nPara llevar a cabo el dise˜ no y la implementaci´ on de este experimento, se seguir´ a el diagrama\\nexpuesto en el apartado anterior.\\nEl sistema actual tiene las propiedades representadas en la tabla del apartado anterior y la carga\\nejecutada con el benchmark stress ser´ a de 300000. Esta carga se ejecutar´ a 5 veces para garantizar\\nque los datos obtenidos son lo m´ as realista posibles. Para ello, se utilizar´ an los scripts mencionados\\nal principio del experimento y que se podr´ an encontrar al final de esta documentaci´ on. En este\\ncaso, el benchmark stress ser´ a configurado para estresar el 100 % de las CPUs, que corresponde a\\nun total de 8.\\nPor lo que hace a los monitores, se utilizaran los mismos que en el apartado anterior, el toppara\\nmonitorizar el estado de la CPU y el vmstat para hacer lo respectivo con la memoria. Estos\\nmonitores tienen como par´ ametros la frecuencia de muestreo y el total de ejecuciones que deber´ ıa\\nhacer el monitor. Como la carga tarda aproximadamente 238s en ejecutarse por completo, ejecutar\\n5 veces dicha carga m´ as un sleep de 2s entre ejecuciones, nos deja un tiempo total de 1200s; lo\\ncual equivale a 600 muestras. De todas formas, como es habitual, recogeremos algunas muestras\\nm´ as con el monitor para corregir el redondeo de los tiempos de respuesta obtenidos.\\nPor lo que hace a las condiciones del sistema actual, se han buscado las condiciones ´ optimas para\\nrealizar el experimento con la mayor objetividad posible. Se ha mantenido el sistema a un 100 % de\\ncarga y conectado a la red el´ ectrica durante toda la prueba. Adem´ as, no se ha utilizado el sistema\\npara realizar ninguna otra tarea que no fuera ejecutar el benchmark y los monitores. ´Unicamente\\nse han podido ejecutar procesos propios del sistema operativo, necesarios para mantenerlo activo.\\n18', '2. Considerando solamente el rendimiento de los servidores, ¿cambiar´ ıas el sistema\\nactual por el servidor A? ¿Y por el B? ¿Por qu´ e?\\nSi tenemos en cuenta ´ unicamente el rendimiento de ambos sistemas, entonces deberemos comparar\\nlas respectivas productividades:\\nXA=Trabajo\\nTiempo=250000 W\\n23,584s= 10600 W/s\\nXB=Trabajo\\nTiempo=300000 W\\n26,998s= 11112 W/s\\nXActual −Sysbench =Trabajo\\nTiempo=250000 W\\n202s= 1237 W/s\\nXActual −Stress =Trabajo\\nTiempo=300000 W\\n237,41s= 1263 W/s\\nObservamos claramente como ambos servidores son mejores que el sistema actual. Cabe recordar\\nque no ser´ ıa una comparaci´ on justa decir que el Servidor B tiene una mejor productividad que el\\nServidor A, ya que ambos han sido estresados con benchmarks distintos, totalmente diferentes.\\nSi ahora nos disponemos a hacer las respectivas aceleraciones:\\nAA−Actual =XA\\nXActual −Sysbench=10600\\n1237= 8,57\\nAB−Actual =XB\\nXActual −Stress=11112\\n1263= 8,8\\nEntonces podemos afirmar que ambos servidores son, aproximadamente, 8 veces mejor que el\\nsistema actual. Y, por tanto, realizar el cambio del sistema actual por ambos servidores ser´ ıa una\\ndecisi´ on acertada.\\n3. Si adem´ as consideramos el coste econ´ omico, ¿cambiar´ ıas el sistema actual por el\\nservidor A? ¿Y por el B? ¿Por qu´ e?\\nEn primer lugar, debemos calcular el rendimiento que hemos sacado sobre el dinero invertido en\\ncada sistema. Esto se calcular´ a dividiendo la productividad entre el coste de cada uno.\\nRendimiento −Coste A=XA\\nCoste A=10600\\n1245e= 8,51\\nRendimiento −Coste B=XB\\nCoste B=11112\\n907e= 12,25\\n19', 'Rendimiento −Coste Actual −Sysbench =XActual\\nCoste Actual=1237\\n700e= 1,77\\nRendimiento −Coste Actual −Stress =XAcual\\nCoste Actual=1263\\n700e= 1,8\\nAunque la forma habitual de calcular el rendimiento coste sea:\\nX=1\\nRendimiento ×Coste\\ncreo que calculando las productividades, el ´ ındice resultante es m´ as visual. De todas formas, ambos\\nc´ alculos son linealmente y dar´ ıan resultados proporcionales.\\nSi ahora nos disponemos a calcular las respectivas aceleraciones:\\nAA−Actual =Rendimiento −Coste A\\nRendimiento −Coste Actual −Sysbench=8,51\\n1,77= 4,8\\nAB−Actual =Rendimiento −Coste B\\nRendimiento −Coste Actual −Stress=12,25\\n1,8= 6,8\\nPor tanto, podemos observar que el servidor A es 4,8 y el servidor B 6,8 veces mejor en lo que se\\nrefiere al rendimiento sacado sobre la inversi´ on realizada, que el sistema actual. Por tanto, realizar\\nun cambio de cualquiera de los servidores por el sistema actual, ser´ ıa una decisi´ on totalmente\\nacertada.\\n4. ¿C´ omo influye la carga ejecutada en los servidores A y B en la decisi´ on de cambio?\\nEn primer lugar, hay que diferenciar entre los benmchmarks ejecutados en cada servidor. Por un\\nlado, el sysbench realiza una b´ usqueda de n´ umeros primos entre 0 y la carga inyectada (por ejemplo\\n25000). Y en este caso, al no haber una proporci´ on entre el n´ umero de n´ umeros primos que hay\\nentre dos valores, a mayor carga el tiempo de respuesta no aumenta linealmente. Por otro lado, el\\nstress realiza diferentes operaciones con enteros, n´ umeros en coma flotante, pruebas del registro 0\\ndel procesador, entre otras. La gran diferencia es que dichas operaciones si muestran una tendencia\\nlineal cuando la carga varia.\\nEn conclusi´ on, la carga ejecutada en los servidores si influye en la decisi´ on de cambio; todo depen-\\nder´ a del objetivo con el que queramos adquirir un sistema. Si comparamos, respectivamente, cada\\nservidor con el sistema actual, entonces podemos afirmar con total seguridad que los servidores\\nson mejores. Pero no podemos asegurar que el servidor B sea mejor o peor que el A realizando\\nb´ usquedas de n´ umeros primos, o viceversa con los diferentes tipos de operaciones.\\n20', 'Scripts\\nA continuaci´ on el script que ejecuta los distintos monitores:\\n1#!/bin/bash\\n2\\n3if [ -z \"$1\" ]; then # Check monitor\\n4 echo \"Define a valid moitor <top, vm>\"\\n5 exit 1\\n6else\\n7 case $1 in\\n8 help)\\n9 echo \"Usage: mon <top vm> <delay> <messures>\"\\n10 exit 1\\n11 ;;\\n12 top);;\\n13 vm) ;;\\n14 *)\\n15 echo \"Define a valid moitor <top, vm>\"\\n16 exit 1\\n17 ;;\\n18 esac\\n19fi\\n20\\n21if [ -z \"$2\" ]; then # Check delay\\n22 echo \"Define a delay\"\\n23 exit 1\\n24else\\n25\\n26 if [ \"$2\" -lt 1 ]; then # delay < 1\\n27 echo \"Define a valid range of delay. d > 1\"\\n28 exit 1\\n29 fi\\n30fi\\n31\\n32if [ -z \"$3\" ]; then # Check messures\\n33 echo \"Define the number of messures\"\\n34 exit 1\\n35else\\n36 if [ \"$3\" -lt 1 ]; then # messures < 1\\n37 echo \"Define a valid range of messures. n > 1\"\\n38 exit 1\\n39 fi\\n40fi\\n21', '41\\n42# Correct syntax\\n43mkdir \"./monitor\" > /dev/null 2>&1\\n44echo \"=== Starting monitor ===\"\\n45\\n46printf \"Work in process... \"\\n47case $1 in\\n48 top)\\n49 top -b -d \"$2\" -n \"$3\" | grep \"%Cpu(s):\" > tempCPU\\n50\\n51 sed -i \\'s/ni,100.0/ni, 100.0/g\\' tempCPU # Add space to nice\\ntime. Avoid bug with awk ,→\\n52 awk \\'{print $2, $4, $8}\\' tempCPU > \"./monitor/TOP.txt\" # Data\\nfiltering ,→\\n53 rm tempCPU\\n54 ;;#break\\n55\\n56 vm)\\n57 vmstat \"$2\" \"$3\" -n >tempVM\\n58\\n59 sed -i \\'1,2d\\' tempVM # Remove first and second line (header)\\n60 awk \\'{print $4}\\' tempVM > \"./monitor/VM.txt\"\\n61 rm tempVM\\n62 ;;#break\\n63esac\\n64\\n65echo \"Done\"\\n22', 'A continuaci´ on el script que ejecuta los distintos benchmarks:\\n1#!/bin/bash\\n2\\n3case $1 in\\n4 help)\\n5 echo \"Usage: bench <sysbench stress> <number cpus> <number\\niterations>\" ,→\\n6 exit 1;\\n7 ;;\\n8 sysbench) ;;\\n9 stress) ;;\\n10 *)\\n11 echo \"Define a valid monitor <sysbench stress>\"\\n12 exit 1\\n13 ;;\\n14esac\\n15\\n16if [ -z \"$2\" ]\\n17then # Check number of cpus\\n18 echo \"Define the number of cpus\"\\n19 exit 1\\n20else\\n21 if [ \"$2\" -lt 1 ]\\n22 then # Number of cpus < 1\\n23 echo \"Define a valid number of cpus\"\\n24 exit 1\\n25 fi\\n26fi\\n27\\n28if [ -z \"$3\" ]\\n29then # Check number of iterations\\n30 echo \"Define the number of iterations\"\\n31 exit 1\\n32else\\n33 if [ \"$3\" -lt 1 ]\\n34 then # Number of iterations < 1\\n35 echo \"Define a valid number of iterations n > 1\"\\n36 exit 1\\n37 fi\\n38fi\\n39\\n40\\n41\\n23', '42for i in 25000 50000 100000 150000 250000\\n43do\\n44 echo \"=== Start workload $i ===\"\\n45 j=1\\n46\\n47 while [ \"$j\" -le \"$3\" ]; do\\n48 echo \"$1 iteration $j...\"\\n49\\n50 case $1 in\\n51 sysbench)\\n52 sysbench --test=cpu --cpu-max-prime=\"$i\"\\n--num-threads=\"$2\" run ,→\\n53 ;;# Break\\n54\\n55 stress)\\n56 stress-ng --cpu=\"$2\" --cpu-ops=\"$i\"\\n57 ;;# Break\\n58 esac\\n59\\n60 echo \"Done\"\\n61 j=$((j + 1))\\n62\\n63 sleep 2\\n64 done\\n65 echo \"\"\\n66done\\n* Cabe remarcar que en caso de querer usar otras cargas, se deber´ an modificar desde el script.\\n24', 'Pr´ actica 4\\nBloque 1\\nSe pide responder las siguientes cuestiones:\\n1. ¿Cu´ al es la principal diferencia entre la evaluaci´ on de sistemas mediante la experi-\\nmentaci´ on real y el modelado?\\nLa principal diferencia es que con la primera estamos trabajando con un sistema real y con la\\nsegunda con uno “inventado”. En consecuencia, el sistema real no sigue ninguna funci´ on (ya que\\nel sistema puede experimentar diferentes actividades no esperadas) y el modelo si, es por eso que\\nnunca va a fallar (independientement del sistema real).\\n2. ¿Qu´ e relaci´ on hay entre ellas?\\nLa relaci´ on es que podemos trabajar sobre ambas para realizar los c´ alculos necesarios para la im-\\nplementaci´ on de un sistema cualquiera. Es decir, el modelo nos podria servir para inyectar posibles\\ncargas reales y poder evaluar como se comporta el sistema. Por otro lado, la experimentaci´ on real\\nayuda a mejorar el modelo que tenemos.\\n3. ¿C´ omo podr´ ıamos combinar ambas formas de evaluaci´ on? Explica detalladamente\\nc´ omo podr´ ıamos combinarlas con un ejemplo de la vida real.\\nAmbas formas deber´ ıan combinarse. B´ asicamente, porque el objetivo de los modelos es recrear\\nde manera ficticia la realidad; con el objetivo de estresar al sistema con ese modelo y observar si\\nsoportar´ ıa una situaci´ on real similar. Aunque debemos ser conscientes de que el modelo es algo\\ninventado y, por tanto, la realidad siempre puede sorprendernos. En consecuencia, tener un modelo\\nes necesario para predecir (en la medida de lo posible) lo que nuestro sistema deber´ a soportar.\\nPara entenderlo mejor, el ejemplo del servidor es muy claro. Tenemos un servidor que anualmente\\nrecibe una serie de peticiones (por ejemplo registros de matr´ ıculas de una universidad) que suelen\\nser similares, a˜ no tras a˜ no. Entonces, el administrador del sistema puede recrear un modelo con\\nlos datos obtenidos del mismo sistema (o datos externos, como por ejemplo el n´ umero de personas\\nque ha aprobado selectividad en la misma zona) y testear el servidor para ver si soportara la carga.\\nA partir de all´ ı ya seria decisi´ on del administrador si los resultados obtenidos son fiables o no para\\nafrontar el siguiente periodo de matr´ ıculas.\\n25', 'Bloque 2\\nConsideremos la carga Stress-ng ejecutada en la pr´ actica 3. En concreto, el que es ejecutado al\\n100 % de uso de la CPU. De la ejecuci´ on de esta carga se obtuvo un tiempo medio de respuesta.\\nAdem´ as, ahora se concreta que el tiempo medio de ejecuci´ on es de 1,23 segundos. Tambi´ en, la\\nCPU recibe una media de dos programas por segundo (del tipo Stress-ng).\\nSe pide calcular:\\n1. Utilizaci´ on media del procesador.\\nSi aplicamos la hip´ otesis de equilibrio de flujo, entonces podemos aplicar la Ley de la Utilizaci´ on.\\nEn este caso, al recibir la CPU 2 trabajos por segundo, nuestra λ= 2. Adem´ as, nuestro tiempo\\nmedio de ejecuci´ on es de 1,23s, como se indica en el enunciado. Por tanto, la utilizaci´ on se calcular´ ıa\\nde la siguiente forma:\\nU=X×S=λ×S= 2×1,23 = 2 ,46≃246 %\\nComo la utilizaci´ on es mayor al 100 % entonces podemos deducir que el sistema est´ a saturado y,\\npor tanto, es seguro que si no ha colapsado, colapsara en cualquier momento. Entonces, para que\\nel sistema tenga una utilizaci´ on del 100 %, necesitar´ ıamos reducir el tiempo de servicio a 0,5s o\\nbajar la productividad a 0,813 trabajos/s.\\n2. Tiempo medio de espera en la cola del procesador.\\nEl tiempo de espera, es aquel en el cual un trabajo se encuentra en la cola de trabajos para ser\\nservido. Este se puede calcular si restamos al tiempo total, el tiempo de ejecuci´ on. Por tanto, el\\nresultado se calcular´ ıa de la siguiente forma:\\nWi=Ri−Si= 26,998s−1,23s= 25,768s\\n3. N´ umero medio de programas en la cola de espera del procesador.\\nPara calcular el n´ umero medio de trabajo en la cola de espera, podemos aplicar la Ley de Little\\na la misma cola. La productividad del procesador es la misma que la de la cola y el tiempo de\\nrespuesta es el tiempo de espera en cola calculador en el apartado anterior. Por tanto, se calcula\\nde la siguiente forma:\\nN=X×R= 2trabajos/s ×25,768s= 51,536trabajos\\n26', 'Pr´ actica 5\\nBloque 1\\nEsta pr´ actica consiste en implementar y verificar el correcto funcionamiento del algoritmo del valor\\nmedio para resolver redes cerradas (MVA). El algoritmo se puede entrar en la p´ agina 136 del libro\\nde la asignatura. Tambi´ en, se pueden hacer uso de los ejercicios resueltos en el libro para comprobar\\nque el algoritmo funciona correctamente.\\nAdem´ as, se deber´ an mostrar gr´ aficamente el valor de las variables Ri, R, X, N iyUien funci´ on del\\nn´ umero de clientes que hay en el sistema. Se deber´ a entregar:\\n1. Implementaci´ on del algoritmo en el lenguaje que el alumno considere m´ as oportuno.\\nEl c´ odigo implementado se ha adjuntado al final de esta pr´ actica. Es un script en Python que\\ncalcula el algoritmo del valor medio para resolver redes cerradas y adem´ as, genera los gr´ aficos\\ncorrespondientes.\\n2. Un documento donde se reflejen tres ejemplos usados para verificar el buen funcio-\\nnamiento del algoritmo.\\nSe han realizado tres experimentos para verificar el buen funcionamiento del algoritmo. A conti-\\nnuaci´ on se muestran las condiciones y los resultados de los mismos.\\n27', 'Experimento 1\\nEn este experimento se han introducido un tiempo de reflexi´ on de 5 segundos y un total de 5\\ntrabajos. Adem´ as, las razones de visita y los tiempos de servicio de cada dispositivo son 15 y 0,03s\\npara el dispositivo 0 y 14 y 0,5s para el dispositivo 1, respectivamente.\\nTrabajos R (s) X (trabajos/s)\\n1 7.45 0.0803\\n2 11.402 0.1219\\n3 16.8098 0.1376\\n4 23.2072 0.1418\\n5 30.0414 0.1427\\nTrabajos Dispositivo Ri (s) Xi (trabajos/s) Ni (trabajos) Ui ( %)\\n0 0.03 1.2048 0.0361 0.036111 0.5 1.1245 0.5622 0.5622\\n0 0.0311 1.829 0.0569 0.054921 0.7811 1.7071 1.3335 0.8536\\n0 0.0317 2.0633 0.0654 0.061931 1.1667 1.9257 2.2468 0.9629\\n0 0.032 2.1271 0.068 0.063841 1.6234 1.9853 3.223 0.9927\\n0 0.032 2.1403 0.0686 0.064251 2.1115 1.9976 4.218 0.9988\\n28', 'Experimento 2\\nEn este experimento se han introducido un tiempo de reflexi´ on de 8 segundos y un total de 10\\ntrabajos. Adem´ as, las razones de visita y los tiempos de servicio de cada dispositivo son 8 y 0,03s\\npara el dispositivo 0 y 7 y 0,1s para el dispositivo 1, respectivamente.\\nTrabajos R (s) X (trabajos/s)\\n1 0.94 0.1119\\n2 1.0013 0.2222\\n3 1.0705 0.3307\\n4 1.1493 0.4372\\n5 1.2394 0.5412\\n6 1.343 0.6422\\n7 1.4626 0.7398\\n8 1.6013 0.8332\\n9 1.7628 0.9219\\n10 1.9511 1.0049\\nTrabajos Dispositivo Ri (s) Xi (trabajos/s) Ni (trabajos) Ui ( %)\\n0 0.03 0.8949 0.0268 0.026811 0.1 0.783 0.0783 0.0783\\n0 0.0308 1.7775 0.0548 0.053321 0.1078 1.5553 0.1677 0.1555\\n0 0.0316 2.6459 0.0837 0.079431 0.1168 2.3152 0.2703 0.2315\\n0 0.0325 3.4975 0.1137 0.104941 0.127 3.0603 0.3888 0.306\\n0 0.0334 4.3293 0.1446 0.129951 0.1389 3.7881 0.5261 0.3788\\n0 0.0343 5.1376 0.1764 0.154161 0.1526 4.4954 0.686 0.4495\\n0 0.0353 5.9181 0.2089 0.177571 0.1686 5.1783 0.8731 0.5178\\n0 0.0363 6.6658 0.2417 0.281 0.1873 5.8326 1.0925 0.5833\\n0 0.0373 7.375 0.2747 0.221291 0.2092 6.4531 1.3503 0.6453\\n0 0.0382 8.0393 0.3074 0.2412101 0.235 7.0344 1.6533 0.7034\\n29', 'Experimento 3\\nEn este experimento se han introducido un tiempo de reflexi´ on de 8 segundos y un total de 10\\ntrabajos. Adem´ as, las razones de visita y los tiempos de servicio de cada dispositivo son 8 y 0,03s\\npara el dispositivo 0, 7 y 0,1s para el dispositivo 1 y 16 y 0.15s para el dispositivo 2, respectivamente.\\nTrabajos R (s) X (trabajos/s)\\n1 3.34 0.0882\\n2 3.8962 0.1681\\n3 4.6107 0.2379\\n4 5.5256 0.2957\\n5 6.6816 0.3406\\n6 8.1065 0.3725\\n7 9.8026 0.3932\\n8 11.7407 0.4053\\n9 13.8674 0.4116\\n10 16.1217 0.4146\\nTrabajos Dispositivo Ri (s) Xi (trabajos/s) Ni (trabajos) Ui ( %)\\n0 0.03 0.7055 0.0212 0.0212\\n1 0.1 0.6173 0.0617 0.0617 1\\n2 0.15 1.4109 0.2116 0.2116\\n0 0.0306 1.345 0.0412 0.0403\\n1 0.1062 1.1768 0.1249 0.1177 2\\n2 0.1817 2.6899 0.4889 0.4035\\n0 0.0312 1.9031 0.0594 0.0571\\n1 0.1125 1.6653 0.1873 0.1665 3\\n2 0.2233 3.8063 0.8501 0.5709\\n0 0.0318 2.3659 0.0752 0.071\\n1 0.1187 2.0702 0.2458 0.207 4\\n2 0.2775 4.7318 1.3131 0.7098\\n0 0.0323 2.7245 0.0879 0.0817\\n1 0.1246 2.3839 0.297 0.2384 5\\n2 0.347 5.449 1.8906 0.8174\\n0 0.0326 2.9802 0.0973 0.0894\\n1 0.1297 2.6076 0.3382 0.2608 6\\n2 0.4336 5.9603 2.5844 0.894\\n0 0.0329 3.1456 0.1035 0.0944\\n1 0.1338 2.7524 0.3683 0.2752 7\\n2 0.5377 6.2912 3.3825 0.9437\\n30', '0 0.0331 3.242 0.1073 0.0973\\n1 0.1368 2.8368 0.3882 0.2837 8\\n2 0.6574 6.4841 4.2625 0.9726\\n0 0.0332 3.2926 0.1094 0.0988\\n1 0.1388 2.881 0.3999 0.2881 9\\n2 0.7894 6.5851 5.1981 0.9878\\n0 0.0333 3.3165 0.1104 0.0995\\n1 0.14 2.902 0.4063 0.2902 10\\n2 0.9297 6.633 6.1669 0.995\\nN´ otese que en las tablas de los diferentes experimentos, el dispositivo 0, tiene como resultado\\nvalores bastante inferiores con respecto al dispositivo 0. Esto se debe a que el tiempo de servicio\\ndel primer dispositivo es mucho menor que del segundo, la cual cosa veremos reflejada en las\\ngr´ aficas a continuaci´ on.\\nCon todos estos experimentos, tendremos diferentes datos para poder observar el comportamiento\\ndel algoritmo. En el siguiente apartado se proceder´ a a graficar y analizarlos.\\n31', '3. A˜ nadir a la documentaci´ on la representaci´ on gr´ afica de las variables calculadas y\\nuna discusi´ on sobre su comportamiento.\\nExperimento 1\\nEn primer lugar, podemos observar que el tiempo de respuesta muestra una tendencia lineal a\\nlargo plazo. Por tanto, podemos decir que a mayor n´ umero de trabajos, proporcionalmente el\\nsistema tendr´ a un tiempo de respuesta mayor. Por otro lado, la productividad tiene una tendencia\\nlogar´ ıtmica, la cual nos muestra a partir de cuantos trabajos el sistema queda estancado. Si nos\\nfijamos, a partir de 4 trabajos, el sistema ya se estanca en cuanto a productividad; pero realmente\\nsolo ha llegado a aproximadamente 0.14 trabajos/s. Eso nos indicia que alg´ un dispositivo hace de\\ncuello de botella.\\nEn este caso, como se ha comentado en el apartado anterior, observamos que los valores del\\ndispositivo 0 en algunas gr´ aficas, no se pueden apreciar del todo. De todos modos, es m´ as interesante\\ncomparar los distintos valores entre dispositivos, con el objetivo de visualizar cu´ al est´ a teniendo\\nm´ as o menos carga de trabajo. Es por eso que las tendencias del dispositivo 0 ser´ an similares\\na las del dispositivo 1. Adem´ as, los resultados que nos pueda ofrecer un sistema al monitorizar\\nlos dispositivos, ser´ a similar a como est´ an graficados ahora. Procedemos ahora si, a comentar su\\ncomportamiento.\\n32', 'En primer lugar, observamos que el tiempo de respuesta del dispositivo 1 es mucho mayor (debido\\na los valores del tiempo de servicio de ambos) y parece mostrar una tendencia lineal relativamente\\nsuave. Esto nos indica que de primeras, con un n´ umero de trabajos bajos, la productividad es alta,\\npero a la larga se acaba estancando (a partir de 3) y a cuantos m´ as trabajos, proporcionalmente\\ntardara m´ as tiempo. Estas suposiciones se afirman observando la gr´ afica de la productividad, que\\na partir de 3 trabajos, el sistema empieza a observar un cuello de botella. Comentar adem´ as, que\\nes curioso como el dispositivo 0 es m´ as productivo que el 1, la cual cosa a simple vista no nos\\nlo parece. En consecuencia, es muy seguro que en las siguientes graficamos veamos como en las\\nrespectivas utilizaciones de los dispositivos, el 1 es el que nos perjudica el rendimiento general del\\nsistema.\\nAqu´ ı podemos ver como el n´ umero de trabajos que se van acumulando en la estaci´ on de cada\\ndispositivo, aumenta linealmente. Esto se debe a que la llegada de trabajos tambi´ en es lineal.\\nPor otro lado, la utilizaci´ on de los dispositivos es distinta. El dispositivo 1 llega a su punto de\\nsaturaci´ on a partir del trabajo 4, es decir, a su m´ axima utilizaci´ on. En cambio, el dispositivo 0\\ntambi´ en se estanca entre el trabajo 3 y 4, pero no pasa de un 10 % de utilizaci´ on. Esto se debe a\\nque el dispositivo 1 tiene una mayor carga de trabajo y, por tanto, una mayor demanda de servicio;\\nes por eso que podr´ ıamos decir que se trata del cuello de botella dels sistema.\\n33', 'Experimento 2\\nEn este caso, el tiempo de respuesta del sistema tiene una tendencia exponencial. Esto significa\\nque a mayor n´ umero de trabajos, el tiempo de respuesta es cada vez mayor (por tanto, peor que\\nen el anterior experimento). Por otro lado, la productividad muestra una tendencia logar´ ıtmica,\\naunque no muy marcada. Podr´ ıamos deducir que a largo plazo se llegar´ ıa a estancar; pero con los\\ndatos recogidos no podemos deducir ese valor. En consecuencia, el sistema tiene a´ un tiene margen\\npara soportar una mayor carga.\\nEn este caso, los dispositivos se comportan muy diferente por lo que se refiere a su tiempo de\\nrespuesta. El dispositivo 0 tiene una tendencia lineal y, sin embargo, el dispositivo 1 la tiene\\nexponencial. Esto significa que el dispositivo 0, a un mayor n´ umero de trabajos, tiene un menor\\ntiempo de respuesta y en consecuencia es m´ as r´ apido. Esto se ve reflejado en la gr´ afica de las\\nproductividades. Claramente, el dispositivo 0 realiza m´ as trabajos por segundo que el dispositivo 1.\\nAmbas no muestran una tendencia clara, pero por lo que nos dice la experiencia, si la calcul´ aramos\\ncon un n´ umero mayor de trabajos, resultar´ ıa ser una tendencia logar´ ıtmica.\\n34', 'En este caso, nos encontramos que el dispositivo 1 tambi´ en muestra peores resultados en estas\\ngr´ aficas. Por un lado, la tendencia de trabajos que se van acumulando en la estaci´ on es exponencial,\\nfrente a la lineal del dispositivo 0. Por otro lado, las dos utilizaciones muestran la misma tendencia,\\npero la del dispositivo 1 aumenta mucho m´ as r´ apido en el eje de las ordenadas.\\nEntonces podemos concluir que en este experimento, ambos dispositivos tienen margen para recibir\\nm´ as carga de trabajo; ya que ninguno se encuentra saturado. Por consiguiente, el sistema tambien\\ntiene margen para recibir m´ as trabajo.\\n35', 'Experimento 3\\nEn este experimento, el tiempo de respuesta tambi´ en es exponencial, y todo lo que ello conlle-\\nva (comentado en el experimento anterior). Adem´ as, la productividad del sistema muestra una\\ntendencia logar´ ıtmica y a partir de los 10 trabajos aproximadamente, el sistema se estanca. Esto\\nquiere decir que algunos de los dispositivos es nuestro cuello de botella.\\nN´ otese que en estas gr´ aficas hemos realizado el experimento con tres dispositivos, a diferencia de\\nlos otros que eran con dos. En este caso, por lo que hace al tiempo de respuesta, el dispositivo 0 y\\n1 tienen una tendencia similar. Sin embargo, el dispositivo 2 muestra una tendencia exponencial,\\npor tanto, tiene un tiempo de respuesta mucho mayor que los otros. En consecuencia, con los\\nmismos trabajos, emplear´ a mucho m´ as tiempo que los otros dispositivos. Como siempre, esto se\\nve reflejado en la productividad del sistema. Sin embargo, por lo que hace a la productividad, el\\ndispositvo 2 muestra una diferencia notoria entre los otros dispostivos. Por mucho que el tiempo\\nde respuesta del dispositvo 2 sea mucho mayor, su productividad sigue siendo mucho mejor que la\\nde los otros dispositivos y esto se ver´ a reflejado en la producitividad del sistema.\\n36', 'El dispositivo 2 muestra un mayor numero de trabajos en la estaci´ on en funci´ on del tiempo, frente\\na los otros dispisitivos. Concretamente, tiene una tendencia que primeramente parece exponencial\\npero se consigue fijar como una tendencia lineal (a un numero mayor de trabajos). Por otro lado,\\nla utilizaci´ on sigue la misma tendencia logaritmica en en todos los dispositivos, pero claramente\\nla del dispositivo 2 llega practicmante al 100 % y por ende seria el cuello de botella del sistema.\\n37', 'Bloque 2 (Opcional)\\nDada la l´ ınea 11 del metro de Barcelona, la cual consta de 5 paradas, se pide modelar el sistema\\nde transporte haciendo uso de la teor´ ıa de colas y responder a las siguientes preguntas:\\nLa informaci´ on necesaria para responder a las preguntas es:\\nFrecuencia de llegada de pasajeros a cada estaci´ on: 20 pasajeros / minuto\\nFrecuencia de llegada del metro en cada estaci´ on: 1 metro / 3 minutos\\nTiempo medio del recorrido entre estaciones: 1 minuto\\nProbabilidad de un pasajero de bajarse: 40\\nTiempo medio de permanencia de un metro en la estaci´ on: 30 segundos\\nPara realizar esta parte de la pr´ actica, se ha llevado a cabo un modelo de una posible soluci´ on del\\nproblema propuesto. El modelo en cuesti´ on es el siguiente:\\nEn este modelo, modelamos dos colas de forma recursiva (para todas las estaciones del metro).\\nLa primera cola ser´ ıa una cola abierta, que representar´ ıa la llegada de personas a la estaci´ on de\\nmetro; y su servicio ser´ ıa entrar dentro del vag´ on del metro. Por otro lado, tenemos la cola que\\nmodela los trenes del metro, concretamente el trayecto que estos siguen. Como la red de metros es\\nuna red cerrada, la respectiva cola tambi´ en lo ser´ a y su servicio ser´ ıa el tiempo que tarda en hacer\\nun trayecto de una estaci´ on a otra.\\nPor tanto, con los datos que se no facilitan, podemos deducir las siguientes equivalencias:\\nFrecuencia de llegadas de pasajeros a cada estaci´ on = λPersonas\\nFrecuencia de llegada del metro en cada estaci´ on = λMetro\\nTiempo del recorrido entre estaciones = STrayecto\\nTiempo medio de permamencia de un metro en la estaci´ on = SMetro =WTrayecto\\n38', 'Ahora entonces, con el modelo hecho y teniendo claro que es cada cosa, podemos proceder a resolver\\nlas siguientes cuestiones.\\n1. ¿Cu´ anto tiempo tarda un metro en recorrer la l´ ınea?\\nSiguiendo el modelo anterior, el tiempo que tarda en recorrer el metro la l´ ınea ser´ ıa equivalente\\nal tiempo de respuesta de la cola cerrada que representa el trayecto. El tiempo de servicio nos lo\\ndan, es 1 minuto, y el tiempo de espera ser´ a el tiempo de servicio de la cola anterior, es decir, 30\\nsegundos. Por tanto, el tiempo de respuesta se puede resolver de la siguiente forma:\\nRTrayecto =SMetro +STrayecto =WTrayecto +STrayecto = 30s+ 1min = 1,5min\\n2. ¿Cu´ al es la probabilidad de llegar a la estaci´ on y encontrarse un metro? ¿Y qu´ e no\\nhaya?\\nEn este caso entendemos que la probabilidad de que un cliente encuentre un metro en la estaci´ on,\\nser´ ıa equivalente a cuando el metro est´ a siendo utilizado.\\nPMetro =UMetro =λMetro∗SMetro =1\\n180trabajos/s ∗30s=1\\n6= 0,1667\\nPor tanto, la probabilidad de llegar y encontrarse un metro es de un 16,67 %. En consecuencia, la\\nprobabilidad de no encontrarselo seria 1 −0,1667 = 0 ,8333, es decir, un 83,33 %.\\n3. ¿Cu´ al es la frecuencia de llegadas m´ axima que soporta el sistema?\\nLa frecuencia m´ axima que soportara el sistema ser´ a la frecuencia m´ axima que soporte la segunda\\ncola; ya que realmente el cuello de botella del sistema es el trayecto que realizan los metros. En\\neste caso, se rige por la siguiente f´ ormula:\\nλmax=1\\nDb\\nPero para caluclar la Dbnecesitamos saber las razones de visita del dispositivo. En este caso es\\n1, ya que las v´ ıas del tren solo pueden llevar un metro. Entonces, la ecuaci´ on se resolver´ a de la\\nsiguiente forma:\\nλmax=1\\nDb=1\\nV∗S=1\\n1∗30= 0,0333\\nPor tanto, la mayor frecuencia de metros/segundo que soportara el sistema ser´ a de 0,0333, es decir,\\naproximadamente 120 metros cada hora.\\n39', 'Scripts\\nA continuaci´ on el script implementado:\\n1import csv\\n2import matplotlib.pyplot as plt\\n3\\n4# Leemos el fichero con los datos\\n5with open(\"data.txt\", \"r\") as f:\\n6 csv_reader = list(csv.reader(f, delimiter=\" \"))\\n7\\n8# Eliminamos la cabecera de las columnas\\n9csv_reader.pop(0)\\n10\\n11# Declaramos la raz´ on de visita y el tiempo de servicio\\n12V = []\\n13S = []\\n14\\n15# Almacenamos los datos del fichero en los arrays correspondientes\\n16for i in range(len(csv_reader)):\\n17 V.append(float(csv_reader[i][0]))\\n18 S.append(float(csv_reader[i][1]))\\n19\\n20dispositivos = len(V)\\n21\\n22# Array bidimensional que contendra los resultados obtenidos\\n23resultados_sistema = []\\n24resultados_dispositivos = []\\n25\\n26# Almacenamos el input del usuario\\n27N = int(input(\"Introduce el n´ umero de trabajos: \"))\\n28Z = int(input(\"Introduce el tiempo de reflexi´ on: \"))\\n29\\n30\\n31def __main__():\\n32 \"\"\" Algoritmo para el an´ alisis del valor medio para redes de colas\\ncerradas\"\"\" ,→\\n33\\n34 # Para todos los trabajos\\n35 for n in range(1, N + 1):\\n36 print(f\"----- Job {n}-----\")\\n37\\n38\\n39\\n40', '40 # Calculamos el tiempo de respuesta y la productividad del sistema\\n41 R = formatear(calcularR(n))\\n42 X = formatear(calcularX(n))\\n43\\n44 resultados_sistema.append([n, R, X])\\n45\\n46 # Para todos los dispositivos\\n47 for i in range(dispositivos):\\n48 Ri = formatear(calcularRi(n, i))\\n49 Xi = formatear(calcularXi(n, i))\\n50 Ni = formatear(calcularNi(n, i))\\n51 Ui = formatear(calcularUi(n, i))\\n52\\n53 resultados_dispositivos.append([i, Ri, Xi, Ni, Ui])\\n54\\n55 # Almacenamos los resultados del sistema en un fichero\\n56 with open(\"resultados_sistema.txt\", \"w\") as f:\\n57 write = csv.writer(f)\\n58 write.writerows(resultados_sistema)\\n59\\n60 # Almacenamos los resultados de los dispositivos en un fichero\\n61 with open(\"resultados_dispositivos.txt\", \"w\") as f:\\n62 write = csv.writer(f)\\n63 write.writerows(resultados_dispositivos)\\n64\\n65 # Almacenamos los valores del eje x para todas las graficas\\n66 j = 0\\n67 eje_x = [fila[j] for fila in resultados_sistema]\\n68\\n69 # Almacenamos las cabeceras de los valores del eje y\\n70 cabeceras = [\\n71 \"Tiempo de respuesta (s)\",\\n72 \"Productividad (trabajos/s)\"]\\n73\\n74 cabeceras_i = [\\n75 \"Tiempo de respuesta (s)\",\\n76 \"Productividad (trabajos/s)\",\\n77 \"Trabajos en la estaci´ on\",\\n78 \"Utilizaci´ on (%)\"]\\n79\\n80 # Graficamos los resultados del sistema\\n81 for i in range(len(cabeceras)):\\n82 plt.figure()\\n83\\n41', '84 # Obtenemos los valores del eje y\\n85 eje_y = [fila[i + 1] for fila in resultados_sistema]\\n86\\n87 # Graficamos los resultados\\n88 plt.plot(eje_x, eje_y, marker = \\'o\\', markersize = 3)\\n89\\n90 # A~ nadimos las etiquetas\\n91 plt.xlabel(\"Trabajos\")\\n92 plt.ylabel(f\" {cabeceras[i] }\")\\n93 plt.title(f\" {cabeceras[i] }del sistema\")\\n94 plt.savefig(f\"grafica_sistema_ {i}.png\")\\n95\\n96 # Graficamos los resultados de los dispositivos\\n97 for i in range(len(cabeceras_i)):\\n98 plt.figure()\\n99\\n100 # Obtenemos los valores del eje y de cada dispositivo\\n101 for j in range(dispositivos):\\n102 eje_y = [fila[i + 1] for fila in resultados_dispositivos if fila[0]\\n== j] ,→\\n103\\n104 # Graficamos los resultados\\n105 plt.plot(eje_x, eje_y, label=f\"Dispositivo {j}\", marker = \\'o\\',\\nmarkersize = 3) ,→\\n106\\n107 # A~ nadimos las etiquetas\\n108 plt.xlabel(\"Trabajos\")\\n109 plt.ylabel(f\" {cabeceras_i[i] }\")\\n110 plt.title(f\" {cabeceras_i[i] }de los dispositivos\")\\n111 plt.legend(loc=\\'upper left\\')\\n112 plt.savefig(f\"grafica_ {i}.png\")\\n113\\n114# Funci´ on para formatear los resultados\\n115def formatear(x):\\n116 return float((\\' %.4f \\' % x).rstrip(\\'0\\').rstrip(\\'.\\'))\\n117\\n118# Funci´ on para calcular el tiempo de respuesta\\n119def calcularR(n):\\n120 return sum(V[i] * calcularRi(n, i) for i in range(dispositivos))\\n121\\n122# Funci´ on para calcular la productividad del sistema\\n123def calcularX(n):\\n124 return n / (Z + calcularR(n))\\n125\\n42', \"126# Funci´ on para calcular la productividad de un dispositivo\\n127def calcularXi(n, i):\\n128 return calcularX(n) * V[i]\\n129\\n130# Funci´ on para calcular el n´ umero de trabajos de un dispositivo\\n131def calcularNi(n, i):\\n132 return (calcularX(n) * V[i] * calcularRi(n, i) if n != 0 else 0)\\n133\\n134# Funci´ on para calcular el tiempo de respuesta de un dispositivo\\n135def calcularRi(n, i):\\n136 return (calcularNi(n - 1, i) + 1) * S[i]\\n137\\n138# Funci´ on para calcular la utilizaci´ on de un dispositivo\\n139def calcularUi(n, i):\\n140 return calcularX(n) * V[i] * S[i]\\n141\\n142\\n143if __name__ == '__main__':\\n144 __main__()\\n43\", 'Pr´ actica 6\\nEl objetivo de esta pr´ actica es la comprensi´ on del concepto de caracterizaci´ on de la carga. Para\\nello, se har´ a uso de la herramienta Weka.\\nDe la monitorizaci´ on de un sistema de almacenamiento, se proporciona un fichero de datos llamado\\ndata.txt. En el fichero se almacenan tres columnas con la siguiente informaci´ on:\\nEl tama˜ no del fichero accedido (en MB). Los valores que correspondan con “-1” quieren decir\\nque el acceso al fichero ha fallado.\\nLa hora a la que se hizo el acceso. El valor 22 representan las 22h, el valor 01 representan\\nlas 1h (a.m.), etc.\\nEl ancho de banda consumido (en MS/s). Los valores de esta columna est´ an entre 453 y\\n1355, por lo tanto, los valores de esta columna deber´ an ser tratados. Es decir, el valor crudo\\nde “1258.84,”, corresponde con “1258,84”.\\nCon los datos proporcionados se pide caracterizar la carga haciendo uso del algoritmo de K-Means\\ny responder a las siguientes preguntas:\\nPara realizar el correcto filtrado de los datos del fichero, se ha realizado el script para que el\\nsoftware Weka pueda interpretar de forma correcta los datos; queda adjunto al final de la pr´ actica.\\n44', '1. Aplicando el algoritmo con 100 iteraciones y agrupando los datos en 3 clases, ¿qu´ e\\nresultados se obtienen? Mu´ estralo gr´ aficamente.\\nEn primer lugar, se llev´ o a cabo la implementaci´ on de un script (opcional) que, teniendo como\\ninput los datos ofrecidos por el Weka, genera una gr´ afica en tres dimensiones (ya que dispon´ ıamos\\nde 3 variables) para obtener una correcta visualizaci´ on de las proyecciones de los datos.\\nEntonces, al visualizar esta gr´ afica, r´ apidamente nos damos cuenta de que la informaci´ on que\\nnos da es un tanto extra˜ na. Es posible esperar otro tipo de agrupamientos, pero analiz´ andolo\\ndetalladamente, nos percatamos de que esto se debe a que el eje del Time (h) no nos est´ a dando\\nninguna informaci´ on relevante. Al no tener datos de todo el d´ ıa, dicha variable no nos es del todo\\n´ util y, por tanto, se puede despreciar. Es por ello que ahora si podemos graficar los resultados\\nconforme a la gr´ afica siguiente; la cual representa, en dos dimensiones, el tama˜ no frente a la\\nvelocidad de transferencia.\\n45', 'Observamos ahora que el Weka nos agrupa los datos en tres grupos (como se le hab´ ıa pedido)\\nproporcionalmente iguales. Sin embargo, no tenemos una nube de puntos, la gr´ afica sigue un\\ncomportamiento conocido como o heavy-tailed distribution . Este comportamiento representa una\\ngran cantidad de valores pr´ oximos al punto cero de la gr´ afica y conforme avanza la gr´ afica se va\\nreduciendo de forma dr´ astica el n´ umero de valores. Esto nos puede hacer pensar que el sistema de\\nalmacenamiento mueve muchos m´ as ficheros de un tama˜ no peque˜ no que de tama˜ nos m´ as grandes.\\nEs obvio ya que los sistemas operativos suelen contener una multitud de ficheros de configuraci´ on\\no de registros, que suelen pesar bastante poco. Y claramente son ficheros que se van actualizando\\nconstantemente.\\n46', '2. Con el mismo n´ umero de iteraciones y agrupando los datos en 5 clases, ¿qu´ e resul-\\ntados se obtienen? ¿C´ omo difieren de los anteriormente obtenidos?\\nAqu´ ı tambi´ en se realiz´ o la representaci´ on en tres dimensiones. Pero como se puede presuponer\\n(viendo los resultados anteriores) tampoco nos va a dar la informaci´ on de una forma ´ util para\\nanalizarla. Por tanto, tambi´ en se han realizado los mismos pasos que en el apartado anterior y se\\nha representado en dos dimensiones directamente.\\nVemos que sigue el mismo patr´ on que en apartado anterior. Es decir, observamos el mayor n´ umero\\nde transferencias de ficheros, son los que ocupan menos y a medida que el tama˜ no aumenta, se\\nrealizan menos transferencias. La ´ unica diferencia palpable es que el Weka ha realizado cinco\\ncl´ usteres en vez de tres.\\n3. ¿Hay alguna caracter´ ıstica especial en la carga proporcionada? Expl´ ıcala con detalle.\\nS´ ı, encontramos unas cuantas. En primer lugar, es un poco extra˜ no que el agrupamiento de los datos\\npor cl´ uster no sea una nube de puntos, como se hab´ ıa visto en las clases te´ oricas. De hecho, dicho\\nagrupamiento ha sido bastante igualado entre cl´ usteres. Esto nos indica que los datos introducidos\\nen el Weka tal vez no eran los correctos, para lo que finalmente quer´ ıamos observar y exige una\\ncomprensi´ on extra por parte del analista para darse cuenta de qu´ e est´ a pasando. En segundo lugar,\\nobservamos que los cl´ usteres se dividen en tres columnas (aunque podr´ ıan ser dos, dependiendo\\ndel zoom que hagamos o lo concretos que queramos ser), la cual cosa sorprende. Esto est´ a ligado\\ncon la tercera caracter´ ıstica especial, que es el porqu´ e se generan estas columnas en los gr´ aficos.\\nComo se ha comentado un poco anteriormente, parece ser que los datos siguen una distribuci´ on de\\ncola pesada (o heavy-tailed distribution ). Este tipo de distribuciones se caracteriza por concentrar\\nla mayor parte de los datos en los valores m´ as cercanos al cero y van disminuyendo a medida que\\naumenta el eje de las abscisas. A continuaci´ on un ejemplo de dicha distribuci´ on.\\n47', 'Heavy-Tailed Distribution\\nEn este ejemplo, la curva que representar´ ıa m´ as la tendencia que siguen nuestros datos ser´ ıa la\\nde color azul. Si nos imagin´ aramos que los ejes tuvieran los mismos nombres que en las gr´ aficas\\n(de dos dimensiones) anteriores, entonces ver´ ıamos claramente que se concentran la mayor´ ıa de\\nficheros al principio del gr´ afico.\\nFinalmente, comentar que para tener una mejor representaci´ on (y en consecuencia un mejor an´ ali-\\nsis) de los cl´ usteres, se deber´ ıa hacer un trabajo previo de agrupaci´ on cualitativa en funci´ on del\\ntama˜ no de los ficheros. Esto nos permitir´ ıa realizar un cl´ uster de cada agrupaci´ on de datos (en\\neste caso posiblemente serian 3) y seguramente el Weka nos mostrar´ ıa unos cl´ usteres mucho m´ as\\ninteresantes que los que nos ha mostrado hasta ahora.\\n48', 'Scripts\\nA continuaci´ on el script de filtrado de los datos que nos genera un archivo .arff de Weka:\\n1import argparse\\n2\\n3parser = argparse.ArgumentParser()\\n4parser.add_argument(\"-i\", \"--input\", help=\"Input file\",\\n5 default=\"data.in\", type=str)\\n6parser.add_argument(\\'-c\\', \"--csv\", help=\"csv format?\",\\n7 action=argparse.BooleanOptionalAction)\\n8args = parser.parse_args()\\n9\\n10def main():\\n11 with open(args.input) as file:\\n12 data = file.read().splitlines()\\n13\\n14 # Remove header\\n15 data.pop(0)\\n16 with open(f\"data. {\\'csv\\' if args.csv else \\'arff\\' }\", \"x\") as output:\\n17 if args.csv:\\n18 output.write(\"size,hour,MB/s\\\\n\")\\n19 else:\\n20 output.write(\"@relation data-server\\\\n\\\\n\")\\n21 output.write(\"@attribute SIZE numeric\\\\n\")\\n22 output.write(\"@attribute HOUR numeric\\\\n\")\\n23 output.write(\"@attribute MBS numeric \\\\n\")\\n24 output.write(\"\\\\n@data\\\\n\\\\n\")\\n25\\n26 for line in data:\\n27 line = line.split(\",\")\\n28\\n29 # Remove first -1\\n30 if line[0] == \"-1\":\\n31 continue\\n32\\n33 # Remove last part\\n34 try:\\n35 line.pop(2)\\n36 except:\\n37 pass\\n38\\n39 # Split values\\n40 try:\\n49', '41 temp = line[1].split(\"\\\\t\")\\n42 except:\\n43 print(line)\\n44\\n45 line[1] = temp[0]\\n46\\n47 # Refractor numbers\\n48 line.append(fractor_number(temp[1]))\\n49\\n50 output.write(f\" {line[0] },{line[1] },{line[2] }\\\\n\")\\n51\\n52def fractor_number(number):\\n53 temp = number.split(\".\")\\n54\\n55 if len(temp) == 3:\\n56 return f\" {temp[0] } {temp[1] }.{temp[2] }\"\\n57 else:\\n58 return number\\n59\\n60if __name__ == \"__main__\":\\n61 main()\\n50', 'A continuaci´ on el script que nos permite representar tantos clusters como genere el Weka, en tres\\ndimensiones:\\n1import argparse\\n2import matplotlib.pyplot as plt\\n3import numpy as np\\n4\\n5colors = (\"r\", \"g\", \"b\")\\n6\\n7parser = argparse.ArgumentParser()\\n8parser.add_argument(\"-c\", \"--cluster\", help=\"Select cluster number\",\\n9 default=3, type=int)\\n10args = parser.parse_args()\\n11\\n12\\n13def main():\\n14 # Get number of clusters from keyboard input\\n15 num_clusters = args.cluster\\n16\\n17 plt.figure()\\n18 ax = plt.axes(projection=\\'3d\\')\\n19\\n20 # Get cluster data and make a scatter plot\\n21 for i in range(num_clusters):\\n22 x_norm, y_norm, z_norm = get_cluster_norm_values(i)\\n23 ax.scatter3D(x_norm, y_norm, z_norm,\\n24 label=f\"Cluster {i}\", c=colors[i], marker=\"o\")\\n25\\n26 # Plot data\\n27 ax.set_title(\\n28 f\"Representation of {args.cluster }clusters | K-Means Clustering with\\nEuclidean Distance\") ,→\\n29 ax.set_xlabel(\\'Size (MB)\\')\\n30 ax.set_ylabel(\\'Time (h)\\')\\n31 ax.set_zlabel(\\'Speed (MB/s)\\')\\n32 ax.legend(bbox_to_anchor=(1.05, 1), ncol=num_clusters)\\n33 plt.savefig(\"cube.png\")\\n34\\n35\\n36def get_cluster_norm_values(value):\\n37 with open(\"cluster.arff\", \"r\") as file:\\n38 data = file.read().splitlines()\\n39\\n40 # Remove header\\n51', '41 data = data[9:]\\n42\\n43 # Create an array with the cluster data\\n44 cluster_value = []\\n45 for line in data:\\n46 line = line.split(\\',\\')\\n47 if line[4] == f\"cluster {value }\":\\n48 cluster_value.append([line[1], line[2], line[3]])\\n49\\n50 # Create diferent arrays for each axis\\n51 cluster_x = [float(x[0]) for x in cluster_value]\\n52 cluster_y = [float(x[1]) for x in cluster_value]\\n53 cluster_z = [float(x[2]) for x in cluster_value]\\n54\\n55 # Get min and max values\\n56 x_mn = [np.min(cluster_x), np.max(cluster_x)]\\n57 y_mn = [np.min(cluster_y), np.max(cluster_y)]\\n58 z_mn = [np.min(cluster_z), np.max(cluster_z)]\\n59\\n60 # Normalize data\\n61 x_norm = [normalize(data, x_mn[0], x_mn[1]) for data in cluster_x]\\n62 y_norm = [normalize(data, y_mn[0], y_mn[1]) for data in cluster_y]\\n63 z_norm = [normalize(data, z_mn[0], z_mn[1]) for data in cluster_z]\\n64\\n65 # Return a tuple\\n66 return x_norm, y_norm, z_norm\\n67\\n68\\n69def normalize(value, min, max):\\n70 return (value - min) / (max - min)\\n71\\n72\\n73if __name__ == \"__main__\":\\n74 main()\\n52', 'A continuaci´ on el script que nos permite representar tantos clusters como genere el Weka, en dos\\ndimensiones:\\n1import argparse\\n2import matplotlib.pyplot as plt\\n3\\n4colors = (\"red\", \"green\", \"blue\", \"yellow\", \"purple\")\\n5\\n6parser = argparse.ArgumentParser()\\n7parser.add_argument(\"-c\", \"--cluster\", help=\"Select cluster number\",\\n8 default=0, type=int)\\n9args = parser.parse_args()\\n10\\n11# Get number of clusters from keyboard input\\n12num_clusters = args.cluster\\n13\\n14\\n15def main():\\n16 plt.figure()\\n17 plt.rcParams.update({\"font.family\": \"serif\"})\\n18\\n19 # Get cluster data and make a scatter plot\\n20 for i in range(num_clusters):\\n21 x_norm, y_norm = get_cluster_norm_values(i)\\n22 plt.plot(x_norm, y_norm, \\'o\\', color=colors[i], markersize=3,\\nlabel=f\"Cluster {i}\") ,→\\n23\\n24 # Plot data\\n25 plt.xlabel(\"Tama~ no (MB)\")\\n26 plt.ylabel(\"Velocidad (MB/s)\")\\n27 plt.title(\\n28 f\"K-Means Algorithm with Euclidean Distance of {num_clusters }\\nclusters\") ,→\\n29 plt.legend(loc=\"upper right\")\\n30 plt.savefig(f\"cluster_ {num_clusters }.png\")\\n31\\n32\\n33def get_cluster_norm_values(value):\\n34 with open(f\"cluster {num_clusters }.arff\", \"r\") as file:\\n35 data = file.read().splitlines()\\n36\\n37 # Remove header\\n38 data = data[8:]\\n39\\n53', '40 # Create an array with the cluster data\\n41 cluster_value = []\\n42 for line in data:\\n43 line = line.split(\\',\\')\\n44 if line[4] == f\"cluster {value }\":\\n45 cluster_value.append([line[1], line[3]])\\n46\\n47 # Create diferent arrays for each axis\\n48 cluster_x = [float(x[0]) for x in cluster_value]\\n49 cluster_y = [float(x[1]) for x in cluster_value]\\n50\\n51 # Return a tuple\\n52 return cluster_x, cluster_y\\n53\\n54\\n55def normalize(value, min, max):\\n56 return (value - min) / (max - min)\\n57\\n58\\n59if __name__ == \"__main__\":\\n60 main()\\n54', 'Pr´ actica 7\\nUna empresa de almacenamiento en la nube monitoriza la actividad de sus usuarios, es decir, se\\nguarda la hora de acceso del cliente, el tama˜ no del fichero al que se ha accedido y la cantidad de\\ninformaci´ on transmitida por unidad de tiempo (hacer uso de los datos de la pr´ actica 6).\\nEl director del departamento de inform´ atica de la empresa solicita calcular la cantidad de infor-\\nmaci´ on transmitida por la red y el tama˜ no del fichero accedido para las 6 a.m. (recordar que la\\n´ ultima hora monitorizada son las 5 a.m.).\\n1. ¿Qu´ e patr´ on siguen los datos monitorizados? Proporciona una representaci´ on gr´ afica.\\n2. Calcula los valores solicitados para las 6 a.m. haciendo uso de la regresi´ on lineal, medias\\nm´ oviles (usar los 4 ´ ultimos valores) y suavizado exponencial (peso fijo del 60 %).\\n3. ¿Qu´ e t´ ecnica de predicci´ on funciona mejor? ¿Por qu´ e? ¿Cu´ al es la m´ as adecuada para los\\ndatos con los que contamos?\\nComentar que para la realizaci´ on de esta pr´ actica se ha implementado un script que realiza todos\\nlos c´ alculos necesarios. Este se encuentra adjunto al final del documento.\\n55', '1. ¿Qu´ e patr´ on siguen los datos monitorizados? Proporciona una representaci´ on gr´ afi-\\nca.\\nPor lo que hace al tama˜ no de los ficheros, podemos observar dos grupos de datos. Por un lado,\\nlos referentes al rango de horas entre las 22 y las 23, donde el sistema trabaja con ficheros de un\\ntama˜ no relativamente peque˜ no. Sin embargo, el segundo grupo, referente al rango de horas entre la\\n1 y las 5 de la ma˜ nana, el sistema trabaja con ficheros de un tama˜ no mucho mayor. Esto suele ser\\nhabitual en los sistemas (tipo servidores) que, durante las horas de la noche, realizan los trabajos\\nm´ as pesados. Esto se hace as´ ı porque si se hicieran de d´ ıa (mientras el usuario tambi´ en hace uso\\ndel sistema) los usuarios podr´ ıan ser los perjudicados.\\nPor otro lado, tenemos la velocidad a la cual se transfieren dichos ficheros. N´ otese que pr´ acticamente\\ndurante toda la monitorizaci´ on del sistema, este transfiere los archivos lo m´ as r´ apido que puede, ya\\nque pr´ acticamente es el mismo valor en todo el eje x. Observamos, pero, una bajada importante a\\nlas 23h. Esto podr´ ıa ser por el cambio de pasar a trabajar con ficheros de tama˜ no considerablemente\\nmayor; ya que si nos fijamos en la gr´ afica anterior, dicho cambio se efect´ ua sobre la misma hora.\\n56', '2. Calcula los valores solicitados para las 6 a.m. haciendo uso de la regresi´ on lineal,\\nmedias m´ oviles (usar los 4 ´ ultimos valores) y suavizado exponencial (peso fijo del\\n60 %).\\nC´ alculos para el Tama˜ no\\nPara construir la recta que representara la regresion lineal se rige por la ecuaci´ on de la recta\\ny=a+bx, donde\\nb=nX\\ni=1xi×yi−n×¯x×¯y\\nnX\\ni=1x2\\ni−n×¯x2\\na= ¯y−b×¯x\\nEntonces, nos quedarian los siguientes resultados:\\ny= 3669 ,2544 + 236 ,6961x\\n¯x= 4\\n¯y= 4379 ,3427\\nY por tanto, la prediccion de la hora 6 seria:\\ny= 3669 ,2544 + 236 ,6961∗(8) = 5562 ,8232MB\\n57', 'Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=yt+yt−1+...+yt−n+1\\nn\\nDonde ft+1es la predicci´ on, ytnson los valores del eje y que queremos utilizar para realizar la\\nprediccion y nque es el n´ umero de ytque cojamos. Por tanto, la operaci´ on para calcular la sexta\\nhora (con los ´ ultimos cuatro valores) es el siguiente:\\nf6=4881,8906 + 4949 ,225 + 4611 ,4016 + 4775 ,2293\\n4= 4804 ,4366MB\\n58', 'Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=ft+α(yt+1−ft)\\nEl cual se tendra que aplicar para cada valor de y. En este caso aplicaremos un α= 0,6:\\nHora Media del tama˜ no (MB) Predicci´ on\\n1 3443.8934 3443.8934\\n2 3546.7858 3505.2288\\n3 4447.9735 4070.8756\\n4 4881.8906 4557.4846\\n5 4949.225 4792.5288\\n6 4611.4016 4683.8524\\n7 4775.2293 4738.6785\\nY, por tanto, el valor que le corresponde a la hora 6 es, 4738.6785 MB.\\n59', 'C´ alculos para la Velocidad\\nPara construir la recta que representara la regresion lineal se rige por la ecuaci´ on de la recta\\ny=a+bx, donde\\nb=nX\\ni=1xi×yi−n×¯x×¯y\\nnX\\ni=1x2\\ni−n×¯x2\\na= ¯y−b×¯x\\nEntonces, nos quedarian los siguientes resultados:\\ny= 817 ,4075 + 1 ,1535x\\n¯x= 4\\n¯y= 820 ,8680\\nY por tanto, la prediccion de la hora 6 seria:\\ny= 817 ,4075 + 1 ,1535∗(8) = 826 ,6355MBps\\n60', 'Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=yt+yt−1+...+yt−n+1\\nn\\nDonde ft+1es la predicci´ on, ytnson los valores del eje y que queremos utilizar para realizar la\\nprediccion y nque es el n´ umero de ytque cojamos. Por tanto, la operaci´ on para calcular la sexta\\nhora (con los ´ ultimos cuatro valores) es el siguiente:\\nf6=823,8627 + 822 ,9925 + 822 ,4515 + 823 ,3838\\n4= 823 ,1726MBps\\n61', 'Dicho c´ alculo de las medias m´ oviles viene dada por la siguiente ecuaci´ on:\\nft+1=ft+α(yt+1−ft)\\nEl cual se tendra que aplicar para cada valor de y. En este caso aplicaremos un α= 0,6:\\nHora Media del tama˜ no (MB) Predicci´ on\\n1 822.5798 822.5798\\n2 807.7088 813.6572\\n3 823.3496 819.4726\\n4 823.8627 822.1066\\n5 822.9925 822.6381\\n6 822.4515 822.5261\\n7 823.3838 823.0407\\nY, por tanto, el valor que le corresponde a la hora 6 es, 823.0407 MBps.\\n3. ¿Qu´ e t´ ecnica de predicci´ on funciona mejor? ¿Por qu´ e? ¿Cu´ al es la m´ as adecuada\\npara los datos con los que contamos?\\nAntes de decidir que t´ ecnica de predicci´ on es la m´ as adecuada, debemos poner en perspectiva los\\ndatos que estamos analizando. Actualmente, estamos calculando el valor que corresponde a la hora\\n6, el cual se predice mediante los valores anteriores. Estos valores anteriores realmente son medias\\nde las decenas de miles de valores que ten´ ıamos previos a la realizaci´ on de las medias. Por tanto, en\\neste contexto, ahora mismo estamos trabajando con periodos de tiempo muy grandes (aunque sea\\nde 1h). Esto se debe a que antes ten´ ıamos miles de valores incluso por cada mil´ esima de segundo\\ny ahora solo tenemos uno por hora.\\nEsto significa que anteriormente el periodo de tiempo entre muestra y muestra era ´ ınfimo, y, por\\ntanto, aplicar una predicci´ on con medias m´ oviles ser´ ıa la opci´ on te´ oricamente m´ as acertada. Sin\\n62', 'embargo, ahora tenemos un periodo de tiempo de horas (miles de mil´ esimas de segundo), es decir,\\nun periodo exageradamente m´ as grande que el anterior. En consecuencia, esto nos indica que\\nla t´ ecnica de predicci´ on m´ as adecuada ser´ a el suavizado exponencial; que funciona mejor para\\nperiodos de tiempo grandes.\\nClaramente, si nos fijamos en los gr´ aficos, podemos observar como lo comentado hasta ahora se\\nrefleja claramente. En particular, en el caso del tama˜ no, la diferencia entre medias m´ oviles y\\nsuavizado exponencial es poca, pero existe. Sin embargo, en el caso de la velocidad, pr´ acticamente\\nes el mismo valor. Es por ello que esto puede llevarnos a la confusi´ on, pero aplicando los conceptos\\nte´ oricos vistos en clase, nos decantamos claramente por el suavizado exponencial en ambos casos.\\n63', 'Scripts\\nA continuaci´ on el script implementado:\\n1import numpy as np\\n2import statistics\\n3import matplotlib.pyplot as plt\\n4\\n5with open(\"data.arff\", \"r\") as file:\\n6 data = file.read().splitlines()\\n7\\n8data = data[8:]\\n9\\n10hours_label = [\"22\", \"23\", \"01\", \"02\", \"03\", \"04\", \"05\"]\\n11pred_hours_label = [\"22\", \"23\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\\n12hours = np.arange(len(hours_label))\\n13\\n14\\n15def size():\\n16 # Plot initialization\\n17 plt.figure()\\n18 plt.rcParams.update({\"font.family\": \"serif\"})\\n19\\n20 y_values = []\\n21\\n22 # Get data for especific hour\\n23 for hour in hours_label:\\n24 y = get_axes_mean(hour, 0)\\n25 plt.scatter(hour, y, s=10, c=\"blue\")\\n26 plt.xticks(hours, hours_label)\\n27\\n28 # Data for post-processing\\n29 y_values.append(y)\\n30\\n31 # Save plot\\n32 plt.title(\"Media de los Tama~ nos (MB) frente al Tiempo (h)\")\\n33 plt.xlabel(\\'Tiempo (h)\\')\\n34 plt.ylabel(\\'Tama~ no (MB)\\')\\n35 plt.savefig(f\"size.png\")\\n36\\n37 # Post-processing\\n38 linear_regression(y_values, \"Tama~ no (MB)\")\\n39 moving_means(y_values, \"Tama~ no (MB)\")\\n40 exponential_smoothing(y_values, \"Tama~ no (MB)\")\\n64', '41\\n42\\n43def velocity():\\n44 # Plot initialization\\n45 plt.figure()\\n46 plt.rcParams.update({\"font.family\": \"serif\"})\\n47\\n48 y_values = []\\n49\\n50 # Get data for especific hour\\n51 for hour in hours_label:\\n52 y = get_axes_mean(hour, 2)\\n53 plt.scatter(hour, y, s=10, c=\"blue\")\\n54 plt.xticks(hours, hours_label)\\n55\\n56 # Data for post-processing\\n57 y_values.append(y)\\n58\\n59 # Save plot\\n60 plt.title(\"Media de las Velocidades (MBps) frente al Tiempo (h)\")\\n61 plt.xlabel(\\'Tiempo (h)\\')\\n62 plt.ylabel(\\'Velocidad (MBps)\\')\\n63 plt.savefig(f\"velocity.png\")\\n64\\n65 # Post-processing\\n66 linear_regression(y_values, \"Velocidad (MBps)\")\\n67 moving_means(y_values, \"Velocidad (MBps)\")\\n68 exponential_smoothing(y_values, \"Velocidad (MBps)\")\\n69\\n70\\n71def format(x):\\n72 return float((\\' %.4f \\' % x).rstrip(\\'0\\').rstrip(\\'.\\'))\\n73\\n74\\n75def get_axes_mean(hour, value):\\n76 y = []\\n77\\n78 # Get data for especific hour\\n79 for line in data:\\n80 line = line.split(\\',\\')\\n81 if line[1] == hour:\\n82 y.append(float(line[value]))\\n83\\n84 # Calculate mean\\n65', '85 if value == 0:\\n86 return format(np.mean(y))\\n87 else:\\n88 return format(statistics.harmonic_mean(y))\\n89\\n90\\n91def linear_regression(y, type):\\n92 x = np.arange(len(y))\\n93\\n94 # Calculate means\\n95 x_mean = np.mean(x)\\n96 if type == \"Velocidad (MBps)\":\\n97 y_mean = statistics.harmonic_mean(y)\\n98 else:\\n99 y_mean = np.mean(y)\\n100\\n101 # Calculate b\\n102 b = (np.sum(y * x) - len(y) * x_mean * y_mean) / (np.sum(x * x) - len(x) *\\nx_mean * x_mean) ,→\\n103\\n104 # Calculate a\\n105 a = y_mean - b * x_mean\\n106\\n107 # Plot data\\n108 plt.figure()\\n109 plt.rcParams.update({\"font.family\": \"serif\"})\\n110 plt.scatter(x, y, s=10, c=\"blue\")\\n111\\n112 # Plot linear regression\\n113 x_plot = np.arange(len(pred_hours_label))\\n114 plt.plot(x_plot, a + b * x_plot, color=\\'red\\')\\n115\\n116 # Save plot\\n117 plt.xticks(x_plot, pred_hours_label)\\n118 plt.title(f\"Regresi´ on Lineal de {type }\")\\n119 plt.xlabel(\\'Tiempo (h)\\')\\n120 plt.ylabel(f\" {type }\")\\n121 plt.savefig(f\"linear_regression_ {type }.png\")\\n122\\n123\\n124def moving_means(y, type):\\n125 i = 1\\n126 moving_averages = []\\n127 cum_sum = np.cumsum(y)\\n66', '128 x = np.arange(len(y))\\n129\\n130 # Calculate moving averages\\n131 i = 4\\n132 while i <= (len(y)):\\n133 window_average = round(cum_sum[i-1] / i, 2)\\n134 moving_averages.append(window_average)\\n135 i += 1\\n136\\n137 # Calulate moving averages for next hour\\n138 moving_averages.append(np.sum(y[-4:])/4)\\n139\\n140 # Plot data\\n141 plt.figure()\\n142 plt.rcParams.update({\"font.family\": \"serif\"})\\n143 plt.scatter(x, y, s=10, c=\"blue\")\\n144\\n145 # Plot moving averages\\n146 x_plot = np.arange(3, 8)\\n147 plt.plot(x_plot, moving_averages, color=\"red\")\\n148\\n149 # Save plot\\n150 x = np.arange(len(pred_hours_label))\\n151 plt.xticks(x, pred_hours_label)\\n152 plt.title(f\"Media M´ ovil de {type }\")\\n153 plt.xlabel(\\'Tiempo (h)\\')\\n154 plt.ylabel(f\" {type }\")\\n155 plt.savefig(f\"moving_means_ {type }.png\")\\n156\\n157\\n158def exponential_smoothing(y, type):\\n159 x = np.arange(len(y))\\n160\\n161 # Plot data\\n162 plt.figure()\\n163 plt.rcParams.update({\"font.family\": \"serif\"})\\n164 plt.scatter(x, y, s=10, c=\"blue\")\\n165\\n166 # Exponential smoothing\\n167 alpha = 0.6\\n168 smoothed = [y[0]]\\n169 for i in range(1, len(y)):\\n170 smoothed.append(alpha * y[i] + (1 - alpha) * smoothed[i-1])\\n171\\n67', '172 # Calculate moving averages for next hour\\n173 smoothed.append(smoothed[-1])\\n174\\n175 # Plot exponential smoothing\\n176 x_plot = np.arange(8)\\n177 plt.plot(x_plot, smoothed, color=\"red\")\\n178\\n179 # Save plot\\n180 plt.xticks(x_plot, pred_hours_label)\\n181 plt.title(f\"Suavizado Exponencial de {type }\")\\n182 plt.xlabel(\\'Tiempo (h)\\')\\n183 plt.ylabel(f\" {type }\")\\n184 plt.savefig(f\"exponential_smoothing_ {type }.png\")\\n185\\n186\\n187if __name__ == \"__main__\":\\n188 size()\\n189 velocity()\\n68']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "combined_pages = []\n",
    "for file_ in files:\n",
    "    file_content = []\n",
    "    for page in file_:\n",
    "        file_content.append(page.page_content)\n",
    "\n",
    "    combined_pages.append(file_content)\n",
    "\n",
    "print(str(combined_pages[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Dependencies for InstructorEmbedding not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:156\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mInstructorEmbedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INSTRUCTOR\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m INSTRUCTOR(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m    160\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'InstructorEmbedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make embeddings with HuggingFace model locally\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceInstructEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBAAI/bge-small-en-v1.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:162\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m INSTRUCTOR(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDependencies for InstructorEmbedding not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Dependencies for InstructorEmbedding not found."
     ]
    }
   ],
   "source": [
    "# Make embeddings with HuggingFace model locally\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "1\n",
      "108\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pdf_files = []\n",
    "for file_ in os.listdir(DATA_PATH):\n",
    "    if file_.endswith(\".pdf\"):\n",
    "        pdf_files.append(file_)\n",
    "\n",
    "raw_files = []\n",
    "for file_ in pdf_files:\n",
    "    reader = PdfReader(os.path.join(DATA_PATH, file_))\n",
    "    raw_files.append(reader)\n",
    "\n",
    "# Extract text from each file\n",
    "files = []\n",
    "for i in raw_files:\n",
    "    documents = []\n",
    "    for j in range(len(i.pages)):\n",
    "        files.append(i.pages[j].extract_text().encode('ascii', 'ignore'))\n",
    "    print(len(files))\n",
    "\n",
    "    # Concatenate all pages of each file in documents\n",
    "    documents.append(files)\n",
    "    print(len(documents))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
